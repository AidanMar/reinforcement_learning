{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('quant': conda)",
   "display_name": "Python 3.7.9 64-bit ('quant': conda)",
   "metadata": {
    "interpreter": {
     "hash": "53410fa49836f37e2db933f2a1c7951cc241afccd53051166d8350041d9f0a2e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-03 12:16:37,191\tINFO services.py:1166 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.0.100',\n",
       " 'raylet_ip_address': '192.168.0.100',\n",
       " 'redis_address': '192.168.0.100:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-11-03_12-16-36_703095_28837/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-11-03_12-16-36_703095_28837/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-11-03_12-16-36_703095_28837',\n",
       " 'metrics_export_port': 59821}"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import gym\n",
    "import ray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "ray.init()"
   ]
  },
  {
   "source": [
    "Load the current s&p 500 ticker list, we will only be trading on these stocks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABMD', 'ABT', 'ACN', 'ADBE', 'ADI', 'ADM', 'ADP', 'ADSK', 'AEE', 'AEP', 'AES', 'AFL', 'AIG', 'AIV', 'AIZ', 'AJG', 'AKAM', 'ALB', 'ALGN', 'ALK', 'ALL', 'ALLE', 'ALXN', 'AMAT', 'AMCR', 'AMD', 'AME', 'AMGN', 'AMP', 'AMT', 'AMZN', 'ANET', 'ANSS', 'ANTM', 'AON', 'AOS', 'APA', 'APD', 'APH', 'APTV', 'ARE', 'ATO', 'ATVI', 'AVB', 'AVGO', 'AVY', 'AWK', 'AXP', 'AZO', 'BA', 'BAC', 'BAX', 'BBY', 'BDX', 'BEN', 'BF.B', 'BIIB', 'BIO', 'BK', 'BKNG', 'BKR', 'BLK', 'BLL', 'BMY', 'BR', 'BRK.B', 'BSX', 'BWA', 'BXP', 'C', 'CAG', 'CAH', 'CARR', 'CAT', 'CB', 'CBOE', 'CBRE', 'CCI', 'CCL', 'CDNS', 'CDW', 'CE', 'CERN', 'CF', 'CFG', 'CHD', 'CHRW', 'CHTR', 'CI', 'CINF', 'CL', 'CLX', 'CMA', 'CMCSA', 'CME', 'CMG', 'CMI', 'CMS', 'CNC', 'CNP', 'COF', 'COG', 'COO', 'COP', 'COST', 'COTY', 'CPB', 'CPRT', 'CRM', 'CSCO', 'CSX', 'CTAS', 'CTL', 'CTSH', 'CTVA', 'CTXS', 'CVS', 'CVX', 'CXO', 'D', 'DAL', 'DD', 'DE', 'DFS', 'DG', 'DGX', 'DHI', 'DHR', 'DIS', 'DISCA', 'DISCK', 'DISH', 'DLR', 'DLTR', 'DOV', 'DOW', 'DPZ', 'DRE', 'DRI', 'DTE', 'DUK', 'DVA', 'DVN', 'DXC', 'DXCM', 'EA', 'EBAY', 'ECL', 'ED', 'EFX', 'EIX', 'EL', 'EMN', 'EMR', 'EOG', 'EQIX', 'EQR', 'ES', 'ESS', 'ETFC', 'ETN', 'ETR', 'EVRG', 'EW', 'EXC', 'EXPD', 'EXPE', 'EXR', 'F', 'FANG', 'FAST', 'FB', 'FBHS', 'FCX', 'FDX', 'FE', 'FFIV', 'FIS', 'FISV', 'FITB', 'FLIR', 'FLS', 'FLT', 'FMC', 'FOX', 'FOXA', 'FRC', 'FRT', 'FTI', 'FTNT', 'FTV', 'GD', 'GE', 'GILD', 'GIS', 'GL', 'GLW', 'GM', 'GOOG', 'GOOGL', 'GPC', 'GPN', 'GPS', 'GRMN', 'GS', 'GWW', 'HAL', 'HAS', 'HBAN', 'HBI', 'HCA', 'HD', 'HES', 'HFC', 'HIG', 'HII', 'HLT', 'HOLX', 'HON', 'HPE', 'HPQ', 'HRB', 'HRL', 'HSIC', 'HST', 'HSY', 'HUM', 'HWM', 'IBM', 'ICE', 'IDXX', 'IEX', 'IFF', 'ILMN', 'INCY', 'INFO', 'INTC', 'INTU', 'IP', 'IPG', 'IPGP', 'IQV', 'IR', 'IRM', 'ISRG', 'IT', 'ITW', 'IVZ', 'J', 'JBHT', 'JCI', 'JKHY', 'JNJ', 'JNPR', 'JPM', 'K', 'KEY', 'KEYS', 'KHC', 'KIM', 'KLAC', 'KMB', 'KMI', 'KMX', 'KO', 'KR', 'KSS', 'KSU', 'L', 'LB', 'LDOS', 'LEG', 'LEN', 'LH', 'LHX', 'LIN', 'LKQ', 'LLY', 'LMT', 'LNC', 'LNT', 'LOW', 'LRCX', 'LUV', 'LVS', 'LW', 'LYB', 'LYV', 'MA', 'MAA', 'MAR', 'MAS', 'MCD', 'MCHP', 'MCK', 'MCO', 'MDLZ', 'MDT', 'MET', 'MGM', 'MHK', 'MKC', 'MKTX', 'MLM', 'MMC', 'MMM', 'MNST', 'MO', 'MOS', 'MPC', 'MRK', 'MRO', 'MS', 'MSCI', 'MSFT', 'MSI', 'MTB', 'MTD', 'MU', 'MXIM', 'MYL', 'NBL', 'NCLH', 'NDAQ', 'NEE', 'NEM', 'NFLX', 'NI', 'NKE', 'NLOK', 'NLSN', 'NOC', 'NOV', 'NOW', 'NRG', 'NSC', 'NTAP', 'NTRS', 'NUE', 'NVDA', 'NVR', 'NWL', 'NWS', 'NWSA', 'O', 'ODFL', 'OKE', 'OMC', 'ORCL', 'ORLY', 'OTIS', 'OXY', 'PAYC', 'PAYX', 'PBCT', 'PCAR', 'PEAK', 'PEG', 'PEP', 'PFE', 'PFG', 'PG', 'PGR', 'PH', 'PHM', 'PKG', 'PKI', 'PLD', 'PM', 'PNC', 'PNR', 'PNW', 'PPG', 'PPL', 'PRGO', 'PRU', 'PSA', 'PSX', 'PVH', 'PWR', 'PXD', 'PYPL', 'QCOM', 'QRVO', 'RCL', 'RE', 'REG', 'REGN', 'RF', 'RHI', 'RJF', 'RL', 'RMD', 'ROK', 'ROL', 'ROP', 'ROST', 'RSG', 'RTX', 'SBAC', 'SBUX', 'SCHW', 'SEE', 'SHW', 'SIVB', 'SJM', 'SLB', 'SLG', 'SNA', 'SNPS', 'SO', 'SPG', 'SPGI', 'SRE', 'STE', 'STT', 'STX', 'STZ', 'SWK', 'SWKS', 'SYF', 'SYK', 'SYY', 'T', 'TAP', 'TDG', 'TDY', 'TEL', 'TFC', 'TFX', 'TGT', 'TIF', 'TJX', 'TMO', 'TMUS', 'TPR', 'TROW', 'TRV', 'TSCO', 'TSN', 'TT', 'TTWO', 'TWTR', 'TXN', 'TXT', 'TYL', 'UA', 'UAA', 'UAL', 'UDR', 'UHS', 'ULTA', 'UNH', 'UNM', 'UNP', 'UPS', 'URI', 'USB', 'V', 'VAR', 'VFC', 'VIAC', 'VLO', 'VMC', 'VNO', 'VRSK', 'VRSN', 'VRTX', 'VTR', 'VZ', 'WAB', 'WAT', 'WBA', 'WDC', 'WEC', 'WELL', 'WFC', 'WHR', 'WLTW', 'WM', 'WMB', 'WMT', 'WRB', 'WRK', 'WST', 'WU', 'WY', 'WYNN', 'XEL', 'XLNX', 'XOM', 'XRAY', 'XRX', 'XYL', 'YUM', 'ZBH', 'ZBRA', 'ZION', 'ZTS']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tickers = open('s&p500_tickers.dat', 'r').read().split('\\n')\n",
    "print(tickers)"
   ]
  },
  {
   "source": [
    "Data start and end dates and initialise ticker dataframe dictionary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day = pd.Timedelta(days=1)\n",
    "\n",
    "i = 0\n",
    "cur_day = pd.to_datetime('1992-06-15', format=r'%Y-%m-%d') #pd.to_datetime('1992-06-15')\n",
    "end_day = pd.to_datetime('2020-01-01', format=r'%Y-%m-%d')\n",
    "\n",
    "end_df = pd.read_csv('equity_data/' + (end_day - one_day).strftime(r'%Y%m%d') + '.csv')\n",
    "ticker_df = end_df.loc[end_df.symbol.isin(tickers)] # Tickers that are in the dataframe on the last day\n",
    "ticker_dict = {ticker_df.symbol.iloc[i] : ticker_df.finnhub_id.iloc[i] for i in range(len(ticker_df.index))} # Create a mapping between tickers and finnhub_ids"
   ]
  },
  {
   "source": [
    "For all dates between start and end range, load the day into ticker dict with the key being ticker and dataframe indexed by day"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_columns = pd.read_csv('equity_data/' + cur_day.strftime(r'%Y%m%d') + '.csv').columns\n",
    "ticker_dfs = { ticker : pd.DataFrame(index=pd.date_range(cur_day, end_day - one_day, freq='D'), columns=df_columns) for ticker in tickers }\n",
    "save_df = False\n",
    "if save_df:\n",
    "    pbar = tqdm(total=(end_day - cur_day).days)\n",
    "    while (cur_day != end_day):\n",
    "        pbar.update()\n",
    "        try:\n",
    "            day_df = pd.read_csv('equity_data/' + cur_day.strftime(r'%Y%m%d') + '.csv')\n",
    "        except FileNotFoundError:\n",
    "            cur_day += one_day\n",
    "            i += 1\n",
    "            continue\n",
    "        for ticker in ticker_dict.keys():\n",
    "            if ticker in day_df.symbol.values:\n",
    "                row = day_df.loc[day_df.finnhub_id == ticker_dict[ticker]]\n",
    "                if row.shape[0] == 2:\n",
    "                    print(ticker)\n",
    "                    print(row)\n",
    "                if not row.shape[0] == 0:\n",
    "                    ticker_dfs[ticker].loc[cur_day] = row.values[0, :]\n",
    "        cur_day += one_day\n",
    "        i += 1\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ss    open    high     low   close  \\\n",
      "index                                                                  \n",
      "2002-10-25  FH109424521   WYNN  None   13.00   13.15   12.85   13.01   \n",
      "2002-10-28  FH109424521   WYNN  None   13.01   13.05   12.96   13.01   \n",
      "2002-10-29  FH109424521   WYNN  None   13.00   13.01   12.04   12.64   \n",
      "2002-10-30  FH109424521   WYNN  None   12.61   12.62   12.13   12.50   \n",
      "2002-10-31  FH109424521   WYNN  None   12.56   13.02   12.50   12.61   \n",
      "...                 ...    ...   ...     ...     ...     ...     ...   \n",
      "2019-12-24  FH109424521   WYNN  None  139.91  140.12  139.24  139.44   \n",
      "2019-12-26  FH109424521   WYNN  None  140.19  141.00  139.57  140.94   \n",
      "2019-12-27  FH109424521   WYNN  None  141.17  141.84  138.73  139.81   \n",
      "2019-12-30  FH109424521   WYNN  None  140.25  140.87  138.02  139.38   \n",
      "2019-12-31  FH109424521   WYNN  None  138.66  140.07  138.25  138.87   \n",
      "\n",
      "                volume  div adjustment     bid     ask  \n",
      "index                                                   \n",
      "2002-10-25  14058747.0  NaN       None   13.00   13.01  \n",
      "2002-10-28   5508729.0  NaN       None   13.00   13.01  \n",
      "2002-10-29   2237596.0  NaN       None   12.60   12.62  \n",
      "2002-10-30    936590.0  NaN       None   12.50   12.51  \n",
      "2002-10-31    301282.0  NaN       None   12.60   12.61  \n",
      "...                ...  ...        ...     ...     ...  \n",
      "2019-12-24    470702.0  NaN       None  139.43  139.47  \n",
      "2019-12-26    978206.0  NaN       None  140.88  140.94  \n",
      "2019-12-27   1399031.0  NaN       None  139.77  139.81  \n",
      "2019-12-30   3054953.0  NaN       None  139.38  139.39  \n",
      "2019-12-31   1133822.0  NaN       None  138.82  138.88  \n",
      "\n",
      "[4324 rows x 12 columns], 'XEL':               finnhub_id symbol class   open   high    low  close     volume  \\\n",
      "index                                                                          \n",
      "1993-08-06  FH1094910B21    NSP  None  45.88  45.88  45.50  45.75    19900.0   \n",
      "1993-08-09  FH1094910B21    NSP  None  45.75  46.00  45.62  45.88    58300.0   \n",
      "1993-08-10  FH1094910B21    NSP  None  45.88  46.00  45.88  46.00    56300.0   \n",
      "1993-08-11  FH1094910B21    NSP  None  46.25  46.50  45.88  46.00   121000.0   \n",
      "1993-08-12  FH1094910B21    NSP  None  46.12  46.25  45.88  46.00    28400.0   \n",
      "...                  ...    ...   ...    ...    ...    ...    ...        ...   \n",
      "2019-12-24  FH1094910B21    XEL  None  62.54  62.90  62.32  62.86   949086.0   \n",
      "2019-12-26  FH1094910B21    XEL  None  62.83  63.03  62.55  62.79  1320610.0   \n",
      "2019-12-27  FH1094910B21    XEL  None  62.81  63.16  62.69  63.12  1927291.0   \n",
      "2019-12-30  FH1094910B21    XEL  None  62.94  63.29  62.72  63.29  1714860.0   \n",
      "2019-12-31  FH1094910B21    XEL  None  63.29  63.55  63.13  63.49  2135979.0   \n",
      "\n",
      "              div adjustment    bid    ask  \n",
      "index                                       \n",
      "1993-08-06    NaN       None  45.50  45.75  \n",
      "1993-08-09    NaN       None  45.75  45.88  \n",
      "1993-08-10    NaN       None  45.75  46.12  \n",
      "1993-08-11    NaN       None  45.75  46.00  \n",
      "1993-08-12    NaN       None  45.75  46.25  \n",
      "...           ...        ...    ...    ...  \n",
      "2019-12-24  0.405       None  62.86  62.89  \n",
      "2019-12-26    NaN       None  62.78  62.79  \n",
      "2019-12-27    NaN       None  63.11  63.12  \n",
      "2019-12-30    NaN       None  63.28  63.29  \n",
      "2019-12-31    NaN       None  63.47  63.49  \n",
      "\n",
      "[6170 rows x 12 columns], 'XLNX':                finnhub_id symbol class   open   high    low  close     volume  \\\n",
      "index                                                                           \n",
      "1992-06-15  FH10941021021   XLNX  None  20.50  21.00  20.25  20.75   127089.0   \n",
      "1992-06-16  FH10941021021   XLNX  None  20.25  20.75  20.00  20.75   101506.0   \n",
      "1992-06-17  FH10941021021   XLNX  None  20.50  20.75  19.00  19.25   274950.0   \n",
      "1992-06-18  FH10941021021   XLNX  None  19.50  20.00  18.25  18.62   197238.0   \n",
      "1992-06-19  FH10941021021   XLNX  None  19.00  19.00  18.50  18.75   247074.0   \n",
      "...                   ...    ...   ...    ...    ...    ...    ...        ...   \n",
      "2019-12-24  FH10941021021   XLNX  None  99.29  99.40  98.05  98.49  1232877.0   \n",
      "2019-12-26  FH10941021021   XLNX  None  98.98  99.09  97.93  98.68  1463913.0   \n",
      "2019-12-27  FH10941021021   XLNX  None  99.00  99.26  98.06  98.42  1726606.0   \n",
      "2019-12-30  FH10941021021   XLNX  None  98.10  98.39  96.69  97.68  1658842.0   \n",
      "2019-12-31  FH10941021021   XLNX  None  96.94  98.54  96.94  97.77  1667449.0   \n",
      "\n",
      "            div adjustment    bid    ask  \n",
      "index                                     \n",
      "1992-06-15  NaN       None  20.75  21.00  \n",
      "1992-06-16  NaN       None  20.50  20.75  \n",
      "1992-06-17  NaN       None  19.00  19.25  \n",
      "1992-06-18  NaN       None  18.25  18.75  \n",
      "1992-06-19  NaN       None  18.75  19.00  \n",
      "...         ...        ...    ...    ...  \n",
      "2019-12-24  NaN       None  98.44  98.49  \n",
      "2019-12-26  NaN       None  98.62  98.67  \n",
      "2019-12-27  NaN       None  98.41  98.42  \n",
      "2019-12-30  NaN       None  97.69  97.71  \n",
      "2019-12-31  NaN       None  97.74  97.77  \n",
      "\n",
      "[6936 rows x 12 columns], 'XOM':             finnhub_id symbol class   open   high    low  close      volume  \\\n",
      "index                                                                         \n",
      "1999-12-01  FH41342G21    XOM  None  79.25  82.88  79.25  82.50   6266000.0   \n",
      "1999-12-02  FH41342G21    XOM  None  82.88  82.88  81.25  81.56   5468000.0   \n",
      "1999-12-03  FH41342G21    XOM  None  82.00  83.12  81.62  82.62   5656299.0   \n",
      "1999-12-06  FH41342G21    XOM  None  82.25  84.00  82.00  83.88   4577199.0   \n",
      "1999-12-07  FH41342G21    XOM  None  84.00  85.19  83.75  83.88   7831199.0   \n",
      "...                ...    ...   ...    ...    ...    ...    ...         ...   \n",
      "2019-12-24  FH41342G21    XOM  None  70.35  70.50  69.91  70.02   3979442.0   \n",
      "2019-12-26  FH41342G21    XOM  None  70.19  70.50  70.01  70.13   8842249.0   \n",
      "2019-12-27  FH41342G21    XOM  None  70.20  70.31  69.88  69.89  10518520.0   \n",
      "2019-12-30  FH41342G21    XOM  None  70.09  70.44  69.40  69.48  12691254.0   \n",
      "2019-12-31  FH41342G21    XOM  None  69.02  69.80  69.01  69.78  13158024.0   \n",
      "\n",
      "            div adjustment    bid    ask  \n",
      "index                                     \n",
      "1999-12-01  NaN       None  81.50  84.00  \n",
      "1999-12-02  NaN       None  81.38  81.75  \n",
      "1999-12-03  NaN       None  82.38  82.88  \n",
      "1999-12-06  NaN       None  83.62  84.12  \n",
      "1999-12-07  NaN       None  83.00  84.50  \n",
      "...         ...        ...    ...    ...  \n",
      "2019-12-24  NaN       None  70.02  70.03  \n",
      "2019-12-26  NaN       None  70.12  70.13  \n",
      "2019-12-27  NaN       None  69.89  69.90  \n",
      "2019-12-30  NaN       None  69.48  69.49  \n",
      "2019-12-31  NaN       None  69.75  69.77  \n",
      "\n",
      "[5053 rows x 12 columns], 'XRAY':              finnhub_id symbol class   open   high    low  close     volume  \\\n",
      "index                                                                         \n",
      "1992-06-15  FH351017P21   XRAY  None  39.25  39.50  38.25  39.25     7113.0   \n",
      "1992-06-16  FH351017P21   XRAY  None  38.25  39.50  38.25  39.00    32080.0   \n",
      "1992-06-17  FH351017P21   XRAY  None  38.50  39.00  38.25  38.75     9425.0   \n",
      "1992-06-18  FH351017P21   XRAY  None  37.50  38.00  36.50  36.75    53196.0   \n",
      "1992-06-19  FH351017P21   XRAY  None  36.50  37.25  36.50  37.25    18390.0   \n",
      "...                 ...    ...   ...    ...    ...    ...    ...        ...   \n",
      "2019-12-24  FH351017P21   XRAY  None  57.03  57.38  56.19  57.21   575234.0   \n",
      "2019-12-26  FH351017P21   XRAY  None  57.12  57.12  56.22  56.53   706347.0   \n",
      "2019-12-27  FH351017P21   XRAY  None  56.44  56.98  56.30  56.84   663099.0   \n",
      "2019-12-30  FH351017P21   XRAY  None  56.69  57.23  56.26  56.40  1282208.0   \n",
      "2019-12-31  FH351017P21   XRAY  None  56.37  56.70  55.95  56.59  1210301.0   \n",
      "\n",
      "            div adjustment    bid    ask  \n",
      "index                                     \n",
      "1992-06-15  NaN       None  38.50  39.50  \n",
      "1992-06-16  NaN       None  38.50  39.25  \n",
      "1992-06-17  NaN       None  38.25  39.25  \n",
      "1992-06-18  NaN       None  36.50  36.75  \n",
      "1992-06-19  NaN       None  36.50  37.25  \n",
      "...         ...        ...    ...    ...  \n",
      "2019-12-24  NaN       None  57.17  57.20  \n",
      "2019-12-26  0.1       None  56.53  56.54  \n",
      "2019-12-27  NaN       None  56.86  56.87  \n",
      "2019-12-30  NaN       None  56.38  56.41  \n",
      "2019-12-31  NaN       None  56.56  56.60  \n",
      "\n",
      "[6936 rows x 12 columns], 'XRX':              finnhub_id symbol class   open   high    low  close     volume  \\\n",
      "index                                                                         \n",
      "1992-06-15  FH109532M21    XRX  None  70.62  70.75  68.75  68.88   391900.0   \n",
      "1992-06-16  FH109532M21    XRX  None  67.25  69.25  67.25  68.75   780300.0   \n",
      "1992-06-17  FH109532M21    XRX  None  68.88  69.62  68.62  68.62   402600.0   \n",
      "1992-06-18  FH109532M21    XRX  None  68.50  69.12  67.38  68.00   503700.0   \n",
      "1992-06-19  FH109532M21    XRX  None  67.75  68.00  67.50  67.88   358400.0   \n",
      "...                 ...    ...   ...    ...    ...    ...    ...        ...   \n",
      "2019-12-24  FH109532M21    XRX  None  37.42  37.52  37.28  37.37   416604.0   \n",
      "2019-12-26  FH109532M21    XRX  None  37.30  37.62  37.30  37.48   776757.0   \n",
      "2019-12-27  FH109532M21    XRX  None  37.55  37.73  37.19  37.31  1163837.0   \n",
      "2019-12-30  FH109532M21    XRX  None  37.13  37.21  36.69  36.90  1083600.0   \n",
      "2019-12-31  FH109532M21    XRX  None  36.78  37.07  36.73  36.87  1380129.0   \n",
      "\n",
      "             div adjustment    bid    ask  \n",
      "index                                      \n",
      "1992-06-15   NaN       None    NaN    NaN  \n",
      "1992-06-16   NaN       None    NaN    NaN  \n",
      "1992-06-17   NaN       None    NaN    NaN  \n",
      "1992-06-18   NaN       None    NaN    NaN  \n",
      "1992-06-19   NaN       None    NaN    NaN  \n",
      "...          ...        ...    ...    ...  \n",
      "2019-12-24   NaN       None  37.38  37.40  \n",
      "2019-12-26   NaN       None  37.48  37.50  \n",
      "2019-12-27   NaN       None  37.31  37.32  \n",
      "2019-12-30  0.25       None  36.92  36.93  \n",
      "2019-12-31   NaN       None  36.87  36.88  \n",
      "\n",
      "[6938 rows x 12 columns], 'XYL':               finnhub_id symbol class   open   high    low  close     volume  \\\n",
      "index                                                                          \n",
      "2011-11-01  FH1095210M21    XYL  None  25.60  28.28  25.15  27.31  6095500.0   \n",
      "2011-11-02  FH1095210M21    XYL  None  27.40  27.40  25.79  26.62  2476700.0   \n",
      "2011-11-03  FH1095210M21    XYL  None  26.94  27.07  26.38  26.39  1615000.0   \n",
      "2011-11-04  FH1095210M21    XYL  None  26.17  26.59  24.88  25.19  1923300.0   \n",
      "2011-11-07  FH1095210M21    XYL  None  24.91  25.48  24.37  24.60  2703400.0   \n",
      "...                  ...    ...   ...    ...    ...    ...    ...        ...   \n",
      "2019-12-24  FH1095210M21    XYL  None  79.00  79.46  78.44  78.64   184585.0   \n",
      "2019-12-26  FH1095210M21    XYL  None  78.64  79.00  77.96  78.60   427501.0   \n",
      "2019-12-27  FH1095210M21    XYL  None  78.88  79.13  78.57  78.84   346738.0   \n",
      "2019-12-30  FH1095210M21    XYL  None  78.89  79.21  78.63  78.74   523845.0   \n",
      "2019-12-31  FH1095210M21    XYL  None  78.87  79.12  78.24  78.79   491967.0   \n",
      "\n",
      "            div adjustment    bid    ask  \n",
      "index                                     \n",
      "2011-11-01  NaN       None  26.94  27.59  \n",
      "2011-11-02  NaN       None  26.62  26.68  \n",
      "2011-11-03  NaN       None  26.39  26.40  \n",
      "2011-11-04  NaN       None  25.16  25.18  \n",
      "2011-11-07  NaN       None  24.56  24.59  \n",
      "...         ...        ...    ...    ...  \n",
      "2019-12-24  NaN       None  78.62  78.63  \n",
      "2019-12-26  NaN       None  78.55  78.57  \n",
      "2019-12-27  NaN       None  78.80  78.83  \n",
      "2019-12-30  NaN       None  78.73  78.74  \n",
      "2019-12-31  NaN       None  78.77  78.80  \n",
      "\n",
      "[2054 rows x 12 columns], 'YUM':               finnhub_id symbol class    open    high     low   close  \\\n",
      "index                                                                   \n",
      "1997-10-07  FH1099510921    YUM  None   32.25   32.75   30.62   31.12   \n",
      "1997-10-08  FH1099510921    YUM  None   31.12   31.25   30.50   30.69   \n",
      "1997-10-09  FH1099510921    YUM  None   30.62   32.00   30.06   31.94   \n",
      "1997-10-10  FH1099510921    YUM  None   30.88   31.94   30.75   31.56   \n",
      "1997-10-13  FH1099510921    YUM  None   31.62   32.06   31.56   32.06   \n",
      "...                  ...    ...   ...     ...     ...     ...     ...   \n",
      "2019-12-24  FH1099510921    YUM  None   99.74  100.46   99.53  100.33   \n",
      "2019-12-26  FH1099510921    YUM  None  100.61  101.82  100.35  101.79   \n",
      "2019-12-27  FH1099510921    YUM  None  101.84  102.20  101.61  101.90   \n",
      "2019-12-30  FH1099510921    YUM  None  101.64  101.64  100.45  100.64   \n",
      "2019-12-31  FH1099510921    YUM  None  100.67  101.17  100.23  100.73   \n",
      "\n",
      "               volume  div adjustment     bid     ask  \n",
      "index                                                  \n",
      "1997-10-07  3883000.0  NaN       None   30.94   31.19  \n",
      "1997-10-08  2995000.0  NaN       None   30.50   30.81  \n",
      "1997-10-09  2309000.0  NaN       None   31.69   32.06  \n",
      "1997-10-10  1853000.0  NaN       None   31.50   31.88  \n",
      "1997-10-13  1891000.0  NaN       None   31.81   32.25  \n",
      "...               ...  ...        ...     ...     ...  \n",
      "2019-12-24   656381.0  NaN       None  100.34  100.37  \n",
      "2019-12-26  1177082.0  NaN       None  101.79  101.80  \n",
      "2019-12-27  1130456.0  NaN       None  101.91  101.93  \n",
      "2019-12-30  1185804.0  NaN       None  100.62  100.64  \n",
      "2019-12-31  1271045.0  NaN       None  100.70  100.73  \n",
      "\n",
      "[5595 rows x 12 columns], 'ZBH':               finnhub_id symbol class    open    high     low   close  \\\n",
      "index                                                                   \n",
      "2015-06-29  FH1091067P21    ZBH  None  107.00  114.41   97.48  109.29   \n",
      "2015-06-30  FH1091067P21    ZBH  None  110.50  110.90  108.75  109.23   \n",
      "2015-07-01  FH1091067P21    ZBH  None  110.00  111.35  109.01  109.21   \n",
      "2015-07-02  FH1091067P21    ZBH  None  110.00  110.98  107.00  108.19   \n",
      "2015-07-06  FH1091067P21    ZBH  None  108.19  109.54  107.61  108.79   \n",
      "...                  ...    ...   ...     ...     ...     ...     ...   \n",
      "2019-12-24  FH1091067P21    ZBH  None  151.19  151.61  150.28  150.87   \n",
      "2019-12-26  FH1091067P21    ZBH  None  150.78  151.67  149.30  150.30   \n",
      "2019-12-27  FH1091067P21    ZBH  None  150.58  150.63  149.68  150.01   \n",
      "2019-12-30  FH1091067P21    ZBH  None  150.15  150.53  148.23  148.75   \n",
      "2019-12-31  FH1091067P21    ZBH  None  148.29  149.71  148.29  149.68   \n",
      "\n",
      "               volume   div adjustment     bid     ask  \n",
      "index                                                   \n",
      "2015-06-29  1562088.0   NaN       None  109.31  109.33  \n",
      "2015-06-30  2225280.0   NaN       None  108.93  108.94  \n",
      "2015-07-01  1240381.0   NaN       None  109.18  109.20  \n",
      "2015-07-02  1402447.0   NaN       None  108.16  108.19  \n",
      "2015-07-06  1524480.0   NaN       None  108.88  108.92  \n",
      "...               ...   ...        ...     ...     ...  \n",
      "2019-12-24   244981.0   NaN       None  150.77  150.87  \n",
      "2019-12-26   611709.0  0.24       None  150.27  150.29  \n",
      "2019-12-27   391920.0   NaN       None  149.98  150.02  \n",
      "2019-12-30   589753.0   NaN       None  148.72  148.75  \n",
      "2019-12-31   612400.0   NaN       None  149.63  149.68  \n",
      "\n",
      "[1136 rows x 12 columns], 'ZBRA':               finnhub_id symbol class    open    high     low   close  \\\n",
      "index                                                                   \n",
      "1992-06-15  FH1091031821   ZBRA     A   18.50   18.50   18.00   18.00   \n",
      "1992-06-16  FH1091031821   ZBRA     A   18.00   18.50   18.00   18.50   \n",
      "1992-06-17  FH1091031821   ZBRA     A   18.00   18.25   17.50   17.50   \n",
      "1992-06-18  FH1091031821   ZBRA     A   18.00   18.00   16.25   16.75   \n",
      "1992-06-19  FH1091031821   ZBRA     A   16.75   18.00   16.25   17.75   \n",
      "...                  ...    ...   ...     ...     ...     ...     ...   \n",
      "2019-12-24  FH1091031821   ZBRA     A  257.05  257.18  253.92  254.33   \n",
      "2019-12-26  FH1091031821   ZBRA     A  255.80  257.00  253.00  254.42   \n",
      "2019-12-27  FH1091031821   ZBRA     A  256.31  257.94  253.38  256.00   \n",
      "2019-12-30  FH1091031821   ZBRA     A  256.00  256.71  253.73  254.11   \n",
      "2019-12-31  FH1091031821   ZBRA     A  253.90  256.47  253.90  255.44   \n",
      "\n",
      "              volume   div adjustment     bid     ask  \n",
      "index                                                  \n",
      "1992-06-15    2700.0  None       None   18.00   18.50  \n",
      "1992-06-16    1100.0  None       None   18.00   18.50  \n",
      "1992-06-17    5150.0  None       None   17.50   18.00  \n",
      "1992-06-18   35550.0  None       None   16.25   16.75  \n",
      "1992-06-19   67650.0  None       None   17.50   17.75  \n",
      "...              ...   ...        ...     ...     ...  \n",
      "2019-12-24  164109.0  None       None  254.10  254.33  \n",
      "2019-12-26  254659.0  None       None  254.35  254.42  \n",
      "2019-12-27  213456.0  None       None  255.97  256.00  \n",
      "2019-12-30  337952.0  None       None  254.12  254.29  \n",
      "2019-12-31  362559.0  None       None  255.44  255.49  \n",
      "\n",
      "[6937 rows x 12 columns], 'ZION':               finnhub_id symbol class   open   high    low  close     volume  \\\n",
      "index                                                                          \n",
      "1992-06-15  FH1091081221   ZION  None  52.88  52.88  52.00  52.00     1600.0   \n",
      "1992-06-16  FH1091081221   ZION  None  52.50  52.50  52.50  52.50      400.0   \n",
      "1992-06-17  FH1091081221   ZION  None  52.00  52.75  52.00  52.75     1364.0   \n",
      "1992-06-18  FH1091081221   ZION  None  52.00  52.00  52.00  52.00      225.0   \n",
      "1992-06-19  FH1091081221   ZION  None  54.00  54.00  54.00  54.00      500.0   \n",
      "...                  ...    ...   ...    ...    ...    ...    ...        ...   \n",
      "2019-12-24  FH1091081221   ZION  None  51.55  51.59  51.29  51.53   312232.0   \n",
      "2019-12-26  FH1091081221   ZION  None  51.48  51.71  50.51  51.66   584797.0   \n",
      "2019-12-27  FH1091081221   ZION  None  51.86  51.86  51.36  51.50   918423.0   \n",
      "2019-12-30  FH1091081221   ZION  None  51.81  52.08  51.30  51.77  1500183.0   \n",
      "2019-12-31  FH1091081221   ZION  None  51.61  52.04  51.61  51.92  1244338.0   \n",
      "\n",
      "            div adjustment    bid    ask  \n",
      "index                                     \n",
      "1992-06-15  NaN       None  52.00  53.75  \n",
      "1992-06-16  NaN       None  52.00  53.75  \n",
      "1992-06-17  NaN       None  52.00  53.75  \n",
      "1992-06-18  NaN       None  52.00  53.75  \n",
      "1992-06-19  NaN       None  52.00  54.00  \n",
      "...         ...        ...    ...    ...  \n",
      "2019-12-24  NaN       None  51.53  51.56  \n",
      "2019-12-26  NaN       None  51.65  51.66  \n",
      "2019-12-27  NaN       None  51.50  51.51  \n",
      "2019-12-30  NaN       None  51.77  51.78  \n",
      "2019-12-31  NaN       None  51.91  51.92  \n",
      "\n",
      "[6931 rows x 12 columns], 'ZTS':               finnhub_id symbol class    open    high     low   close  \\\n",
      "index                                                                   \n",
      "2013-02-01  FH1091089V21    ZTS     A   31.50   31.74   30.47   31.01   \n",
      "2013-02-04  FH1091089V21    ZTS     A   31.09   31.99   30.76   31.02   \n",
      "2013-02-05  FH1091089V21    ZTS     A   31.25   31.98   30.85   31.04   \n",
      "2013-02-06  FH1091089V21    ZTS     A   30.98   31.43   30.75   31.03   \n",
      "2013-02-07  FH1091089V21    ZTS     A   31.00   32.73   31.00   32.00   \n",
      "...                  ...    ...   ...     ...     ...     ...     ...   \n",
      "2019-12-24  FH1091089V21    ZTS     A  132.21  133.08  131.29  132.92   \n",
      "2019-12-26  FH1091089V21    ZTS     A  133.19  133.19  132.32  133.03   \n",
      "2019-12-27  FH1091089V21    ZTS     A  133.40  133.48  132.38  133.25   \n",
      "2019-12-30  FH1091089V21    ZTS     A  133.57  133.66  131.81  132.21   \n",
      "2019-12-31  FH1091089V21    ZTS     A  132.01  132.58  131.45  132.35   \n",
      "\n",
      "                volume  div adjustment     bid     ask  \n",
      "index                                                   \n",
      "2013-02-01  66789500.0  NaN       None   31.04   31.09  \n",
      "2013-02-04   7695900.0  NaN       None   31.07   31.10  \n",
      "2013-02-05   5014300.0  NaN       None   31.05   31.07  \n",
      "2013-02-06   2126100.0  NaN       None   31.03   31.04  \n",
      "2013-02-07   3800800.0  NaN       None   32.11   32.14  \n",
      "...                ...  ...        ...     ...     ...  \n",
      "2019-12-24    442469.0  NaN       None  132.93  132.95  \n",
      "2019-12-26    929458.0  NaN       None  133.03  133.04  \n",
      "2019-12-27   1296099.0  NaN       None  133.25  133.26  \n",
      "2019-12-30    941961.0  NaN       None  132.21  132.24  \n",
      "2019-12-31   1128567.0  NaN       None  132.30  132.33  \n",
      "\n",
      "[1741 rows x 12 columns]}\n"
     ]
    }
   ],
   "source": [
    "# Loading logic, as the above is slow process and we dont want to perform it every time\n",
    "if save_df:\n",
    "    for ticker, ticker_frame in ticker_dfs.items():\n",
    "        ticker_frame.reset_index(inplace=True)\n",
    "        ticker_frame.to_feather('equity_data/stored/' + ticker.lower() + '.feather')\n",
    "else:\n",
    "    print('Loading from storage...')\n",
    "    for symbol in ticker_dict.keys():\n",
    "        ticker_dfs[symbol] = pd.read_feather('equity_data/stored/' + symbol.lower() + '.feather').set_index('index', drop=True)\n",
    "    print(ticker_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Deleting ticker: AAL\nDeleting ticker: ABBV\nDeleting ticker: ADP\nDeleting ticker: AEE\nDeleting ticker: ALLE\nDeleting ticker: AMCR\nDeleting ticker: ANET\nDeleting ticker: ANTM\nDeleting ticker: APTV\nDeleting ticker: BF.B\nDeleting ticker: BKNG\nDeleting ticker: BKR\nDeleting ticker: BRK.B\nDeleting ticker: C\nDeleting ticker: CARR\nDeleting ticker: CBRE\nDeleting ticker: CCI\nDeleting ticker: CDW\nDeleting ticker: CFG\nDeleting ticker: CMCSA\nDeleting ticker: CMI\nDeleting ticker: CNC\nDeleting ticker: CNP\nDeleting ticker: COP\nDeleting ticker: COST\nDeleting ticker: COTY\nDeleting ticker: CTVA\nDeleting ticker: CVS\nDeleting ticker: DD\nDeleting ticker: DOW\nDeleting ticker: DXC\nDeleting ticker: EA\nDeleting ticker: ES\nDeleting ticker: EVRG\nDeleting ticker: EXC\nDeleting ticker: FANG\nDeleting ticker: FB\nDeleting ticker: FOX\nDeleting ticker: FOXA\nDeleting ticker: FTI\nDeleting ticker: FTV\nDeleting ticker: GL\nDeleting ticker: GOOG\nDeleting ticker: GOOGL\nDeleting ticker: HLT\nDeleting ticker: HPE\nDeleting ticker: HST\nDeleting ticker: HWM\nDeleting ticker: INFO\nDeleting ticker: IQV\nDeleting ticker: IT\nDeleting ticker: J\nDeleting ticker: KEY\nDeleting ticker: KEYS\nDeleting ticker: KHC\nDeleting ticker: L\nDeleting ticker: LB\nDeleting ticker: LDOS\nDeleting ticker: LHX\nDeleting ticker: LIN\nDeleting ticker: LKQ\nDeleting ticker: LUV\nDeleting ticker: LW\nDeleting ticker: MDLZ\nDeleting ticker: MGM\nDeleting ticker: MKC\nDeleting ticker: MNST\nDeleting ticker: MS\nDeleting ticker: MSI\nDeleting ticker: MTB\nDeleting ticker: MXIM\nDeleting ticker: NCLH\nDeleting ticker: NLOK\nDeleting ticker: NOV\nDeleting ticker: NOW\nDeleting ticker: NWS\nDeleting ticker: NWSA\nDeleting ticker: OTIS\nDeleting ticker: PAYC\nDeleting ticker: PAYX\nDeleting ticker: PEAK\nDeleting ticker: PNR\nDeleting ticker: PSA\nDeleting ticker: PSX\nDeleting ticker: PYPL\nDeleting ticker: QRVO\nDeleting ticker: RF\nDeleting ticker: RTX\nDeleting ticker: SPG\nDeleting ticker: SPGI\nDeleting ticker: STE\nDeleting ticker: STT\nDeleting ticker: STZ\nDeleting ticker: SYF\nDeleting ticker: T\nDeleting ticker: TAP\nDeleting ticker: TFC\nDeleting ticker: TGT\nDeleting ticker: TMUS\nDeleting ticker: TPR\nDeleting ticker: TRV\nDeleting ticker: TT\nDeleting ticker: TTWO\nDeleting ticker: TWTR\nDeleting ticker: UA\nDeleting ticker: UAA\nDeleting ticker: USB\nDeleting ticker: VIAC\nDeleting ticker: WBA\nDeleting ticker: WEC\nDeleting ticker: WELL\nDeleting ticker: WLTW\nDeleting ticker: WM\nDeleting ticker: WRK\nDeleting ticker: XEL\nDeleting ticker: ZBH\nDeleting ticker: ZTS\n388\n"
     ]
    }
   ],
   "source": [
    "# Clear the data somewhat, we only want frames with more than 2000 days that have gaps no larger than 7 days\n",
    "to_delete = []\n",
    "for ticker, frame in ticker_dfs.items():\n",
    "    prev_day = frame.index[-1]\n",
    "    frame.dropna(axis='index', how='all', inplace=True)\n",
    "    if frame.empty:\n",
    "        to_delete.append(ticker)\n",
    "    elif len(frame.index) < 2000:\n",
    "        to_delete.append(ticker)\n",
    "    else:\n",
    "        for day in frame.index[::-1][1:]:\n",
    "            if (prev_day - day).days > 7: # if gap between datapoints larger than 7 days, remove\n",
    "                to_delete.append(ticker)\n",
    "                break\n",
    "            prev_day = day\n",
    "\n",
    "for ticker in to_delete:\n",
    "    del ticker_dfs[ticker]\n",
    "    print('Deleting ticker: ' + ticker)\n",
    "print(len(ticker_dfs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DatetimeIndex(['1999-11-18', '1999-11-19', '1999-11-22', '1999-11-23',\n",
      "               '1999-11-24', '1999-11-26', '1999-11-29', '1999-11-30',\n",
      "               '1999-12-01', '1999-12-02',\n",
      "               ...\n",
      "               '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20',\n",
      "               '2019-12-23', '2019-12-24', '2019-12-26', '2019-12-27',\n",
      "               '2019-12-30', '2019-12-31'],\n",
      "              dtype='datetime64[ns]', name='index', length=5061, freq=None)\n",
      "A: 5061\n",
      "AAP: 4553\n",
      "AAPL: 4551\n",
      "ABC: 4551\n",
      "ABMD: 4550\n",
      "ABT: 4550\n",
      "ACN: 4550\n",
      "ADBE: 4550\n",
      "ADI: 4550\n",
      "ADM: 4550\n",
      "ADSK: 4550\n",
      "AEP: 4550\n",
      "AES: 4550\n",
      "AFL: 4550\n",
      "AIG: 4550\n",
      "AIV: 4550\n",
      "AIZ: 4001\n",
      "AJG: 4001\n",
      "AKAM: 4001\n",
      "ALB: 4001\n",
      "ALGN: 4001\n",
      "ALK: 4001\n",
      "ALL: 4001\n",
      "ALXN: 4001\n",
      "AMAT: 4001\n",
      "AMD: 4001\n",
      "AME: 4001\n",
      "AMGN: 4001\n",
      "AMP: 3585\n",
      "AMT: 3585\n",
      "AMZN: 3585\n",
      "ANSS: 3585\n",
      "AON: 2537\n",
      "AOS: 2537\n",
      "APA: 2537\n",
      "APD: 2537\n",
      "APH: 2537\n",
      "ARE: 2537\n",
      "ATO: 2537\n",
      "ATVI: 2537\n",
      "AVB: 2537\n",
      "AVGO: 2537\n",
      "AVY: 2537\n",
      "AWK: 2537\n",
      "AXP: 2537\n",
      "AZO: 2537\n",
      "BA: 2537\n",
      "BAC: 2537\n",
      "BAX: 2537\n",
      "BBY: 2537\n",
      "BDX: 2537\n",
      "BEN: 2537\n",
      "BIIB: 2537\n",
      "BIO: 2537\n",
      "BK: 2537\n",
      "BLK: 2537\n",
      "BLL: 2537\n",
      "BMY: 2537\n",
      "BR: 2537\n",
      "BSX: 2537\n",
      "BWA: 2537\n",
      "BXP: 2537\n",
      "CAG: 2537\n",
      "CAH: 2537\n",
      "CAT: 2537\n",
      "CB: 2537\n",
      "CBOE: 2403\n",
      "CCL: 2403\n",
      "CDNS: 2403\n",
      "CE: 2403\n",
      "CERN: 2403\n",
      "CF: 2403\n",
      "CHD: 2403\n",
      "CHRW: 2403\n",
      "CHTR: 2340\n",
      "CI: 2340\n",
      "CINF: 2340\n",
      "CL: 2340\n",
      "CLX: 2340\n",
      "CMA: 2340\n",
      "CME: 2340\n",
      "CMG: 2340\n",
      "CMS: 2340\n",
      "COF: 2340\n",
      "COG: 2340\n",
      "COO: 2340\n",
      "CPB: 2340\n",
      "CPRT: 2340\n",
      "CRM: 2340\n",
      "CSCO: 2340\n",
      "CSX: 2340\n",
      "CTAS: 2340\n",
      "CTL: 2340\n",
      "CTSH: 2340\n",
      "CTXS: 2340\n",
      "CVX: 2340\n",
      "CXO: 2340\n",
      "D: 2340\n",
      "DAL: 2340\n",
      "DE: 2340\n",
      "DFS: 2340\n",
      "DG: 2340\n",
      "DGX: 2340\n",
      "DHI: 2340\n",
      "DHR: 2340\n",
      "DIS: 2340\n",
      "DISCA: 2340\n",
      "DISCK: 2340\n",
      "DISH: 2340\n",
      "DLR: 2340\n",
      "DLTR: 2340\n",
      "DOV: 2340\n",
      "DPZ: 2340\n",
      "DRE: 2340\n",
      "DRI: 2340\n",
      "DTE: 2340\n",
      "DUK: 2340\n",
      "DVA: 2340\n",
      "DVN: 2340\n",
      "DXCM: 2339\n",
      "EBAY: 2339\n",
      "ECL: 2339\n",
      "ED: 2339\n",
      "EFX: 2339\n",
      "EIX: 2339\n",
      "EL: 2339\n",
      "EMN: 2339\n",
      "EMR: 2339\n",
      "EOG: 2339\n",
      "EQIX: 2339\n",
      "EQR: 2339\n",
      "ESS: 2339\n",
      "ETFC: 2339\n",
      "ETN: 2339\n",
      "ETR: 2339\n",
      "EW: 2339\n",
      "EXPD: 2339\n",
      "EXPE: 2339\n",
      "EXR: 2339\n",
      "F: 2339\n",
      "FAST: 2339\n",
      "FBHS: 2072\n",
      "FCX: 2072\n",
      "FDX: 2072\n",
      "FE: 2072\n",
      "FFIV: 2072\n",
      "FIS: 2072\n",
      "FISV: 2072\n",
      "FITB: 2072\n",
      "FLIR: 2072\n",
      "FLS: 2072\n",
      "FLT: 2072\n",
      "FMC: 2072\n",
      "FRC: 2072\n",
      "FRT: 2072\n",
      "FTNT: 2072\n",
      "GD: 2072\n",
      "GE: 2072\n",
      "GILD: 2072\n",
      "GIS: 2072\n",
      "GLW: 2072\n",
      "GM: 2072\n",
      "GPC: 2072\n",
      "GPN: 2072\n",
      "GPS: 2072\n",
      "GRMN: 2072\n",
      "GS: 2072\n",
      "GWW: 2072\n",
      "HAL: 2072\n",
      "HAS: 2072\n",
      "HBAN: 2072\n",
      "HBI: 2072\n",
      "HCA: 2072\n",
      "HD: 2072\n",
      "HES: 2072\n",
      "HFC: 2072\n",
      "HIG: 2072\n",
      "HII: 2072\n",
      "HOLX: 2072\n",
      "HON: 2072\n",
      "HPQ: 2072\n",
      "HRB: 2072\n",
      "HRL: 2072\n",
      "HSIC: 2072\n",
      "HSY: 2072\n",
      "HUM: 2072\n",
      "IBM: 2072\n",
      "ICE: 2072\n",
      "IDXX: 2072\n",
      "IEX: 2072\n",
      "IFF: 2072\n",
      "ILMN: 2072\n",
      "INCY: 2072\n",
      "INTC: 2072\n",
      "INTU: 2072\n",
      "IP: 2072\n",
      "IPG: 2072\n",
      "IPGP: 2072\n",
      "IR: 2072\n",
      "IRM: 2072\n",
      "ISRG: 2072\n",
      "ITW: 2072\n",
      "IVZ: 2072\n",
      "JBHT: 2072\n",
      "JCI: 2072\n",
      "JKHY: 2072\n",
      "JNJ: 2072\n",
      "JNPR: 2072\n",
      "JPM: 2072\n",
      "K: 2072\n",
      "KIM: 2072\n",
      "KLAC: 2072\n",
      "KMB: 2072\n",
      "KMI: 2072\n",
      "KMX: 2072\n",
      "KO: 2072\n",
      "KR: 2072\n",
      "KSS: 2072\n",
      "KSU: 2072\n",
      "LEG: 2072\n",
      "LEN: 2072\n",
      "LH: 2072\n",
      "LLY: 2072\n",
      "LMT: 2072\n",
      "LNC: 2072\n",
      "LNT: 2072\n",
      "LOW: 2072\n",
      "LRCX: 2072\n",
      "LVS: 2072\n",
      "LYB: 2072\n",
      "LYV: 2072\n",
      "MA: 2072\n",
      "MAA: 2072\n",
      "MAR: 2072\n",
      "MAS: 2072\n",
      "MCD: 2072\n",
      "MCHP: 2072\n",
      "MCK: 2072\n",
      "MCO: 2072\n",
      "MDT: 2072\n",
      "MET: 2072\n",
      "MHK: 2072\n",
      "MKTX: 2072\n",
      "MLM: 2072\n",
      "MMC: 2072\n",
      "MMM: 2072\n",
      "MO: 2072\n",
      "MOS: 2072\n",
      "MPC: 2072\n",
      "MRK: 2072\n",
      "MRO: 2072\n",
      "MSCI: 2072\n",
      "MSFT: 2072\n",
      "MTD: 2072\n",
      "MU: 2072\n",
      "MYL: 2072\n",
      "NBL: 2072\n",
      "NDAQ: 2072\n",
      "NEE: 2072\n",
      "NEM: 2072\n",
      "NFLX: 2072\n",
      "NI: 2072\n",
      "NKE: 2072\n",
      "NLSN: 2072\n",
      "NOC: 2072\n",
      "NRG: 2072\n",
      "NSC: 2072\n",
      "NTAP: 2072\n",
      "NTRS: 2072\n",
      "NUE: 2072\n",
      "NVDA: 2072\n",
      "NVR: 2072\n",
      "NWL: 2072\n",
      "O: 2072\n",
      "ODFL: 2072\n",
      "OKE: 2072\n",
      "OMC: 2072\n",
      "ORCL: 2072\n",
      "ORLY: 2072\n",
      "OXY: 2072\n",
      "PBCT: 2072\n",
      "PCAR: 2072\n",
      "PEG: 2072\n",
      "PEP: 2072\n",
      "PFE: 2072\n",
      "PFG: 2072\n",
      "PG: 2072\n",
      "PGR: 2072\n",
      "PH: 2072\n",
      "PHM: 2072\n",
      "PKG: 2072\n",
      "PKI: 2072\n",
      "PLD: 2072\n",
      "PM: 2072\n",
      "PNC: 2072\n",
      "PNW: 2072\n",
      "PPG: 2072\n",
      "PPL: 2072\n",
      "PRGO: 2072\n",
      "PRU: 2072\n",
      "PVH: 2072\n",
      "PWR: 2072\n",
      "PXD: 2072\n",
      "QCOM: 2072\n",
      "RCL: 2072\n",
      "RE: 2072\n",
      "REG: 2072\n",
      "REGN: 2071\n",
      "RHI: 2071\n",
      "RJF: 2071\n",
      "RL: 2071\n",
      "RMD: 2071\n",
      "ROK: 2071\n",
      "ROL: 2071\n",
      "ROP: 2071\n",
      "ROST: 2071\n",
      "RSG: 2071\n",
      "SBAC: 2071\n",
      "SBUX: 2071\n",
      "SCHW: 2071\n",
      "SEE: 2071\n",
      "SHW: 2071\n",
      "SIVB: 2071\n",
      "SJM: 2071\n",
      "SLB: 2071\n",
      "SLG: 2071\n",
      "SNA: 2071\n",
      "SNPS: 2071\n",
      "SO: 2071\n",
      "SRE: 2071\n",
      "STX: 2071\n",
      "SWK: 2071\n",
      "SWKS: 2071\n",
      "SYK: 2071\n",
      "SYY: 2071\n",
      "TDG: 2071\n",
      "TDY: 2071\n",
      "TEL: 2071\n",
      "TFX: 2071\n",
      "TIF: 2071\n",
      "TJX: 2071\n",
      "TMO: 2071\n",
      "TROW: 2071\n",
      "TSCO: 2071\n",
      "TSN: 2071\n",
      "TXN: 2071\n",
      "TXT: 2071\n",
      "TYL: 2071\n",
      "UAL: 2071\n",
      "UDR: 2071\n",
      "UHS: 2071\n",
      "ULTA: 2071\n",
      "UNH: 2071\n",
      "UNM: 2071\n",
      "UNP: 2071\n",
      "UPS: 2071\n",
      "URI: 2071\n",
      "V: 2071\n",
      "VAR: 2071\n",
      "VFC: 2071\n",
      "VLO: 2071\n",
      "VMC: 2071\n",
      "VNO: 2071\n",
      "VRSK: 2071\n",
      "VRSN: 2071\n",
      "VRTX: 2070\n",
      "VTR: 2070\n",
      "VZ: 2070\n",
      "WAB: 2070\n",
      "WAT: 2070\n",
      "WDC: 2070\n",
      "WFC: 2070\n",
      "WHR: 2070\n",
      "WMB: 2070\n",
      "WMT: 2070\n",
      "WRB: 2070\n",
      "WST: 2070\n",
      "WU: 2070\n",
      "WY: 2070\n",
      "WYNN: 2070\n",
      "XLNX: 2070\n",
      "XOM: 2070\n",
      "XRAY: 2070\n",
      "XRX: 2070\n",
      "XYL: 2050\n",
      "YUM: 2050\n",
      "ZBRA: 2050\n",
      "ZION: 2050\n",
      "DatetimeIndex(['2011-11-01', '2011-11-02', '2011-11-03', '2011-11-04',\n",
      "               '2011-11-07', '2011-11-08', '2011-11-09', '2011-11-10',\n",
      "               '2011-11-11', '2011-11-14',\n",
      "               ...\n",
      "               '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20',\n",
      "               '2019-12-23', '2019-12-24', '2019-12-26', '2019-12-27',\n",
      "               '2019-12-30', '2019-12-31'],\n",
      "              dtype='datetime64[ns]', name='index', length=2050, freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Align dataframes by date and create an intersection\n",
    "index_intersection = ticker_dfs[list(ticker_dfs.keys())[0]].index\n",
    "print(index_intersection)\n",
    "for ticker, ticker_frame in ticker_dfs.items():\n",
    "    index_intersection = index_intersection.intersection(ticker_frame.index)\n",
    "    print(ticker + ': ' + str(len(index_intersection)))\n",
    "print(index_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  \n2019-12-30  NaN       None  68.63  68.64  \n2019-12-31  NaN       None  69.07  69.09  \n\n[2050 rows x 12 columns], 'WST':              finnhub_id symbol class    open    high     low   close  \\\nindex                                                                  \n2011-11-01  FH106641721    WST  None   37.50   38.64   35.86   37.43   \n2011-11-02  FH106641721    WST  None   37.74   38.15   37.60   38.05   \n2011-11-03  FH106641721    WST  None   38.40   39.28   37.41   39.21   \n2011-11-04  FH106641721    WST  None   38.81   39.04   38.45   38.75   \n2011-11-07  FH106641721    WST  None   38.64   39.07   37.99   39.04   \n...                 ...    ...   ...     ...     ...     ...     ...   \n2019-12-24  FH106641721    WST  None  150.99  152.09  150.06  150.73   \n2019-12-26  FH106641721    WST  None  151.04  151.12  150.18  150.77   \n2019-12-27  FH106641721    WST  None  151.43  152.12  150.40  150.81   \n2019-12-30  FH106641721    WST  None  150.87  151.32  149.74  150.81   \n2019-12-31  FH106641721    WST  None  150.66  151.57  149.88  150.33   \n\n              volume  div adjustment     bid     ask  \nindex                                                 \n2011-11-01  344800.0  NaN       None   37.41   37.42  \n2011-11-02  214500.0  NaN       None   38.03   38.04  \n2011-11-03  229400.0  NaN       None   39.17   39.18  \n2011-11-04  136400.0  NaN       None   38.73   38.74  \n2011-11-07   74700.0  NaN       None   38.98   38.99  \n...              ...  ...        ...     ...     ...  \n2019-12-24   83597.0  NaN       None  150.82  150.89  \n2019-12-26  118281.0  NaN       None  150.73  150.77  \n2019-12-27  176333.0  NaN       None  150.81  150.82  \n2019-12-30  200799.0  NaN       None  150.78  150.82  \n2019-12-31  480590.0  NaN       None  150.24  150.31  \n\n[2050 rows x 12 columns], 'WU':               finnhub_id symbol class   open   high    low  close     volume  \\\nindex                                                                          \n2011-11-01  FH1061091321     WU  None  16.95  17.29  16.80  16.96  6846300.0   \n2011-11-02  FH1061091321     WU  None  17.26  17.37  17.06  17.30  5431200.0   \n2011-11-03  FH1061091321     WU  None  17.48  17.58  17.16  17.56  5024100.0   \n2011-11-04  FH1061091321     WU  None  17.40  17.45  17.10  17.36  4548000.0   \n2011-11-07  FH1061091321     WU  None  17.34  17.46  17.10  17.38  4226000.0   \n...                  ...    ...   ...    ...    ...    ...    ...        ...   \n2019-12-24  FH1061091321     WU  None  27.13  27.24  27.06  27.07  1068958.0   \n2019-12-26  FH1061091321     WU  None  27.07  27.31  27.05  27.29  2593530.0   \n2019-12-27  FH1061091321     WU  None  27.36  27.50  27.19  27.37  3339222.0   \n2019-12-30  FH1061091321     WU  None  27.32  27.37  26.76  26.78  4391271.0   \n2019-12-31  FH1061091321     WU  None  26.72  26.89  26.64  26.78  3275708.0   \n\n            div adjustment    bid    ask  \nindex                                     \n2011-11-01  NaN       None  16.97  16.98  \n2011-11-02  NaN       None  17.29  17.30  \n2011-11-03  NaN       None  17.54  17.55  \n2011-11-04  NaN       None  17.37  17.38  \n2011-11-07  NaN       None  17.36  17.37  \n...         ...        ...    ...    ...  \n2019-12-24  NaN       None  27.08  27.09  \n2019-12-26  NaN       None  27.29  27.30  \n2019-12-27  NaN       None  27.37  27.38  \n2019-12-30  NaN       None  26.78  26.79  \n2019-12-31  NaN       None  26.78  26.79  \n\n[2050 rows x 12 columns], 'WY':              finnhub_id symbol class   open   high    low  close     volume  \\\nindex                                                                         \n2011-11-01  FH107327721     WY  None  17.46  17.68  17.10  17.13  9386700.0   \n2011-11-02  FH107327721     WY  None  17.58  17.59  17.04  17.25  7366500.0   \n2011-11-03  FH107327721     WY  None  17.47  17.65  17.06  17.54  6568900.0   \n2011-11-04  FH107327721     WY  None  17.38  17.43  17.12  17.31  6390900.0   \n2011-11-07  FH107327721     WY  None  17.22  17.42  16.99  17.23  5497300.0   \n...                 ...    ...   ...    ...    ...    ...    ...        ...   \n2019-12-24  FH107327721     WY  None  30.09  30.09  29.83  29.85   750349.0   \n2019-12-26  FH107327721     WY  None  29.94  30.04  29.79  29.99  1448283.0   \n2019-12-27  FH107327721     WY  None  30.10  30.10  29.91  29.98  1807714.0   \n2019-12-30  FH107327721     WY  None  29.99  30.01  29.78  29.93  2326992.0   \n2019-12-31  FH107327721     WY  None  29.90  30.21  29.82  30.20  2412712.0   \n\n            div adjustment    bid    ask  \nindex                                     \n2011-11-01  NaN       None  17.14  17.15  \n2011-11-02  NaN       None  17.24  17.25  \n2011-11-03  NaN       None  17.53  17.54  \n2011-11-04  NaN       None  17.29  17.30  \n2011-11-07  NaN       None  17.22  17.23  \n...         ...        ...    ...    ...  \n2019-12-24  NaN       None  29.86  29.87  \n2019-12-26  NaN       None  29.98  29.99  \n2019-12-27  NaN       None  29.98  29.99  \n2019-12-30  NaN       None  29.93  29.94  \n2019-12-31  NaN       None  30.18  30.19  \n\n[2050 rows x 12 columns], 'WYNN':              finnhub_id symbol class    open    high     low   close  \\\nindex                                                                  \n2011-11-01  FH109424521   WYNN  None  129.01  130.96  127.02  128.61   \n2011-11-02  FH109424521   WYNN  None  133.39  136.70  131.29  132.54   \n2011-11-03  FH109424521   WYNN  None  134.14  134.94  129.10  133.69   \n2011-11-04  FH109424521   WYNN  None  132.21  134.46  131.05  131.65   \n2011-11-07  FH109424521   WYNN  None  131.36  132.31  127.20  128.72   \n...                 ...    ...   ...     ...     ...     ...     ...   \n2019-12-24  FH109424521   WYNN  None  139.91  140.12  139.24  139.44   \n2019-12-26  FH109424521   WYNN  None  140.19  141.00  139.57  140.94   \n2019-12-27  FH109424521   WYNN  None  141.17  141.84  138.73  139.81   \n2019-12-30  FH109424521   WYNN  None  140.25  140.87  138.02  139.38   \n2019-12-31  FH109424521   WYNN  None  138.66  140.07  138.25  138.87   \n\n               volume  div adjustment     bid     ask  \nindex                                                  \n2011-11-01  2997577.0  NaN       None  128.60  128.71  \n2011-11-02  3938177.0  NaN       None  132.50  132.56  \n2011-11-03  2755224.0  NaN       None  133.61  133.69  \n2011-11-04  2061237.0  NaN       None  131.65  131.66  \n2011-11-07  3979875.0  NaN       None  128.68  128.72  \n...               ...  ...        ...     ...     ...  \n2019-12-24   470702.0  NaN       None  139.43  139.47  \n2019-12-26   978206.0  NaN       None  140.88  140.94  \n2019-12-27  1399031.0  NaN       None  139.77  139.81  \n2019-12-30  3054953.0  NaN       None  139.38  139.39  \n2019-12-31  1133822.0  NaN       None  138.82  138.88  \n\n[2050 rows x 12 columns], 'XLNX':                finnhub_id symbol class   open   high    low  close     volume  \\\nindex                                                                           \n2011-11-01  FH10941021021   XLNX  None  32.74  33.22  32.48  32.52  8292731.0   \n2011-11-02  FH10941021021   XLNX  None  33.44  33.44  31.62  31.81  9432977.0   \n2011-11-03  FH10941021021   XLNX  None  32.02  32.50  31.65  32.42  8216203.0   \n2011-11-04  FH10941021021   XLNX  None  32.23  32.90  32.06  32.85  6170123.0   \n2011-11-07  FH10941021021   XLNX  None  32.65  33.03  32.38  32.97  4204128.0   \n...                   ...    ...   ...    ...    ...    ...    ...        ...   \n2019-12-24  FH10941021021   XLNX  None  99.29  99.40  98.05  98.49  1232877.0   \n2019-12-26  FH10941021021   XLNX  None  98.98  99.09  97.93  98.68  1463913.0   \n2019-12-27  FH10941021021   XLNX  None  99.00  99.26  98.06  98.42  1726606.0   \n2019-12-30  FH10941021021   XLNX  None  98.10  98.39  96.69  97.68  1658842.0   \n2019-12-31  FH10941021021   XLNX  None  96.94  98.54  96.94  97.77  1667449.0   \n\n             div adjustment    bid    ask  \nindex                                      \n2011-11-01   NaN       None  32.53  32.55  \n2011-11-02   NaN       None  31.80  31.80  \n2011-11-03   NaN       None  32.40  32.41  \n2011-11-04   NaN       None  32.87  32.87  \n2011-11-07  0.19       None  32.98  32.99  \n...          ...        ...    ...    ...  \n2019-12-24   NaN       None  98.44  98.49  \n2019-12-26   NaN       None  98.62  98.67  \n2019-12-27   NaN       None  98.41  98.42  \n2019-12-30   NaN       None  97.69  97.71  \n2019-12-31   NaN       None  97.74  97.77  \n\n[2050 rows x 12 columns], 'XOM':             finnhub_id symbol class   open   high    low  close      volume  \\\nindex                                                                         \n2011-11-01  FH41342G21    XOM  None  75.82  77.11  75.45  75.94  35846400.0   \n2011-11-02  FH41342G21    XOM  None  77.37  77.59  76.50  77.37  21773200.0   \n2011-11-03  FH41342G21    XOM  None  78.19  79.00  77.44  78.86  24483300.0   \n2011-11-04  FH41342G21    XOM  None  78.07  78.61  77.38  78.52  18193700.0   \n2011-11-07  FH41342G21    XOM  None  78.82  79.49  78.12  79.35  17999000.0   \n...                ...    ...   ...    ...    ...    ...    ...         ...   \n2019-12-24  FH41342G21    XOM  None  70.35  70.50  69.91  70.02   3979442.0   \n2019-12-26  FH41342G21    XOM  None  70.19  70.50  70.01  70.13   8842249.0   \n2019-12-27  FH41342G21    XOM  None  70.20  70.31  69.88  69.89  10518520.0   \n2019-12-30  FH41342G21    XOM  None  70.09  70.44  69.40  69.48  12691254.0   \n2019-12-31  FH41342G21    XOM  None  69.02  69.80  69.01  69.78  13158024.0   \n\n            div adjustment    bid    ask  \nindex                                     \n2011-11-01  NaN       None  75.90  75.91  \n2011-11-02  NaN       None  77.37  77.38  \n2011-11-03  NaN       None  78.74  78.75  \n2011-11-04  NaN       None  78.51  78.52  \n2011-11-07  NaN       None  79.36  79.37  \n...         ...        ...    ...    ...  \n2019-12-24  NaN       None  70.02  70.03  \n2019-12-26  NaN       None  70.12  70.13  \n2019-12-27  NaN       None  69.89  69.90  \n2019-12-30  NaN       None  69.48  69.49  \n2019-12-31  NaN       None  69.75  69.77  \n\n[2050 rows x 12 columns], 'XRAY':              finnhub_id symbol class   open   high    low  close     volume  \\\nindex                                                                         \n2011-11-01  FH351017P21   XRAY  None  36.20  36.49  35.29  35.55  2727377.0   \n2011-11-02  FH351017P21   XRAY  None  35.94  36.37  35.57  35.84  1766058.0   \n2011-11-03  FH351017P21   XRAY  None  35.93  36.49  35.75  36.31  1377164.0   \n2011-11-04  FH351017P21   XRAY  None  36.13  36.15  35.47  35.79  1060249.0   \n2011-11-07  FH351017P21   XRAY  None  35.82  36.19  35.34  36.17  1074942.0   \n...                 ...    ...   ...    ...    ...    ...    ...        ...   \n2019-12-24  FH351017P21   XRAY  None  57.03  57.38  56.19  57.21   575234.0   \n2019-12-26  FH351017P21   XRAY  None  57.12  57.12  56.22  56.53   706347.0   \n2019-12-27  FH351017P21   XRAY  None  56.44  56.98  56.30  56.84   663099.0   \n2019-12-30  FH351017P21   XRAY  None  56.69  57.23  56.26  56.40  1282208.0   \n2019-12-31  FH351017P21   XRAY  None  56.37  56.70  55.95  56.59  1210301.0   \n\n            div adjustment    bid    ask  \nindex                                     \n2011-11-01  NaN       None  35.54  35.55  \n2011-11-02  NaN       None  35.84  35.85  \n2011-11-03  NaN       None  36.27  36.31  \n2011-11-04  NaN       None  35.79  35.80  \n2011-11-07  NaN       None  36.16  36.17  \n...         ...        ...    ...    ...  \n2019-12-24  NaN       None  57.17  57.20  \n2019-12-26  0.1       None  56.53  56.54  \n2019-12-27  NaN       None  56.86  56.87  \n2019-12-30  NaN       None  56.38  56.41  \n2019-12-31  NaN       None  56.56  56.60  \n\n[2050 rows x 12 columns], 'XRX':              finnhub_id symbol class   open   high    low  close      volume  \\\nindex                                                                          \n2011-11-01  FH109532M21    XRX  None   8.03   8.09   7.90   7.94  13379800.0   \n2011-11-02  FH109532M21    XRX  None   8.08   8.17   7.99   8.09  10082700.0   \n2011-11-03  FH109532M21    XRX  None   8.18   8.38   8.07   8.35  14627200.0   \n2011-11-04  FH109532M21    XRX  None   8.24   8.46   8.12   8.46  18788200.0   \n2011-11-07  FH109532M21    XRX  None   8.45   8.47   8.22   8.45   8947300.0   \n...                 ...    ...   ...    ...    ...    ...    ...         ...   \n2019-12-24  FH109532M21    XRX  None  37.42  37.52  37.28  37.37    416604.0   \n2019-12-26  FH109532M21    XRX  None  37.30  37.62  37.30  37.48    776757.0   \n2019-12-27  FH109532M21    XRX  None  37.55  37.73  37.19  37.31   1163837.0   \n2019-12-30  FH109532M21    XRX  None  37.13  37.21  36.69  36.90   1083600.0   \n2019-12-31  FH109532M21    XRX  None  36.78  37.07  36.73  36.87   1380129.0   \n\n             div adjustment    bid    ask  \nindex                                      \n2011-11-01   NaN       None   7.94   7.95  \n2011-11-02   NaN       None   8.08   8.09  \n2011-11-03   NaN       None   8.33   8.34  \n2011-11-04   NaN       None   8.44   8.45  \n2011-11-07   NaN       None   8.45   8.46  \n...          ...        ...    ...    ...  \n2019-12-24   NaN       None  37.38  37.40  \n2019-12-26   NaN       None  37.48  37.50  \n2019-12-27   NaN       None  37.31  37.32  \n2019-12-30  0.25       None  36.92  36.93  \n2019-12-31   NaN       None  36.87  36.88  \n\n[2050 rows x 12 columns], 'XYL':               finnhub_id symbol class   open   high    low  close     volume  \\\nindex                                                                          \n2011-11-01  FH1095210M21    XYL  None  25.60  28.28  25.15  27.31  6095500.0   \n2011-11-02  FH1095210M21    XYL  None  27.40  27.40  25.79  26.62  2476700.0   \n2011-11-03  FH1095210M21    XYL  None  26.94  27.07  26.38  26.39  1615000.0   \n2011-11-04  FH1095210M21    XYL  None  26.17  26.59  24.88  25.19  1923300.0   \n2011-11-07  FH1095210M21    XYL  None  24.91  25.48  24.37  24.60  2703400.0   \n...                  ...    ...   ...    ...    ...    ...    ...        ...   \n2019-12-24  FH1095210M21    XYL  None  79.00  79.46  78.44  78.64   184585.0   \n2019-12-26  FH1095210M21    XYL  None  78.64  79.00  77.96  78.60   427501.0   \n2019-12-27  FH1095210M21    XYL  None  78.88  79.13  78.57  78.84   346738.0   \n2019-12-30  FH1095210M21    XYL  None  78.89  79.21  78.63  78.74   523845.0   \n2019-12-31  FH1095210M21    XYL  None  78.87  79.12  78.24  78.79   491967.0   \n\n            div adjustment    bid    ask  \nindex                                     \n2011-11-01  NaN       None  26.94  27.59  \n2011-11-02  NaN       None  26.62  26.68  \n2011-11-03  NaN       None  26.39  26.40  \n2011-11-04  NaN       None  25.16  25.18  \n2011-11-07  NaN       None  24.56  24.59  \n...         ...        ...    ...    ...  \n2019-12-24  NaN       None  78.62  78.63  \n2019-12-26  NaN       None  78.55  78.57  \n2019-12-27  NaN       None  78.80  78.83  \n2019-12-30  NaN       None  78.73  78.74  \n2019-12-31  NaN       None  78.77  78.80  \n\n[2050 rows x 12 columns], 'YUM':               finnhub_id symbol class    open    high     low   close  \\\nindex                                                                   \n2011-11-01  FH1099510921    YUM  None   52.51   53.26   52.16   52.62   \n2011-11-02  FH1099510921    YUM  None   53.09   53.35   52.56   53.15   \n2011-11-03  FH1099510921    YUM  None   53.63   54.12   53.01   54.04   \n2011-11-04  FH1099510921    YUM  None   54.03   54.57   53.35   53.98   \n2011-11-07  FH1099510921    YUM  None   54.15   54.75   53.76   54.63   \n...                  ...    ...   ...     ...     ...     ...     ...   \n2019-12-24  FH1099510921    YUM  None   99.74  100.46   99.53  100.33   \n2019-12-26  FH1099510921    YUM  None  100.61  101.82  100.35  101.79   \n2019-12-27  FH1099510921    YUM  None  101.84  102.20  101.61  101.90   \n2019-12-30  FH1099510921    YUM  None  101.64  101.64  100.45  100.64   \n2019-12-31  FH1099510921    YUM  None  100.67  101.17  100.23  100.73   \n\n               volume  div adjustment     bid     ask  \nindex                                                  \n2011-11-01  4132100.0  NaN       None   52.63   52.65  \n2011-11-02  3317700.0  NaN       None   53.12   53.13  \n2011-11-03  3105500.0  NaN       None   54.02   54.03  \n2011-11-04  3955500.0  NaN       None   53.98   54.00  \n2011-11-07  3518900.0  NaN       None   54.61   54.62  \n...               ...  ...        ...     ...     ...  \n2019-12-24   656381.0  NaN       None  100.34  100.37  \n2019-12-26  1177082.0  NaN       None  101.79  101.80  \n2019-12-27  1130456.0  NaN       None  101.91  101.93  \n2019-12-30  1185804.0  NaN       None  100.62  100.64  \n2019-12-31  1271045.0  NaN       None  100.70  100.73  \n\n[2050 rows x 12 columns], 'ZBRA':               finnhub_id symbol class    open    high     low   close  \\\nindex                                                                   \n2011-11-01  FH1091031821   ZBRA     A   34.56   35.13   33.66   33.97   \n2011-11-02  FH1091031821   ZBRA     A   34.53   35.48   34.23   35.40   \n2011-11-03  FH1091031821   ZBRA     A   35.83   36.46   35.33   36.20   \n2011-11-04  FH1091031821   ZBRA     A   35.79   36.44   35.62   36.31   \n2011-11-07  FH1091031821   ZBRA     A   36.17   36.56   35.25   36.53   \n...                  ...    ...   ...     ...     ...     ...     ...   \n2019-12-24  FH1091031821   ZBRA     A  257.05  257.18  253.92  254.33   \n2019-12-26  FH1091031821   ZBRA     A  255.80  257.00  253.00  254.42   \n2019-12-27  FH1091031821   ZBRA     A  256.31  257.94  253.38  256.00   \n2019-12-30  FH1091031821   ZBRA     A  256.00  256.71  253.73  254.11   \n2019-12-31  FH1091031821   ZBRA     A  253.90  256.47  253.90  255.44   \n\n              volume   div adjustment     bid     ask  \nindex                                                  \n2011-11-01  240601.0  None       None   33.97   34.02  \n2011-11-02  363856.0  None       None   35.40   35.42  \n2011-11-03  176964.0  None       None   36.20   36.24  \n2011-11-04   76339.0  None       None   36.26   36.28  \n2011-11-07   93377.0  None       None   36.47   36.52  \n...              ...   ...        ...     ...     ...  \n2019-12-24  164109.0  None       None  254.10  254.33  \n2019-12-26  254659.0  None       None  254.35  254.42  \n2019-12-27  213456.0  None       None  255.97  256.00  \n2019-12-30  337952.0  None       None  254.12  254.29  \n2019-12-31  362559.0  None       None  255.44  255.49  \n\n[2050 rows x 12 columns], 'ZION':               finnhub_id symbol class   open   high    low  close     volume  \\\nindex                                                                          \n2011-11-01  FH1091081221   ZION  None  16.69  17.19  16.28  16.67  5656058.0   \n2011-11-02  FH1091081221   ZION  None  17.07  17.37  16.85  17.05  3413660.0   \n2011-11-03  FH1091081221   ZION  None  17.31  17.57  16.69  17.41  4313686.0   \n2011-11-04  FH1091081221   ZION  None  17.13  17.26  16.79  17.06  3160846.0   \n2011-11-07  FH1091081221   ZION  None  17.01  17.25  16.73  17.18  2141874.0   \n...                  ...    ...   ...    ...    ...    ...    ...        ...   \n2019-12-24  FH1091081221   ZION  None  51.55  51.59  51.29  51.53   312232.0   \n2019-12-26  FH1091081221   ZION  None  51.48  51.71  50.51  51.66   584797.0   \n2019-12-27  FH1091081221   ZION  None  51.86  51.86  51.36  51.50   918423.0   \n2019-12-30  FH1091081221   ZION  None  51.81  52.08  51.30  51.77  1500183.0   \n2019-12-31  FH1091081221   ZION  None  51.61  52.04  51.61  51.92  1244338.0   \n\n            div adjustment    bid    ask  \nindex                                     \n2011-11-01  NaN       None  16.67  16.68  \n2011-11-02  NaN       None  17.03  17.05  \n2011-11-03  NaN       None  17.41  17.42  \n2011-11-04  NaN       None  17.05  17.06  \n2011-11-07  NaN       None  17.16  17.18  \n...         ...        ...    ...    ...  \n2019-12-24  NaN       None  51.53  51.56  \n2019-12-26  NaN       None  51.65  51.66  \n2019-12-27  NaN       None  51.50  51.51  \n2019-12-30  NaN       None  51.77  51.78  \n2019-12-31  NaN       None  51.91  51.92  \n\n[2050 rows x 12 columns]}\n"
     ]
    }
   ],
   "source": [
    "for ticker in ticker_dfs.keys():\n",
    "    ticker_dfs[ticker] = ticker_dfs[ticker].loc[index_intersection]\n",
    "print(ticker_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env config file structure for reference\n",
    "n_assets = 0\n",
    "n_features = 0\n",
    "config = {\n",
    "    'initial_balance': 0,\n",
    "    'initial_portfolio': [0]*n_assets,\n",
    "    'tickers': ['']*n_assets, # Tickers to trade, must correspond to tickers in dataframe dict! Implicitly defines number of assets\n",
    "    'indicators': [None]*n_features, # Indicator functions/classes to compute features for each stock, implicitly defines number of features. TODO: Support multidimensional indicators\n",
    "    'max_indicator_lookback': 0, # Number of days after which all indicators can compute proper values\n",
    "    'trading_days': 0,\n",
    "    'start_day_offset': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv(gym.Env):\n",
    "\n",
    "    def __init__(self, env_config):\n",
    "        super(TradingEnv, self).__init__()\n",
    "\n",
    "        self._env_config = env_config\n",
    "        self._tickers = env_config['tickers']\n",
    "        self._indicator_funcs = self._env_config['indicators']\n",
    "        self._max_indicator_lookback = self._env_config['max_indicator_lookback'] # Number of days after which all indicators can compute proper values\n",
    "\n",
    "        self._n_assets = len(self._tickers)\n",
    "        self._n_features = len(self._indicator_funcs)\n",
    "\n",
    "        assert self._n_assets != 0, 'Number of assets must not be zero!'\n",
    "        assert self._n_features != 0, 'Number of features must not be zero!'\n",
    "\n",
    "        self._df_dict = env_config['df_dict'] # Daily OHCL data for each stock, indexed and aligned by day\n",
    "\n",
    "        self._days = self._df_dict[self._tickers[0]].index\n",
    "        self._trading_days = env_config['trading_days'] # Number of days the algorithm will be trading\n",
    "        self._start_day_idx = env_config['start_day_offset'] # Offset of the first trading day from the first dataframe day\n",
    "        \n",
    "        if self._start_day_idx is not None:\n",
    "            assert self._start_day_idx >= self._max_indicator_lookback, 'start_day_offset must be larger than max_indicator_lookback in order to properly initialise all indicators'\n",
    "            assert self._start_day_idx + self._trading_days <= len(self._days), 'start_day_idx + trading_days must be lower than the number of days'\n",
    "        else:\n",
    "            self._start_day_idx\n",
    "        \n",
    "        assert self._trading_days + self._max_indicator_lookback <= len(self._days) ,'The sum of trading_days + max_indicator_lookback must be lower than the number of days in the dataframe'\n",
    "\n",
    "        self._initial_balance = self._env_config['initial_balance']\n",
    "        self._initial_portfolio = self._env_config['initial_portfolio'] if self._env_config['initial_portfolio'] is not None else [0] * self._n_assets\n",
    "\n",
    "        assert len(self._initial_portfolio) == self._n_assets, 'Size of initial portfolio must equal the number of assets!'\n",
    "\n",
    "        action_shape = (self._n_assets + 1,)\n",
    "        obs_shape = (self._n_features*self._n_assets + 1,)\n",
    "\n",
    "        self.action_space = gym.spaces.Box(np.full(action_shape, 0), np.full(action_shape, 1), shape=action_shape, dtype=np.float16) # Action space is the assets + cash for rebalancing\n",
    "        self.observation_space = gym.spaces.Box(np.full(obs_shape, 0), np.inf, shape=obs_shape, dtype=np.float16) # Observation space is all the features for each asset + cash\n",
    "        self.max_episode_steps = self._trading_days\n",
    "\n",
    "    def reset(self):\n",
    "        self._balance = self._initial_balance\n",
    "        self._portfolio = self._initial_portfolio\n",
    "\n",
    "        if self._start_day_idx is None:\n",
    "            self._start_day_idx = np.random.randint(self._max_indicator_lookback, len(self._days) - self._trading_days) # If no start day chosen, generate a random start\n",
    "        self._cur_day_idx = self._start_day_idx\n",
    "        self._cur_day = self._days[self._cur_day_idx]\n",
    "        self._cur_day_idx += 1 # Advance one day\n",
    "        \n",
    "        indicators = self._compute_indicators(self._cur_day) # Compute the indicators for the start date\n",
    "        \n",
    "        return np.append(indicators, self._balance) # Observation is number of indicators * number of assets + 1\n",
    "\n",
    "    def _compute_indicators(self, day):\n",
    "        features = np.empty((self._n_features*self._n_assets,))\n",
    "        for (i, ticker) in enumerate(self._tickers):\n",
    "            for (j, indicator) in enumerate(self._indicator_funcs):\n",
    "                ticker_frame_slice = self._df_dict[ticker].loc[self._days[self._start_day_idx] - pd.Timedelta(days=1)*self._max_indicator_lookback:(day + pd.Timedelta(days=1))] # Get the relevant dataframe up until this day (inclusive)\n",
    "                features[i*self._n_features + j] = indicator(ticker_frame_slice)\n",
    "        return features\n",
    "\n",
    "    def _asset_prices(self, day): # Use open prices on the current day\n",
    "        prices = np.empty((self._n_assets,))\n",
    "        for i, ticker in enumerate(self._tickers):\n",
    "            prices[i] = self._df_dict[ticker].loc[day].open\n",
    "        return prices\n",
    "\n",
    "    def _portfolio_val(self, portfolio, balance, day):\n",
    "        return np.dot(self._asset_prices(self._cur_day), portfolio) + balance\n",
    "    \n",
    "    def _rebalance(self, actions): # TODO: Test this more to see if it makes sense\n",
    "        weightings = self._softmax(actions) # First weight is for cash\n",
    "\n",
    "        prices = self._asset_prices(self._cur_day) # Get the open prices of assets on the current day\n",
    "        portfolio_val = np.dot(prices, self._portfolio) + self._balance\n",
    "        return (portfolio_val*np.divide(weightings[1:], prices), portfolio_val*weightings[0]) # Rebalanced portfolio in the form of (assets, cash)\n",
    "\n",
    "    def _reward(self):\n",
    "        # For now just compute the increase in portfolio value\n",
    "        return 1 - self._portfolio_val(self._portfolio, self._balance, self._cur_day) / self._portfolio_val(self._initial_portfolio, self._initial_balance, self._days[self._start_day_idx])\n",
    "\n",
    "    def step(self, action):\n",
    "        self._cur_day = self._days[self._cur_day_idx]\n",
    "        #print('Day: ' + str(self._cur_day))\n",
    "        (self._portfolio, self._balance) = self._rebalance(action)\n",
    "\n",
    "        obs = np.append(self._compute_indicators(self._cur_day), self._balance)\n",
    "        rw = self._reward()\n",
    "        done = (self._cur_day_idx - self._start_day_idx) >= self._trading_days\n",
    "        info = {} # TODO: Add info here\n",
    "\n",
    "        self._cur_day_idx += 1 # Advance one day\n",
    "        return obs, rw, done, info\n",
    "    \n",
    "    def _softmax(self, x):\n",
    "        \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_indicator = lambda df: df.close[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_assets = len(ticker_dfs.keys())\n",
    "env_config = {\n",
    "    'initial_balance': 1E6,\n",
    "    'initial_portfolio': [0]*n_assets,\n",
    "    'tickers': list(ticker_dfs.keys()), # Tickers to trade, must correspond to tickers in dataframe dict! Implicitly defines number of assets\n",
    "    'indicators': [close_indicator], # Indicator functions/classes to compute features for each stock, implicitly defines number of features. TODO: Support multidimensional indicators\n",
    "    'max_indicator_lookback': 0, # Number of days after which all indicators can compute proper values\n",
    "    'trading_days': 100,\n",
    "    'start_day_offset': None,\n",
    "    'df_dict': ticker_dfs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-03 12:34:26,239\tWARNING util.py:139 -- The `start_trial` operation took 3.858757972717285 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:34:27,024\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7847261428833008 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 8.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc  </th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>     </td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.017, max=4.384, mean=2.624),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=-0.021, max=0.001, mean=-0.015)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,352\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,353\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,353\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,353\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,353\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,353\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,353\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,353\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,353\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,354\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,354\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,354\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,362\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-4.292, max=4.545, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.056, max=0.179, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.132),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.026, max=0.025, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-596.535, max=-512.404, mean=-552.789),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.292, max=4.545, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.275, max=2.057, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.132),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.292, max=4.545, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.056, max=0.179, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.382, max=4.384, mean=0.826),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.021, max=0.001, mean=-0.011)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,362\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,421\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,750\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.7454395, 'policy_loss': -0.008770391, 'vf_loss': 3.75115, 'vf_explained_var': -0.00047155222, 'kl': 0.015299902, 'entropy': 552.03174, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,769\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.5043461, 'policy_loss': -0.22469056, 'vf_loss': 3.7132409, 'vf_explained_var': 0.0006874601, 'kl': 0.07897664, 'entropy': 552.15155, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,782\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.4617226, 'policy_loss': -0.24546538, 'vf_loss': 3.6790683, 'vf_explained_var': 0.0013880333, 'kl': 0.14059709, 'entropy': 552.2187, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,796\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.4214716, 'policy_loss': -0.25788155, 'vf_loss': 3.642753, 'vf_explained_var': 0.001957357, 'kl': 0.18300153, 'entropy': 552.2405, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,811\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.3882313, 'policy_loss': -0.261951, 'vf_loss': 3.6092293, 'vf_explained_var': 0.0028648179, 'kl': 0.20476282, 'entropy': 552.2247, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,825\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.3512046, 'policy_loss': -0.26359025, 'vf_loss': 3.5733042, 'vf_explained_var': 0.003838261, 'kl': 0.20745175, 'entropy': 552.1835, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,840\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.3129413, 'policy_loss': -0.26409432, 'vf_loss': 3.5379236, 'vf_explained_var': 0.004924635, 'kl': 0.19556041, 'entropy': 552.1487, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,855\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.273512, 'policy_loss': -0.26426136, 'vf_loss': 3.5028203, 'vf_explained_var': 0.0055840015, 'kl': 0.17476477, 'entropy': 552.11456, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,869\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.2329617, 'policy_loss': -0.26470575, 'vf_loss': 3.4673977, 'vf_explained_var': 0.00655665, 'kl': 0.15134877, 'entropy': 552.099, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,884\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.1923141, 'policy_loss': -0.26475736, 'vf_loss': 3.4315166, 'vf_explained_var': 0.007575909, 'kl': 0.1277718, 'entropy': 552.10077, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,900\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.1509695, 'policy_loss': -0.2649043, 'vf_loss': 3.3946648, 'vf_explained_var': 0.008482277, 'kl': 0.10604444, 'entropy': 552.1172, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,915\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.111164, 'policy_loss': -0.26468483, 'vf_loss': 3.358405, 'vf_explained_var': 0.009716849, 'kl': 0.08721811, 'entropy': 552.13135, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,929\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.0725749, 'policy_loss': -0.26509595, 'vf_loss': 3.3233433, 'vf_explained_var': 0.01098603, 'kl': 0.07163852, 'entropy': 552.12524, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,944\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.0385063, 'policy_loss': -0.26423267, 'vf_loss': 3.2909687, 'vf_explained_var': 0.012240171, 'kl': 0.058851022, 'entropy': 552.1104, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,958\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 3.000951, 'policy_loss': -0.26454905, 'vf_loss': 3.2555962, 'vf_explained_var': 0.013885637, 'kl': 0.049518745, 'entropy': 552.07446, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,973\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.9677966, 'policy_loss': -0.26417556, 'vf_loss': 3.2233238, 'vf_explained_var': 0.01538835, 'kl': 0.043241482, 'entropy': 552.05316, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:10,987\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.9357383, 'policy_loss': -0.26437214, 'vf_loss': 3.1922226, 'vf_explained_var': 0.017078618, 'kl': 0.039438486, 'entropy': 552.05176, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:11,001\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.9078267, 'policy_loss': -0.26471856, 'vf_loss': 3.165022, 'vf_explained_var': 0.018743455, 'kl': 0.037615318, 'entropy': 552.04865, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:11,016\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.8780296, 'policy_loss': -0.26416612, 'vf_loss': 3.134753, 'vf_explained_var': 0.020628095, 'kl': 0.03721285, 'entropy': 552.03064, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:11,031\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.852068, 'policy_loss': -0.26432642, 'vf_loss': 3.1089504, 'vf_explained_var': 0.022503257, 'kl': 0.037221298, 'entropy': 552.0203, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:11,046\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.8274643, 'policy_loss': -0.26492998, 'vf_loss': 3.0849411, 'vf_explained_var': 0.024612665, 'kl': 0.037265677, 'entropy': 552.0525, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:11,062\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.8077924, 'policy_loss': -0.26459464, 'vf_loss': 3.0649357, 'vf_explained_var': 0.02666404, 'kl': 0.037258375, 'entropy': 552.0866, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:11,078\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.7865398, 'policy_loss': -0.2647506, 'vf_loss': 3.0438893, 'vf_explained_var': 0.029122869, 'kl': 0.037005074, 'entropy': 552.1004, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:11,093\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.7677448, 'policy_loss': -0.26426485, 'vf_loss': 3.024765, 'vf_explained_var': 0.031489193, 'kl': 0.03622235, 'entropy': 552.1027, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:11,107\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.748843, 'policy_loss': -0.26496825, 'vf_loss': 3.00675, 'vf_explained_var': 0.033921838, 'kl': 0.035305936, 'entropy': 552.0946, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:11,121\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.7345345, 'policy_loss': -0.26455167, 'vf_loss': 2.9922016, 'vf_explained_var': 0.036711294, 'kl': 0.034424137, 'entropy': 552.08185, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:11,136\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.718541, 'policy_loss': -0.26460627, 'vf_loss': 2.9764566, 'vf_explained_var': 0.03932033, 'kl': 0.033452854, 'entropy': 552.094, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:11,150\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.7039258, 'policy_loss': -0.26445967, 'vf_loss': 2.9618864, 'vf_explained_var': 0.04243934, 'kl': 0.03249546, 'entropy': 552.102, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:11,164\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.6919363, 'policy_loss': -0.26433718, 'vf_loss': 2.9498856, 'vf_explained_var': 0.04551069, 'kl': 0.03193887, 'entropy': 552.1119, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:36:11,178\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.677058, 'policy_loss': -0.264665, 'vf_loss': 2.9354084, 'vf_explained_var': 0.049147725, 'kl': 0.031574022, 'entropy': 552.138, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m WARNING:tensorflow:From /Users/Palo/anaconda3/envs/quant/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:874: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m WARNING:tensorflow:From /Users/Palo/anaconda3/envs/quant/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:874: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=29365)\u001b[0m WARNING:tensorflow:From /Users/Palo/anaconda3/envs/quant/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:874: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=29365)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=29365)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=29368)\u001b[0m WARNING:tensorflow:From /Users/Palo/anaconda3/envs/quant/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:874: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=29368)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=29368)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=29358)\u001b[0m WARNING:tensorflow:From /Users/Palo/anaconda3/envs/quant/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:874: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=29358)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=29358)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=29359)\u001b[0m WARNING:tensorflow:From /Users/Palo/anaconda3/envs/quant/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:874: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=29359)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=29359)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-36-11\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 6.7957666567495\n",
      "  episode_reward_mean: 2.8265456096616264\n",
      "  episode_reward_min: -2.0180984935556423\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 5\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.1380004882812\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03157402202486992\n",
      "        model: {}\n",
      "        policy_loss: -0.26466500759124756\n",
      "        total_loss: 2.677057981491089\n",
      "        vf_explained_var: 0.049147725105285645\n",
      "        vf_loss: 2.935408353805542\n",
      "    num_steps_sampled: 500\n",
      "    num_steps_trained: 500\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.2857142857143\n",
      "    ram_util_percent: 71.89411764705882\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15240234903769917\n",
      "    mean_env_wait_ms: 553.191331825634\n",
      "    mean_inference_ms: 1.7961483190555385\n",
      "    mean_raw_obs_processing_ms: 1.8785467242250349\n",
      "  time_since_restore: 83.6190230846405\n",
      "  time_this_iter_s: 83.6190230846405\n",
      "  time_total_s: 83.6190230846405\n",
      "  timers:\n",
      "    learn_throughput: 660.434\n",
      "    learn_time_ms: 757.078\n",
      "    load_throughput: 7065.043\n",
      "    load_time_ms: 70.771\n",
      "    sample_throughput: 6.048\n",
      "    sample_time_ms: 82678.155\n",
      "    update_time_ms: 5.009\n",
      "  timestamp: 1604403371\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 500\n",
      "  training_iteration: 1\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:36:15,671\tWARNING util.py:139 -- The `process_trial` operation took 3.945167303085327 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:36:16,877\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 1.2050480842590332 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">          83.619</td><td style=\"text-align: right;\"> 500</td><td style=\"text-align: right;\"> 2.82655</td><td style=\"text-align: right;\">             6.79577</td><td style=\"text-align: right;\">             -2.0181</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m 2020-11-03 12:36:41,449\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.069, max=0.069, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-590.546, max=-518.966, mean=-552.134),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.172, max=4.297, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-0.847, max=1.46, mean=-0.309),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=1661857128.0, max=1661857128.0, mean=1661857128.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=1.8, max=5067.044, mean=92.891),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=1.8, max=1000000.0, mean=118.535),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.172, max=4.297, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.076, max=0.102, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.076, max=0.102, mean=-0.003),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=27.0, max=27.0, mean=27.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=-1.831, max=0.675, mean=-0.785),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=-1.515, max=1.025, mean=-0.477)},\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m 2020-11-03 12:36:41,642\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((200, 778), dtype=float32, min=-0.069, max=0.069, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'action_logp': np.ndarray((200,), dtype=float32, min=-590.546, max=-512.076, mean=-550.871),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'action_prob': np.ndarray((200,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'actions': np.ndarray((200, 389), dtype=float32, min=-4.172, max=4.297, mean=-0.004),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'advantages': np.ndarray((200,), dtype=float32, min=-0.847, max=1.568, mean=-0.238),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'dones': np.ndarray((200,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'eps_id': np.ndarray((200,), dtype=int64, min=1327926440.0, max=1661857128.0, mean=1494891784.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'infos': np.ndarray((200,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'new_obs': np.ndarray((200, 389), dtype=float32, min=1.8, max=5101.984, mean=92.98),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'obs': np.ndarray((200, 389), dtype=float32, min=1.8, max=1000000.0, mean=118.623),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'prev_actions': np.ndarray((200, 389), dtype=float32, min=-4.172, max=4.297, mean=-0.004),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'prev_rewards': np.ndarray((200,), dtype=float32, min=-0.076, max=0.103, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'rewards': np.ndarray((200,), dtype=float32, min=-0.076, max=0.103, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             't': np.ndarray((200,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'unroll_id': np.ndarray((200,), dtype=int64, min=26.0, max=27.0, mean=26.5),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'value_targets': np.ndarray((200,), dtype=float32, min=-1.831, max=0.803, mean=-0.714),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'vf_preds': np.ndarray((200,), dtype=float32, min=-1.579, max=1.051, mean=-0.476)},\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m 2020-11-03 12:36:41,821\tINFO rollout_worker.py:577 -- Generating sample batch of size 200\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,202\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,217\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.794284, 'policy_loss': -0.010887966, 'vf_loss': 2.8045359, 'vf_explained_var': 0.049274962, 'kl': 0.0021209812, 'entropy': 552.14874, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,231\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.5577607, 'policy_loss': -0.2411551, 'vf_loss': 2.791983, 'vf_explained_var': 0.05350715, 'kl': 0.023108939, 'entropy': 552.2339, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,247\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.5307593, 'policy_loss': -0.2676135, 'vf_loss': 2.7791688, 'vf_explained_var': 0.057822723, 'kl': 0.06401356, 'entropy': 552.3222, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,262\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.5278022, 'policy_loss': -0.2708074, 'vf_loss': 2.7675393, 'vf_explained_var': 0.06185947, 'kl': 0.10356767, 'entropy': 552.3874, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,276\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.5194085, 'policy_loss': -0.27259877, 'vf_loss': 2.7537143, 'vf_explained_var': 0.06639389, 'kl': 0.12764306, 'entropy': 552.4172, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,289\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.5062206, 'policy_loss': -0.2733557, 'vf_loss': 2.7394779, 'vf_explained_var': 0.07132504, 'kl': 0.13366175, 'entropy': 552.41705, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,304\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.4911373, 'policy_loss': -0.2738144, 'vf_loss': 2.7271366, 'vf_explained_var': 0.07559407, 'kl': 0.12605065, 'entropy': 552.39545, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,319\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.4737935, 'policy_loss': -0.2741821, 'vf_loss': 2.7146091, 'vf_explained_var': 0.07983959, 'kl': 0.11122131, 'entropy': 552.36414, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,332\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.4554327, 'policy_loss': -0.2742458, 'vf_loss': 2.7013474, 'vf_explained_var': 0.08442438, 'kl': 0.0944374, 'entropy': 552.3281, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,346\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.4357865, 'policy_loss': -0.27403125, 'vf_loss': 2.6861622, 'vf_explained_var': 0.08966637, 'kl': 0.07885146, 'entropy': 552.29425, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,361\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.41734, 'policy_loss': -0.27400586, 'vf_loss': 2.6716864, 'vf_explained_var': 0.09479485, 'kl': 0.06553135, 'entropy': 552.2586, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,375\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.3990693, 'policy_loss': -0.27424505, 'vf_loss': 2.6568487, 'vf_explained_var': 0.10001328, 'kl': 0.054885596, 'entropy': 552.2316, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,389\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.3825064, 'policy_loss': -0.27357888, 'vf_loss': 2.6420581, 'vf_explained_var': 0.10503435, 'kl': 0.046757434, 'entropy': 552.2139, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,404\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.363735, 'policy_loss': -0.27410638, 'vf_loss': 2.6255748, 'vf_explained_var': 0.11079949, 'kl': 0.040888026, 'entropy': 552.209, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,419\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.346659, 'policy_loss': -0.27411187, 'vf_loss': 2.609849, 'vf_explained_var': 0.11636319, 'kl': 0.03640657, 'entropy': 552.20465, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,436\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.3301172, 'policy_loss': -0.27414182, 'vf_loss': 2.5943682, 'vf_explained_var': 0.12169895, 'kl': 0.032968927, 'entropy': 552.18866, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,453\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.313045, 'policy_loss': -0.2741771, 'vf_loss': 2.5781069, 'vf_explained_var': 0.1271597, 'kl': 0.03038396, 'entropy': 552.1754, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,469\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.2938218, 'policy_loss': -0.2741369, 'vf_loss': 2.5594487, 'vf_explained_var': 0.1333576, 'kl': 0.02836621, 'entropy': 552.16315, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,486\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.2771862, 'policy_loss': -0.27429202, 'vf_loss': 2.5434606, 'vf_explained_var': 0.1386196, 'kl': 0.026724458, 'entropy': 552.17365, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,500\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.2596335, 'policy_loss': -0.27389687, 'vf_loss': 2.5258362, 'vf_explained_var': 0.14441611, 'kl': 0.025647199, 'entropy': 552.1992, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,517\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.2407067, 'policy_loss': -0.27412415, 'vf_loss': 2.5073335, 'vf_explained_var': 0.1506807, 'kl': 0.024991402, 'entropy': 552.2264, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,532\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.2212067, 'policy_loss': -0.2742592, 'vf_loss': 2.4881227, 'vf_explained_var': 0.1572302, 'kl': 0.02447679, 'entropy': 552.25073, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,547\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.2039323, 'policy_loss': -0.27407947, 'vf_loss': 2.4708145, 'vf_explained_var': 0.16340245, 'kl': 0.023990706, 'entropy': 552.268, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,562\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.1819267, 'policy_loss': -0.2742771, 'vf_loss': 2.4491892, 'vf_explained_var': 0.17071687, 'kl': 0.023382008, 'entropy': 552.26434, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,576\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.162679, 'policy_loss': -0.2743688, 'vf_loss': 2.4301796, 'vf_explained_var': 0.17706245, 'kl': 0.022893542, 'entropy': 552.25287, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,591\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.1415827, 'policy_loss': -0.2744179, 'vf_loss': 2.4093134, 'vf_explained_var': 0.18421991, 'kl': 0.022291115, 'entropy': 552.2422, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,605\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.1198142, 'policy_loss': -0.27421793, 'vf_loss': 2.387562, 'vf_explained_var': 0.19172645, 'kl': 0.021565944, 'entropy': 552.2381, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,619\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.0986187, 'policy_loss': -0.27404678, 'vf_loss': 2.3664145, 'vf_explained_var': 0.198904, 'kl': 0.02083662, 'entropy': 552.25006, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,633\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.0777209, 'policy_loss': -0.27436993, 'vf_loss': 2.3459563, 'vf_explained_var': 0.20570923, 'kl': 0.02044869, 'entropy': 552.2646, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:37:10,646\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.0572128, 'policy_loss': -0.2741988, 'vf_loss': 2.3253624, 'vf_explained_var': 0.21251635, 'kl': 0.020163553, 'entropy': 552.276, 'entropy_coeff': 0.0, 'model': {}}\n",
      "2020-11-03 12:37:11,407\tWARNING util.py:139 -- The `fetch_result` operation took 0.514988899230957 seconds to complete, which may be a performance bottleneck.\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-37-10\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 6.7957666567495\n",
      "  episode_reward_mean: 2.7082438688039874\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 10\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.2760009765625\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020163552835583687\n",
      "        model: {}\n",
      "        policy_loss: -0.2741988003253937\n",
      "        total_loss: 2.0572128295898438\n",
      "        vf_explained_var: 0.21251635253429413\n",
      "        vf_loss: 2.32536244392395\n",
      "    num_steps_sampled: 1000\n",
      "    num_steps_trained: 1000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.923529411764704\n",
      "    ram_util_percent: 63.56470588235294\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15072678939490874\n",
      "    mean_env_wait_ms: 549.4479689338066\n",
      "    mean_inference_ms: 1.6601547126869611\n",
      "    mean_raw_obs_processing_ms: 1.880255151127343\n",
      "  time_since_restore: 138.63401412963867\n",
      "  time_this_iter_s: 55.01499104499817\n",
      "  time_total_s: 138.63401412963867\n",
      "  timers:\n",
      "    learn_throughput: 832.056\n",
      "    learn_time_ms: 600.921\n",
      "    load_throughput: 13719.833\n",
      "    load_time_ms: 36.444\n",
      "    sample_throughput: 7.287\n",
      "    sample_time_ms: 68616.027\n",
      "    update_time_ms: 4.515\n",
      "  timestamp: 1604403430\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 2\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:37:15,051\tWARNING util.py:139 -- The `process_trial` operation took 4.159084796905518 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:37:15,027\tINFO sampler.py:1223 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'info': {},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'obs': np.ndarray((389,), dtype=float64, min=9.15, max=1000000.0, mean=2697.555),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_action': np.ndarray((389,), dtype=float16, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_reward': 0.0,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:37:15,028\tINFO tf_run_builder.py:87 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:37:15,030\tINFO sampler.py:1269 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': ( np.ndarray((1, 389), dtype=float32, min=-3.321, max=2.763, mean=-0.039),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       { 'action_dist_inputs': np.ndarray((1, 778), dtype=float32, min=-0.035, max=0.034, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-556.921, max=-556.921, mean=-556.921),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=0.511, max=0.511, mean=0.511)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:37:15,645\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=9.12, max=2401.58, mean=130.622)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:37:15,645\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:37:15,645\tINFO sampler.py:800 -- Preprocessed obs: np.ndarray((389,), dtype=float64, min=9.12, max=2401.58, mean=130.622)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:37:15,646\tINFO sampler.py:805 -- Filtered obs: np.ndarray((389,), dtype=float64, min=9.12, max=2401.58, mean=130.622)\n",
      "2020-11-03 12:37:16,417\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 1.3651766777038574 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         138.634</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\"> 2.70824</td><td style=\"text-align: right;\">             6.79577</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "8), dtype=float32, min=-0.039, max=0.037, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-585.984, max=-519.309, mean=-551.281),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.324, max=3.886, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-0.9, max=3.715, mean=1.733),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=363009105.0, max=363009105.0, mean=363009105.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4565.635, mean=124.105),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.771),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.324, max=3.886, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=2.0, max=2.0, mean=2.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.015, max=4.398, mean=2.646),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=0.511, max=1.004, mean=0.913)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:38:19,824\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.039, max=0.037, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-585.984, max=-519.309, mean=-551.281),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.324, max=3.886, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-0.9, max=3.715, mean=1.733),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=363009105.0, max=363009105.0, mean=363009105.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4565.635, mean=124.105),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.771),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.324, max=3.886, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=2.0, max=2.0, mean=2.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.015, max=4.398, mean=2.646),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=0.511, max=1.004, mean=0.913)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:20,868\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-4.468, max=4.565, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.057, max=0.183, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.072),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.046, max=0.046, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-595.496, max=-517.41, mean=-550.826),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.468, max=4.565, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.359, max=2.347, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.072),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.468, max=4.565, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.057, max=0.183, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.409, max=4.398, mean=0.818),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=0.12, max=1.067, mean=0.678)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:20,873\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:20,883\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:20,921\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.3344944, 'policy_loss': -0.026397122, 'vf_loss': 2.360288, 'vf_explained_var': 0.20614316, 'kl': 0.0013409952, 'entropy': 552.30475, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:20,938\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.0728972, 'policy_loss': -0.26337096, 'vf_loss': 2.329767, 'vf_explained_var': 0.21449147, 'kl': 0.014446978, 'entropy': 552.3723, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:20,954\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.0350578, 'policy_loss': -0.28507242, 'vf_loss': 2.3026907, 'vf_explained_var': 0.22193289, 'kl': 0.03875449, 'entropy': 552.4477, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:20,971\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2.0177991, 'policy_loss': -0.28770888, 'vf_loss': 2.277425, 'vf_explained_var': 0.22842675, 'kl': 0.06240662, 'entropy': 552.5046, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:20,987\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.9905925, 'policy_loss': -0.28835604, 'vf_loss': 2.2443225, 'vf_explained_var': 0.23913886, 'kl': 0.076946646, 'entropy': 552.53705, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,005\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.9666187, 'policy_loss': -0.28892323, 'vf_loss': 2.219005, 'vf_explained_var': 0.24670626, 'kl': 0.081193134, 'entropy': 552.5427, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,022\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.9379941, 'policy_loss': -0.28909317, 'vf_loss': 2.1920784, 'vf_explained_var': 0.25464198, 'kl': 0.07779773, 'entropy': 552.52985, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,038\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.9130222, 'policy_loss': -0.289397, 'vf_loss': 2.1707013, 'vf_explained_var': 0.26218095, 'kl': 0.07048481, 'entropy': 552.5074, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,056\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.8824888, 'policy_loss': -0.289313, 'vf_loss': 2.1438978, 'vf_explained_var': 0.27113244, 'kl': 0.062009115, 'entropy': 552.48004, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,072\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.8507382, 'policy_loss': -0.28944156, 'vf_loss': 2.1158059, 'vf_explained_var': 0.2808438, 'kl': 0.054164063, 'entropy': 552.4553, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,087\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.8219877, 'policy_loss': -0.2891129, 'vf_loss': 2.0897942, 'vf_explained_var': 0.2896293, 'kl': 0.047347803, 'entropy': 552.4345, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,104\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.7928568, 'policy_loss': -0.28940696, 'vf_loss': 2.0634198, 'vf_explained_var': 0.29839846, 'kl': 0.04187556, 'entropy': 552.4161, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,119\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.7658726, 'policy_loss': -0.2895585, 'vf_loss': 2.0387397, 'vf_explained_var': 0.30684838, 'kl': 0.037092034, 'entropy': 552.4017, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,135\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.7353178, 'policy_loss': -0.2895757, 'vf_loss': 2.0099723, 'vf_explained_var': 0.31679264, 'kl': 0.033158798, 'entropy': 552.38495, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,151\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.7045779, 'policy_loss': -0.2895427, 'vf_loss': 1.980723, 'vf_explained_var': 0.3271841, 'kl': 0.029772012, 'entropy': 552.3722, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,170\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.6756877, 'policy_loss': -0.2895328, 'vf_loss': 1.9531709, 'vf_explained_var': 0.33671427, 'kl': 0.026776606, 'entropy': 552.36426, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,189\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.6517781, 'policy_loss': -0.2893112, 'vf_loss': 1.9301862, 'vf_explained_var': 0.3443605, 'kl': 0.024229193, 'entropy': 552.36255, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,208\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.624451, 'policy_loss': -0.28967002, 'vf_loss': 1.9041247, 'vf_explained_var': 0.3528967, 'kl': 0.022214249, 'entropy': 552.36084, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,227\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.5974213, 'policy_loss': -0.28961298, 'vf_loss': 1.8778216, 'vf_explained_var': 0.36141005, 'kl': 0.020472782, 'entropy': 552.3592, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,246\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.5667014, 'policy_loss': -0.28956577, 'vf_loss': 1.8477062, 'vf_explained_var': 0.37138247, 'kl': 0.0190244, 'entropy': 552.35675, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,264\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.5359124, 'policy_loss': -0.28954908, 'vf_loss': 1.8173972, 'vf_explained_var': 0.3819704, 'kl': 0.017920239, 'entropy': 552.35724, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,283\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.5093938, 'policy_loss': -0.28946862, 'vf_loss': 1.7911927, 'vf_explained_var': 0.3919351, 'kl': 0.017044105, 'entropy': 552.3582, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,299\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.4814574, 'policy_loss': -0.28924152, 'vf_loss': 1.7633232, 'vf_explained_var': 0.4013079, 'kl': 0.016390765, 'entropy': 552.35913, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,316\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.4524635, 'policy_loss': -0.289451, 'vf_loss': 1.7347511, 'vf_explained_var': 0.40992418, 'kl': 0.015918402, 'entropy': 552.36127, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,332\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.4269542, 'policy_loss': -0.2891799, 'vf_loss': 1.709047, 'vf_explained_var': 0.41848302, 'kl': 0.01574912, 'entropy': 552.3643, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,349\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.398097, 'policy_loss': -0.28964782, 'vf_loss': 1.6806186, 'vf_explained_var': 0.42847404, 'kl': 0.015836393, 'entropy': 552.3634, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,366\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.367395, 'policy_loss': -0.28932714, 'vf_loss': 1.6495491, 'vf_explained_var': 0.43921873, 'kl': 0.015940055, 'entropy': 552.3601, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,384\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.3436822, 'policy_loss': -0.2895688, 'vf_loss': 1.626082, 'vf_explained_var': 0.44694495, 'kl': 0.015931034, 'entropy': 552.35834, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,408\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.3199612, 'policy_loss': -0.28955254, 'vf_loss': 1.6024122, 'vf_explained_var': 0.45475784, 'kl': 0.015781472, 'entropy': 552.3475, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:38:21,431\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.291439, 'policy_loss': -0.28880307, 'vf_loss': 1.5732317, 'vf_explained_var': 0.46489525, 'kl': 0.015578645, 'entropy': 552.3296, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-38-21\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 6.829419213597563\n",
      "  episode_reward_mean: 2.745093688024018\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 15\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.32958984375\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015578645281493664\n",
      "        model: {}\n",
      "        policy_loss: -0.2888030707836151\n",
      "        total_loss: 1.2914390563964844\n",
      "        vf_explained_var: 0.46489524841308594\n",
      "        vf_loss: 1.5732316970825195\n",
      "    num_steps_sampled: 1500\n",
      "    num_steps_trained: 1500\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.18799999999999\n",
      "    ram_util_percent: 70.333\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15927933995802046\n",
      "    mean_env_wait_ms: 559.24941491773\n",
      "    mean_inference_ms: 1.6435721172259747\n",
      "    mean_raw_obs_processing_ms: 2.032012808557681\n",
      "  time_since_restore: 205.10674715042114\n",
      "  time_this_iter_s: 66.47273302078247\n",
      "  time_total_s: 205.10674715042114\n",
      "  timers:\n",
      "    learn_throughput: 857.212\n",
      "    learn_time_ms: 583.286\n",
      "    load_throughput: 12341.052\n",
      "    load_time_ms: 40.515\n",
      "    sample_throughput: 7.388\n",
      "    sample_time_ms: 67678.791\n",
      "    update_time_ms: 7.451\n",
      "  timestamp: 1604403501\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1500\n",
      "  training_iteration: 3\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:38:26,705\tWARNING util.py:139 -- The `process_trial` operation took 4.693396806716919 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:38:26,676\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:38:28,231\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 1.5244379043579102 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         205.107</td><td style=\"text-align: right;\">1500</td><td style=\"text-align: right;\"> 2.74509</td><td style=\"text-align: right;\">             6.82942</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.063, max=0.108, mean=0.005),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.063, max=0.108, mean=0.005),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=29.0, max=29.0, mean=29.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=-1.409, max=1.096, mean=-0.426),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=-1.486, max=1.025, mean=-0.46)},\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m 2020-11-03 12:38:40,283\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((200, 778), dtype=float32, min=-0.069, max=0.069, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'action_logp': np.ndarray((200,), dtype=float32, min=-592.296, max=-522.177, mean=-552.663),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'action_prob': np.ndarray((200,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'actions': np.ndarray((200, 389), dtype=float32, min=-4.169, max=4.509, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'advantages': np.ndarray((200,), dtype=float32, min=-0.586, max=1.845, mean=0.036),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'dones': np.ndarray((200,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'eps_id': np.ndarray((200,), dtype=int64, min=63373382.0, max=1116252312.0, mean=589812847.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'infos': np.ndarray((200,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'new_obs': np.ndarray((200, 389), dtype=float32, min=1.8, max=5139.966, mean=92.602),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'obs': np.ndarray((200, 389), dtype=float32, min=1.8, max=1000000.0, mean=118.246),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'prev_actions': np.ndarray((200, 389), dtype=float32, min=-4.169, max=4.509, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'prev_rewards': np.ndarray((200,), dtype=float32, min=-0.065, max=0.108, mean=0.005),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'rewards': np.ndarray((200,), dtype=float32, min=-0.065, max=0.108, mean=0.005),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             't': np.ndarray((200,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'unroll_id': np.ndarray((200,), dtype=int64, min=28.0, max=29.0, mean=28.5),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'value_targets': np.ndarray((200,), dtype=float32, min=-1.463, max=1.096, mean=-0.442),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'vf_preds': np.ndarray((200,), dtype=float32, min=-1.486, max=1.203, mean=-0.479)},\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m 2020-11-03 12:38:40,570\tINFO rollout_worker.py:577 -- Generating sample batch of size 200\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,257\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,258\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,259\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,259\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,259\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,259\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,260\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,260\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,260\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,260\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,260\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,260\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,262\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,280\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.5140225, 'policy_loss': 0.021658368, 'vf_loss': 1.4918274, 'vf_explained_var': 0.46645227, 'kl': 0.0011924303, 'entropy': 552.33966, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,295\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.268368, 'policy_loss': -0.19919927, 'vf_loss': 1.462825, 'vf_explained_var': 0.47671226, 'kl': 0.010538458, 'entropy': 552.3847, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,310\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.2150759, 'policy_loss': -0.23416226, 'vf_loss': 1.4359761, 'vf_explained_var': 0.4856559, 'kl': 0.029471168, 'entropy': 552.425, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,326\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.1960834, 'policy_loss': -0.23674794, 'vf_loss': 1.4106723, 'vf_explained_var': 0.49465287, 'kl': 0.04924223, 'entropy': 552.4585, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,342\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.1782608, 'policy_loss': -0.23761927, 'vf_loss': 1.3873283, 'vf_explained_var': 0.5027918, 'kl': 0.06344816, 'entropy': 552.4747, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,356\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.161142, 'policy_loss': -0.23820038, 'vf_loss': 1.367787, 'vf_explained_var': 0.5107261, 'kl': 0.07012292, 'entropy': 552.46564, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,372\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.1358622, 'policy_loss': -0.23851275, 'vf_loss': 1.3428589, 'vf_explained_var': 0.5195698, 'kl': 0.07003591, 'entropy': 552.4467, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,387\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.1095895, 'policy_loss': -0.23848371, 'vf_loss': 1.3187238, 'vf_explained_var': 0.5294862, 'kl': 0.06522066, 'entropy': 552.42426, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,402\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.084675, 'policy_loss': -0.23866284, 'vf_loss': 1.2968179, 'vf_explained_var': 0.5373358, 'kl': 0.05893294, 'entropy': 552.4039, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,417\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.0562327, 'policy_loss': -0.23856139, 'vf_loss': 1.2711749, 'vf_explained_var': 0.5459582, 'kl': 0.052486748, 'entropy': 552.3868, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,431\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.0292197, 'policy_loss': -0.23844288, 'vf_loss': 1.2464736, 'vf_explained_var': 0.55447817, 'kl': 0.04708658, 'entropy': 552.3722, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,446\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1.0045735, 'policy_loss': -0.23861934, 'vf_loss': 1.2240973, 'vf_explained_var': 0.56230515, 'kl': 0.042434584, 'entropy': 552.3603, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,461\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.9823925, 'policy_loss': -0.23868664, 'vf_loss': 1.2037328, 'vf_explained_var': 0.5695945, 'kl': 0.038546994, 'entropy': 552.3557, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,475\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.9565587, 'policy_loss': -0.23870333, 'vf_loss': 1.1796046, 'vf_explained_var': 0.57807285, 'kl': 0.03479388, 'entropy': 552.3582, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,491\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.93794346, 'policy_loss': -0.23871963, 'vf_loss': 1.1624999, 'vf_explained_var': 0.5840365, 'kl': 0.031473663, 'entropy': 552.3657, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,513\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.9149483, 'policy_loss': -0.23876274, 'vf_loss': 1.1408776, 'vf_explained_var': 0.5911922, 'kl': 0.028518572, 'entropy': 552.37897, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,536\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.8879612, 'policy_loss': -0.23867768, 'vf_loss': 1.1149294, 'vf_explained_var': 0.6006792, 'kl': 0.026021043, 'entropy': 552.3892, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,558\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.86955243, 'policy_loss': -0.23868056, 'vf_loss': 1.0974561, 'vf_explained_var': 0.6068558, 'kl': 0.023948887, 'entropy': 552.4019, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,585\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.8474359, 'policy_loss': -0.23873526, 'vf_loss': 1.076187, 'vf_explained_var': 0.61529416, 'kl': 0.022186741, 'entropy': 552.41205, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,602\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.8255965, 'policy_loss': -0.23857737, 'vf_loss': 1.0548335, 'vf_explained_var': 0.6230117, 'kl': 0.020756157, 'entropy': 552.41833, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,619\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.80264306, 'policy_loss': -0.23869334, 'vf_loss': 1.0325998, 'vf_explained_var': 0.63073057, 'kl': 0.019414721, 'entropy': 552.4238, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,636\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.7858553, 'policy_loss': -0.23855984, 'vf_loss': 1.0161457, 'vf_explained_var': 0.6370569, 'kl': 0.01837643, 'entropy': 552.4261, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,651\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.7705531, 'policy_loss': -0.23864616, 'vf_loss': 1.0012945, 'vf_explained_var': 0.6448346, 'kl': 0.017566098, 'entropy': 552.4245, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,665\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.7578802, 'policy_loss': -0.2386627, 'vf_loss': 0.9888423, 'vf_explained_var': 0.649769, 'kl': 0.017112302, 'entropy': 552.4149, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,680\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.7308099, 'policy_loss': -0.23864226, 'vf_loss': 0.96190804, 'vf_explained_var': 0.6573647, 'kl': 0.016764821, 'entropy': 552.40247, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,696\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.7097864, 'policy_loss': -0.23872463, 'vf_loss': 0.94116765, 'vf_explained_var': 0.66332847, 'kl': 0.016318472, 'entropy': 552.3918, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,713\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.7005003, 'policy_loss': -0.23867564, 'vf_loss': 0.93208694, 'vf_explained_var': 0.66688555, 'kl': 0.015753325, 'entropy': 552.3818, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,729\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.68610483, 'policy_loss': -0.23861194, 'vf_loss': 0.9178316, 'vf_explained_var': 0.6708789, 'kl': 0.015300547, 'entropy': 552.3795, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,747\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.6677187, 'policy_loss': -0.23862685, 'vf_loss': 0.8996334, 'vf_explained_var': 0.6787848, 'kl': 0.014915906, 'entropy': 552.37463, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:39:25,765\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.6519552, 'policy_loss': -0.23847891, 'vf_loss': 0.88388747, 'vf_explained_var': 0.6844058, 'kl': 0.014548242, 'entropy': 552.36945, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-39-25\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 6.977550906041188\n",
      "  episode_reward_mean: 2.794662518841424\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 20\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.3694458007812\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014548242092132568\n",
      "        model: {}\n",
      "        policy_loss: -0.2384789139032364\n",
      "        total_loss: 0.6519551873207092\n",
      "        vf_explained_var: 0.6844058036804199\n",
      "        vf_loss: 0.8838874697685242\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 2000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.82608695652173\n",
      "    ram_util_percent: 67.25434782608696\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1621936570322799\n",
      "    mean_env_wait_ms: 564.0963699095973\n",
      "    mean_inference_ms: 1.6187389666897343\n",
      "    mean_raw_obs_processing_ms: 2.0949473968965178\n",
      "  time_since_restore: 264.2111291885376\n",
      "  time_this_iter_s: 59.104382038116455\n",
      "  time_total_s: 264.2111291885376\n",
      "  timers:\n",
      "    learn_throughput: 887.672\n",
      "    learn_time_ms: 563.271\n",
      "    load_throughput: 15627.617\n",
      "    load_time_ms: 31.995\n",
      "    sample_throughput: 7.645\n",
      "    sample_time_ms: 65404.132\n",
      "    update_time_ms: 6.283\n",
      "  timestamp: 1604403565\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 4\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:39:30,747\tWARNING util.py:139 -- The `process_trial` operation took 4.061963081359863 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:39:30,716\tINFO sampler.py:1223 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'info': {},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'obs': np.ndarray((389,), dtype=float64, min=9.15, max=1000000.0, mean=2697.555),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_action': np.ndarray((389,), dtype=float16, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_reward': 0.0,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:39:30,716\tINFO tf_run_builder.py:87 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:39:30,718\tINFO sampler.py:1269 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': ( np.ndarray((1, 389), dtype=float32, min=-2.738, max=2.866, mean=-0.078),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       { 'action_dist_inputs': np.ndarray((1, 778), dtype=float32, min=-0.04, max=0.049, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-541.081, max=-541.081, mean=-541.081),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=0.885, max=0.885, mean=0.885)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:39:31,276\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=9.12, max=2401.58, mean=132.125)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:39:31,277\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:39:31,277\tINFO sampler.py:800 -- Preprocessed obs: np.ndarray((389,), dtype=float64, min=9.12, max=2401.58, mean=132.125)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:39:31,277\tINFO sampler.py:805 -- Filtered obs: np.ndarray((389,), dtype=float64, min=9.12, max=2401.58, mean=132.125)\n",
      "2020-11-03 12:39:31,945\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 1.196390151977539 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         264.211</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\"> 2.79466</td><td style=\"text-align: right;\">             6.97755</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:40:23,687\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.40747467, 'policy_loss': -0.24818248, 'vf_loss': 0.6420967, 'vf_explained_var': 0.7845996, 'kl': 0.030134395, 'entropy': 552.36755, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:40:23,702\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.3979961, 'policy_loss': -0.24817999, 'vf_loss': 0.6335116, 'vf_explained_var': 0.7884708, 'kl': 0.0281434, 'entropy': 552.3794, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:40:23,718\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.3876141, 'policy_loss': -0.24816005, 'vf_loss': 0.6239838, 'vf_explained_var': 0.7913253, 'kl': 0.026200742, 'entropy': 552.3897, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:40:23,734\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.3754872, 'policy_loss': -0.24823613, 'vf_loss': 0.6127001, 'vf_explained_var': 0.7958319, 'kl': 0.024496078, 'entropy': 552.3963, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:40:23,749\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.36212465, 'policy_loss': -0.2481948, 'vf_loss': 0.600007, 'vf_explained_var': 0.7998479, 'kl': 0.022916585, 'entropy': 552.4014, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:40:23,764\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.34619436, 'policy_loss': -0.24804465, 'vf_loss': 0.5845317, 'vf_explained_var': 0.80390793, 'kl': 0.021571705, 'entropy': 552.4071, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:40:23,779\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.3427532, 'policy_loss': -0.24714553, 'vf_loss': 0.5805462, 'vf_explained_var': 0.8063504, 'kl': 0.020783378, 'entropy': 552.4165, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:40:23,794\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.33018023, 'policy_loss': -0.24808772, 'vf_loss': 0.56918424, 'vf_explained_var': 0.8107508, 'kl': 0.02018603, 'entropy': 552.41754, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:40:23,809\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.31993017, 'policy_loss': -0.24783923, 'vf_loss': 0.5589308, 'vf_explained_var': 0.813698, 'kl': 0.019641196, 'entropy': 552.4091, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:40:23,823\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.30689874, 'policy_loss': -0.24823059, 'vf_loss': 0.5464577, 'vf_explained_var': 0.8165117, 'kl': 0.019270433, 'entropy': 552.39545, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:40:23,837\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.30112672, 'policy_loss': -0.24808423, 'vf_loss': 0.540571, 'vf_explained_var': 0.81838554, 'kl': 0.019199962, 'entropy': 552.3875, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:40:23,852\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.28992167, 'policy_loss': -0.24812001, 'vf_loss': 0.5294114, 'vf_explained_var': 0.823217, 'kl': 0.019178495, 'entropy': 552.38873, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:40:23,866\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.27941364, 'policy_loss': -0.24768834, 'vf_loss': 0.5185259, 'vf_explained_var': 0.8270443, 'kl': 0.019057833, 'entropy': 552.3957, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-40-23\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.010297550829655\n",
      "  episode_reward_mean: 2.8096640465102496\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 25\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.3956909179688\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019057832658290863\n",
      "        model: {}\n",
      "        policy_loss: -0.24768833816051483\n",
      "        total_loss: 0.279413640499115\n",
      "        vf_explained_var: 0.8270443081855774\n",
      "        vf_loss: 0.5185258984565735\n",
      "    num_steps_sampled: 2500\n",
      "    num_steps_trained: 2500\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.04634146341465\n",
      "    ram_util_percent: 70.41951219512195\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16267711454266795\n",
      "    mean_env_wait_ms: 564.6086298241488\n",
      "    mean_inference_ms: 1.5910802657663234\n",
      "    mean_raw_obs_processing_ms: 2.1205975460360555\n",
      "  time_since_restore: 317.3756239414215\n",
      "  time_this_iter_s: 53.16449475288391\n",
      "  time_total_s: 317.3756239414215\n",
      "  timers:\n",
      "    learn_throughput: 923.782\n",
      "    learn_time_ms: 541.253\n",
      "    load_throughput: 19155.537\n",
      "    load_time_ms: 26.102\n",
      "    sample_throughput: 7.954\n",
      "    sample_time_ms: 62862.581\n",
      "    update_time_ms: 5.569\n",
      "  timestamp: 1604403623\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2500\n",
      "  training_iteration: 5\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m 2020-11-03 12:40:27,582\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.069, max=0.069, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-586.873, max=-514.548, mean=-549.668),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.041, max=4.0, mean=-0.006),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-0.581, max=1.671, mean=-0.106),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=299929471.0, max=299929471.0, mean=299929471.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=1.8, max=5078.715, mean=93.165),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=1.8, max=1000000.0, mean=118.726),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.041, max=4.0, mean=-0.005),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.07, max=0.104, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.07, max=0.104, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=31.0, max=31.0, mean=31.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=-1.611, max=0.905, mean=-0.599),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=-1.503, max=1.195, mean=-0.493)},\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m 2020-11-03 12:40:27,737\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((200, 778), dtype=float32, min=-0.069, max=0.069, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'action_logp': np.ndarray((200,), dtype=float32, min=-603.636, max=-514.548, mean=-551.188),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'action_prob': np.ndarray((200,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'actions': np.ndarray((200, 389), dtype=float32, min=-4.467, max=4.0, mean=-0.003),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'advantages': np.ndarray((200,), dtype=float32, min=-0.581, max=1.857, mean=-0.017),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'dones': np.ndarray((200,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'eps_id': np.ndarray((200,), dtype=int64, min=299929471.0, max=398759604.0, mean=349344537.5),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'infos': np.ndarray((200,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'new_obs': np.ndarray((200, 389), dtype=float32, min=1.8, max=5078.715, mean=92.96),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'obs': np.ndarray((200, 389), dtype=float32, min=1.8, max=1000000.0, mean=118.559),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'prev_actions': np.ndarray((200, 389), dtype=float32, min=-4.467, max=4.0, mean=-0.003),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'prev_rewards': np.ndarray((200,), dtype=float32, min=-0.07, max=0.11, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'rewards': np.ndarray((200,), dtype=float32, min=-0.07, max=0.11, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             't': np.ndarray((200,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'unroll_id': np.ndarray((200,), dtype=int64, min=30.0, max=31.0, mean=30.5),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'value_targets': np.ndarray((200,), dtype=float32, min=-1.611, max=1.108, mean=-0.519),\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m             'vf_preds': np.ndarray((200,), dtype=float32, min=-1.503, max=1.195, mean=-0.502)},\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29372)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:27,963\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m { 'inputs': [ np.ndarray((4000, 389), dtype=float32, min=-4.873, max=4.653, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m               np.ndarray((4000,), dtype=float32, min=-0.107, max=0.11, mean=-0.02),\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m               np.ndarray((4000, 389), dtype=float32, min=1.8, max=1000000.0, mean=120.622),\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m               np.ndarray((4000, 778), dtype=float32, min=-0.073, max=0.072, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m               np.ndarray((4000,), dtype=float32, min=-605.651, max=-505.342, mean=-552.055),\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m               np.ndarray((4000, 389), dtype=float32, min=-4.873, max=4.653, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m               np.ndarray((4000,), dtype=float32, min=-4.76, max=7.433, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m               np.ndarray((4000, 389), dtype=float32, min=1.8, max=1000000.0, mean=120.622),\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m               np.ndarray((4000, 389), dtype=float32, min=-4.873, max=4.653, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m               np.ndarray((4000,), dtype=float32, min=-0.107, max=0.11, mean=-0.02),\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m               np.ndarray((4000,), dtype=float32, min=-2.857, max=1.108, mean=-1.162),\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m               np.ndarray((4000,), dtype=float32, min=-2.458, max=1.203, mean=-1.105)],\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:27,964\tINFO multi_gpu_impl.py:188 -- Divided 4000 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:28,053\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:28,194\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.11680895, 'policy_loss': 0.026704503, 'vf_loss': 0.0643284, 'vf_explained_var': 0.91388273, 'kl': 0.038186733, 'entropy': 552.0077, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:28,321\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.036905438, 'policy_loss': -0.15411161, 'vf_loss': 0.063704774, 'vf_explained_var': 0.9148852, 'kl': 0.07926135, 'entropy': 552.07605, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:28,449\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.074668266, 'policy_loss': -0.18555444, 'vf_loss': 0.06308358, 'vf_explained_var': 0.9153462, 'kl': 0.07081865, 'entropy': 552.0956, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:28,576\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.089189634, 'policy_loss': -0.19548002, 'vf_loss': 0.06254742, 'vf_explained_var': 0.91633254, 'kl': 0.064804405, 'entropy': 552.1129, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:28,705\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10164989, 'policy_loss': -0.20321414, 'vf_loss': 0.06101852, 'vf_explained_var': 0.9196372, 'kl': 0.06006779, 'entropy': 552.0862, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:28,840\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.107204214, 'policy_loss': -0.20640473, 'vf_loss': 0.060353596, 'vf_explained_var': 0.9192182, 'kl': 0.057551015, 'entropy': 552.0717, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:28,962\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.110526085, 'policy_loss': -0.20901711, 'vf_loss': 0.06192373, 'vf_explained_var': 0.91696477, 'kl': 0.054173782, 'entropy': 552.07355, 'entropy_coeff': 0.0, 'model': {}}\n",
      "2020-11-03 12:40:29,179\tWARNING util.py:139 -- The `process_trial` operation took 4.497689962387085 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:29,107\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12125678, 'policy_loss': -0.2120164, 'vf_loss': 0.05706125, 'vf_explained_var': 0.92358625, 'kl': 0.049923535, 'entropy': 552.1118, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:40:29,145\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:29,251\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.114523485, 'policy_loss': -0.20935816, 'vf_loss': 0.061337348, 'vf_explained_var': 0.91808045, 'kl': 0.049625665, 'entropy': 552.1002, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:29,411\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.119505234, 'policy_loss': -0.21189016, 'vf_loss': 0.06001574, 'vf_explained_var': 0.9199182, 'kl': 0.047954325, 'entropy': 552.06757, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:29,572\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.122552015, 'policy_loss': -0.21229893, 'vf_loss': 0.056970198, 'vf_explained_var': 0.92368597, 'kl': 0.048558068, 'entropy': 552.0249, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:29,749\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12139023, 'policy_loss': -0.21166934, 'vf_loss': 0.058412626, 'vf_explained_var': 0.92178, 'kl': 0.04720965, 'entropy': 552.077, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:29,934\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12748832, 'policy_loss': -0.21572079, 'vf_loss': 0.057758387, 'vf_explained_var': 0.9238063, 'kl': 0.04514678, 'entropy': 552.1231, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:30,144\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12968652, 'policy_loss': -0.21609169, 'vf_loss': 0.057424363, 'vf_explained_var': 0.92405146, 'kl': 0.042934537, 'entropy': 552.081, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:30,312\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13190307, 'policy_loss': -0.21556674, 'vf_loss': 0.056274183, 'vf_explained_var': 0.92461604, 'kl': 0.04057699, 'entropy': 552.0698, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:30,504\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12949364, 'policy_loss': -0.21687949, 'vf_loss': 0.060741108, 'vf_explained_var': 0.919949, 'kl': 0.039473694, 'entropy': 552.07056, 'entropy_coeff': 0.0, 'model': {}}\n",
      "2020-11-03 12:40:30,602\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 1.4210238456726074 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         317.376</td><td style=\"text-align: right;\">2500</td><td style=\"text-align: right;\"> 2.80966</td><td style=\"text-align: right;\">              7.0103</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13090378, 'policy_loss': -0.2174029, 'vf_loss': 0.060464263, 'vf_explained_var': 0.9190652, 'kl': 0.038570173, 'entropy': 552.04474, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:30,847\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13257928, 'policy_loss': -0.2167546, 'vf_loss': 0.058744006, 'vf_explained_var': 0.9221588, 'kl': 0.037676044, 'entropy': 552.05505, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:30,994\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13496867, 'policy_loss': -0.2168062, 'vf_loss': 0.05633052, 'vf_explained_var': 0.9246225, 'kl': 0.03778816, 'entropy': 552.05133, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:31,145\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13750102, 'policy_loss': -0.21781448, 'vf_loss': 0.054967985, 'vf_explained_var': 0.9266035, 'kl': 0.037548833, 'entropy': 552.0723, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:31,306\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13590042, 'policy_loss': -0.21615176, 'vf_loss': 0.0553078, 'vf_explained_var': 0.9264924, 'kl': 0.036953345, 'entropy': 552.0251, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:31,458\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13717096, 'policy_loss': -0.21753386, 'vf_loss': 0.05494983, 'vf_explained_var': 0.92685133, 'kl': 0.037648994, 'entropy': 552.08905, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:31,599\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13628401, 'policy_loss': -0.21509674, 'vf_loss': 0.053253572, 'vf_explained_var': 0.92925507, 'kl': 0.03786541, 'entropy': 552.0541, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:31,750\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13901633, 'policy_loss': -0.21668096, 'vf_loss': 0.05265705, 'vf_explained_var': 0.9296763, 'kl': 0.03704827, 'entropy': 552.0767, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:31,891\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14032689, 'policy_loss': -0.2169575, 'vf_loss': 0.05203604, 'vf_explained_var': 0.93044066, 'kl': 0.03643637, 'entropy': 552.0843, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:32,031\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14198588, 'policy_loss': -0.21865186, 'vf_loss': 0.052716564, 'vf_explained_var': 0.92998075, 'kl': 0.035480674, 'entropy': 552.0891, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:32,179\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14337614, 'policy_loss': -0.21853009, 'vf_loss': 0.052011732, 'vf_explained_var': 0.93030626, 'kl': 0.03428478, 'entropy': 552.0792, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:32,323\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14364721, 'policy_loss': -0.21770145, 'vf_loss': 0.051271684, 'vf_explained_var': 0.93099284, 'kl': 0.033751935, 'entropy': 552.05927, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:32,475\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1459667, 'policy_loss': -0.2195359, 'vf_loss': 0.05111513, 'vf_explained_var': 0.93146706, 'kl': 0.03326526, 'entropy': 552.0449, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29371)\u001b[0m 2020-11-03 12:40:32,636\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14635167, 'policy_loss': -0.2195468, 'vf_loss': 0.05108707, 'vf_explained_var': 0.93290675, 'kl': 0.032752648, 'entropy': 552.04504, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,345\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-4.94, max=5.034, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.054, max=0.183, mean=0.027),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=129.744),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.057, max=0.056, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-592.297, max=-507.341, mean=-552.639),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.94, max=5.034, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-3.17, max=3.843, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=129.744),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.94, max=5.034, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.054, max=0.183, mean=0.027),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.34, max=4.431, mean=0.794),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.159, max=3.015, mean=0.828)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,345\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,346\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,359\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.5355339, 'policy_loss': -0.014228187, 'vf_loss': 0.5493972, 'vf_explained_var': 0.80878717, 'kl': 0.00081079727, 'entropy': 552.41364, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,369\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.33254024, 'policy_loss': -0.19267114, 'vf_loss': 0.5217293, 'vf_explained_var': 0.8188407, 'kl': 0.0077379695, 'entropy': 552.44824, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,380\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.29740024, 'policy_loss': -0.21878807, 'vf_loss': 0.5077235, 'vf_explained_var': 0.8236551, 'kl': 0.018810594, 'entropy': 552.48016, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,391\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.2847651, 'policy_loss': -0.22568543, 'vf_loss': 0.49693146, 'vf_explained_var': 0.82750064, 'kl': 0.030042341, 'entropy': 552.5246, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,402\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.27644512, 'policy_loss': -0.22881408, 'vf_loss': 0.48752984, 'vf_explained_var': 0.8306268, 'kl': 0.039398547, 'entropy': 552.55927, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,413\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.2717249, 'policy_loss': -0.22998087, 'vf_loss': 0.48123503, 'vf_explained_var': 0.83376116, 'kl': 0.04549047, 'entropy': 552.58014, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,424\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.26171622, 'policy_loss': -0.23059078, 'vf_loss': 0.47072053, 'vf_explained_var': 0.8377061, 'kl': 0.04797004, 'entropy': 552.58887, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,442\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.25451943, 'policy_loss': -0.23097111, 'vf_loss': 0.46389958, 'vf_explained_var': 0.83902377, 'kl': 0.047979902, 'entropy': 552.5826, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,456\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.24349822, 'policy_loss': -0.231216, 'vf_loss': 0.45387205, 'vf_explained_var': 0.8424475, 'kl': 0.046315923, 'entropy': 552.5649, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,468\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.22887377, 'policy_loss': -0.23130326, 'vf_loss': 0.44040632, 'vf_explained_var': 0.84716624, 'kl': 0.04393484, 'entropy': 552.5469, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,480\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.22173683, 'policy_loss': -0.23141289, 'vf_loss': 0.43460524, 'vf_explained_var': 0.84903926, 'kl': 0.041209947, 'entropy': 552.5289, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,491\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.21677686, 'policy_loss': -0.2315783, 'vf_loss': 0.4311246, 'vf_explained_var': 0.85030556, 'kl': 0.038290173, 'entropy': 552.5125, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,501\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.21231437, 'policy_loss': -0.23158753, 'vf_loss': 0.42802182, 'vf_explained_var': 0.8511924, 'kl': 0.035288997, 'entropy': 552.50055, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,512\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.20700496, 'policy_loss': -0.23131536, 'vf_loss': 0.4237319, 'vf_explained_var': 0.8526575, 'kl': 0.03241873, 'entropy': 552.49, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,524\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.20233662, 'policy_loss': -0.23164119, 'vf_loss': 0.4205533, 'vf_explained_var': 0.8545247, 'kl': 0.029832257, 'entropy': 552.4782, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,535\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.19433646, 'policy_loss': -0.23165917, 'vf_loss': 0.4136255, 'vf_explained_var': 0.8568037, 'kl': 0.027489146, 'entropy': 552.46893, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,546\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.18895943, 'policy_loss': -0.23165101, 'vf_loss': 0.4091922, 'vf_explained_var': 0.85772973, 'kl': 0.025373802, 'entropy': 552.4633, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,558\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.18640894, 'policy_loss': -0.23151861, 'vf_loss': 0.4073212, 'vf_explained_var': 0.8584406, 'kl': 0.023569549, 'entropy': 552.4588, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,568\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.1838053, 'policy_loss': -0.23161985, 'vf_loss': 0.40552226, 'vf_explained_var': 0.8592, 'kl': 0.02200629, 'entropy': 552.4544, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,580\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.17625718, 'policy_loss': -0.2316262, 'vf_loss': 0.3986007, 'vf_explained_var': 0.8616085, 'kl': 0.020628164, 'entropy': 552.45, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,591\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.16488656, 'policy_loss': -0.23162492, 'vf_loss': 0.38780257, 'vf_explained_var': 0.8657522, 'kl': 0.019353174, 'entropy': 552.44806, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,603\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.16426355, 'policy_loss': -0.23163973, 'vf_loss': 0.38771644, 'vf_explained_var': 0.86538464, 'kl': 0.018192995, 'entropy': 552.44885, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,615\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.16053583, 'policy_loss': -0.23166482, 'vf_loss': 0.38448206, 'vf_explained_var': 0.8660515, 'kl': 0.017152332, 'entropy': 552.44745, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,626\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.15504183, 'policy_loss': -0.23165917, 'vf_loss': 0.3794292, 'vf_explained_var': 0.868316, 'kl': 0.016159587, 'entropy': 552.44403, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,638\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.15024357, 'policy_loss': -0.23162992, 'vf_loss': 0.37500405, 'vf_explained_var': 0.87011355, 'kl': 0.0152654825, 'entropy': 552.4404, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,651\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.14650643, 'policy_loss': -0.2316612, 'vf_loss': 0.37164804, 'vf_explained_var': 0.8705173, 'kl': 0.014487952, 'entropy': 552.44037, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,661\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.13931307, 'policy_loss': -0.23166525, 'vf_loss': 0.36476985, 'vf_explained_var': 0.8726167, 'kl': 0.01379659, 'entropy': 552.43787, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,673\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.13390414, 'policy_loss': -0.23167099, 'vf_loss': 0.3596511, 'vf_explained_var': 0.8752014, 'kl': 0.01316458, 'entropy': 552.4355, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,684\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.1312667, 'policy_loss': -0.23161274, 'vf_loss': 0.3572152, 'vf_explained_var': 0.87560695, 'kl': 0.012587274, 'entropy': 552.43427, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:06,695\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.12631194, 'policy_loss': -0.23161529, 'vf_loss': 0.35249165, 'vf_explained_var': 0.87692136, 'kl': 0.01207902, 'entropy': 552.4337, 'entropy_coeff': 0.0, 'model': {}}\n",
      "2020-11-03 12:41:08,415\tWARNING util.py:139 -- The `fetch_result` operation took 0.9139409065246582 seconds to complete, which may be a performance bottleneck.\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-41-06\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.010297550829655\n",
      "  episode_reward_mean: 2.7980756504711053\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 30\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.4337158203125\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012079020030796528\n",
      "        model: {}\n",
      "        policy_loss: -0.23161529004573822\n",
      "        total_loss: 0.12631194293498993\n",
      "        vf_explained_var: 0.8769213557243347\n",
      "        vf_loss: 0.3524916470050812\n",
      "    num_steps_sampled: 3000\n",
      "    num_steps_trained: 3000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.436666666666675\n",
      "    ram_util_percent: 75.53166666666667\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16146108189527583\n",
      "    mean_env_wait_ms: 559.3677244045156\n",
      "    mean_inference_ms: 1.557130645706556\n",
      "    mean_raw_obs_processing_ms: 2.1172571012353796\n",
      "  time_since_restore: 354.9372730255127\n",
      "  time_this_iter_s: 37.56164908409119\n",
      "  time_total_s: 354.9372730255127\n",
      "  timers:\n",
      "    learn_throughput: 981.754\n",
      "    learn_time_ms: 509.293\n",
      "    load_throughput: 22232.197\n",
      "    load_time_ms: 22.49\n",
      "    sample_throughput: 8.535\n",
      "    sample_time_ms: 58584.961\n",
      "    update_time_ms: 5.032\n",
      "  timestamp: 1604403666\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3000\n",
      "  training_iteration: 6\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:41:11,521\tWARNING util.py:139 -- The `process_trial` operation took 4.0196709632873535 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:41:12,204\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.6820220947265625 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 8.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         354.937</td><td style=\"text-align: right;\">3000</td><td style=\"text-align: right;\"> 2.79808</td><td style=\"text-align: right;\">              7.0103</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-535.418, max=-535.418, mean=-535.418),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=2.235, max=2.235, mean=2.235)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:41:29,777\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=7.15, max=2346.14, mean=110.196)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:41:29,777\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:41:45,817\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.077, max=0.065, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-579.613, max=-520.516, mean=-550.933),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.127, max=3.732, mean=-0.005),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-1.893, max=2.757, mean=0.339),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=484152000.0, max=484152000.0, mean=484152000.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4695.431, mean=124.187),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.782),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.127, max=3.732, mean=-0.005),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.186, mean=0.072),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.186, mean=0.072),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=6.0, max=6.0, mean=6.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.021, max=4.613, mean=2.794),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=1.17, max=3.38, mean=2.454)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:41:45,951\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.077, max=0.065, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-579.613, max=-520.516, mean=-550.933),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.127, max=3.732, mean=-0.005),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-1.893, max=2.757, mean=0.339),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=484152000.0, max=484152000.0, mean=484152000.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4695.431, mean=124.187),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.782),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.127, max=3.732, mean=-0.005),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.186, mean=0.072),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.186, mean=0.072),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=6.0, max=6.0, mean=6.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.021, max=4.613, mean=2.794),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=1.17, max=3.38, mean=2.454)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,428\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,429\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,429\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,429\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,429\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,429\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,429\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,429\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,429\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,429\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,429\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,429\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,431\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,442\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.44263527, 'policy_loss': -0.0048402646, 'vf_loss': 0.44710746, 'vf_explained_var': 0.85705906, 'kl': 0.00081796135, 'entropy': 552.44006, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,451\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.24639364, 'policy_loss': -0.18531418, 'vf_loss': 0.4282302, 'vf_explained_var': 0.8631852, 'kl': 0.0077280756, 'entropy': 552.4543, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,462\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.22603603, 'policy_loss': -0.20760606, 'vf_loss': 0.42433485, 'vf_explained_var': 0.8647545, 'kl': 0.020682842, 'entropy': 552.47076, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,472\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.21946709, 'policy_loss': -0.21465628, 'vf_loss': 0.41934285, 'vf_explained_var': 0.8667496, 'kl': 0.032845736, 'entropy': 552.488, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,483\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.20665972, 'policy_loss': -0.21646285, 'vf_loss': 0.40431347, 'vf_explained_var': 0.8717845, 'kl': 0.041797947, 'entropy': 552.5032, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,493\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.20083405, 'policy_loss': -0.21762542, 'vf_loss': 0.39745095, 'vf_explained_var': 0.8733721, 'kl': 0.04668552, 'entropy': 552.5075, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,502\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.19039796, 'policy_loss': -0.21805863, 'vf_loss': 0.3869598, 'vf_explained_var': 0.87654257, 'kl': 0.04777062, 'entropy': 552.5006, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,512\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.17961304, 'policy_loss': -0.2182589, 'vf_loss': 0.37716064, 'vf_explained_var': 0.8796831, 'kl': 0.046025082, 'entropy': 552.48724, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,523\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.16967185, 'policy_loss': -0.21844833, 'vf_loss': 0.36906207, 'vf_explained_var': 0.8821805, 'kl': 0.04235139, 'entropy': 552.46686, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,533\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.16464537, 'policy_loss': -0.21853834, 'vf_loss': 0.36583492, 'vf_explained_var': 0.88357025, 'kl': 0.038552944, 'entropy': 552.448, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,543\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.15055232, 'policy_loss': -0.21812718, 'vf_loss': 0.3525643, 'vf_explained_var': 0.88810927, 'kl': 0.035811555, 'entropy': 552.43604, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,554\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.1547613, 'policy_loss': -0.21865481, 'vf_loss': 0.3582629, 'vf_explained_var': 0.88602144, 'kl': 0.033673733, 'entropy': 552.4384, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,564\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.14343867, 'policy_loss': -0.21868944, 'vf_loss': 0.3478687, 'vf_explained_var': 0.88981897, 'kl': 0.031687483, 'entropy': 552.44586, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,574\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.14532854, 'policy_loss': -0.21883221, 'vf_loss': 0.35082492, 'vf_explained_var': 0.8889782, 'kl': 0.029635122, 'entropy': 552.44995, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,585\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.1371981, 'policy_loss': -0.21895136, 'vf_loss': 0.34374967, 'vf_explained_var': 0.8905153, 'kl': 0.027555153, 'entropy': 552.4495, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,595\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.13256963, 'policy_loss': -0.21899684, 'vf_loss': 0.340034, 'vf_explained_var': 0.8910239, 'kl': 0.025627643, 'entropy': 552.4467, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,605\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.13105623, 'policy_loss': -0.21895199, 'vf_loss': 0.33926475, 'vf_explained_var': 0.89151984, 'kl': 0.023874411, 'entropy': 552.44354, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,615\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.121175565, 'policy_loss': -0.21901609, 'vf_loss': 0.33016858, 'vf_explained_var': 0.89492327, 'kl': 0.02227355, 'entropy': 552.44244, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,625\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.11428437, 'policy_loss': -0.21900964, 'vf_loss': 0.3239203, 'vf_explained_var': 0.89689493, 'kl': 0.020830441, 'entropy': 552.4412, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,636\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.113714285, 'policy_loss': -0.21896465, 'vf_loss': 0.3239096, 'vf_explained_var': 0.8971677, 'kl': 0.019487416, 'entropy': 552.4405, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,646\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.10679883, 'policy_loss': -0.21897876, 'vf_loss': 0.3175494, 'vf_explained_var': 0.8991855, 'kl': 0.018284881, 'entropy': 552.44, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,657\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.10751996, 'policy_loss': -0.21894729, 'vf_loss': 0.3187144, 'vf_explained_var': 0.89827013, 'kl': 0.017228512, 'entropy': 552.44006, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,668\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.100236945, 'policy_loss': -0.21893102, 'vf_loss': 0.31176913, 'vf_explained_var': 0.9010181, 'kl': 0.016441876, 'entropy': 552.4397, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,679\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.10373285, 'policy_loss': -0.21885605, 'vf_loss': 0.31547803, 'vf_explained_var': 0.900412, 'kl': 0.01580193, 'entropy': 552.44336, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,690\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.101067565, 'policy_loss': -0.21900196, 'vf_loss': 0.31318015, 'vf_explained_var': 0.90068865, 'kl': 0.015309747, 'entropy': 552.44495, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,701\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.09266584, 'policy_loss': -0.21904962, 'vf_loss': 0.30506995, 'vf_explained_var': 0.9027953, 'kl': 0.014767754, 'entropy': 552.44586, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,712\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.08722069, 'policy_loss': -0.21899255, 'vf_loss': 0.29981533, 'vf_explained_var': 0.9042368, 'kl': 0.014217597, 'entropy': 552.4466, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,723\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.08073657, 'policy_loss': -0.21905424, 'vf_loss': 0.29365745, 'vf_explained_var': 0.9063592, 'kl': 0.01362963, 'entropy': 552.4525, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,733\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0776934, 'policy_loss': -0.21905763, 'vf_loss': 0.29088557, 'vf_explained_var': 0.9074473, 'kl': 0.013034365, 'entropy': 552.45807, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:41:46,745\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.072895646, 'policy_loss': -0.21881433, 'vf_loss': 0.2860218, 'vf_explained_var': 0.9090259, 'kl': 0.012640414, 'entropy': 552.4659, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-41-46\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.772718568824537\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 35\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.4658813476562\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012640413828194141\n",
      "        model: {}\n",
      "        policy_loss: -0.21881432831287384\n",
      "        total_loss: 0.07289564609527588\n",
      "        vf_explained_var: 0.9090259075164795\n",
      "        vf_loss: 0.28602179884910583\n",
      "    num_steps_sampled: 3500\n",
      "    num_steps_trained: 3500\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.017857142857146\n",
      "    ram_util_percent: 58.13571428571429\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15944632489049582\n",
      "    mean_env_wait_ms: 551.7438096892657\n",
      "    mean_inference_ms: 1.522376563957426\n",
      "    mean_raw_obs_processing_ms: 2.1017335898078997\n",
      "  time_since_restore: 390.1948051452637\n",
      "  time_this_iter_s: 35.25753211975098\n",
      "  time_total_s: 390.1948051452637\n",
      "  timers:\n",
      "    learn_throughput: 1038.446\n",
      "    learn_time_ms: 481.489\n",
      "    load_throughput: 25471.717\n",
      "    load_time_ms: 19.63\n",
      "    sample_throughput: 9.057\n",
      "    sample_time_ms: 55205.55\n",
      "    update_time_ms: 4.618\n",
      "  timestamp: 1604403706\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3500\n",
      "  training_iteration: 7\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:41:50,512\tWARNING util.py:139 -- The `process_trial` operation took 3.1593658924102783 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:41:50,491\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:41:51,158\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.6456820964813232 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 9.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         390.195</td><td style=\"text-align: right;\">3500</td><td style=\"text-align: right;\"> 2.77272</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,826\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,837\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.3888924, 'policy_loss': -0.0047507957, 'vf_loss': 0.3933337, 'vf_explained_var': 0.8514913, 'kl': 0.0006877516, 'entropy': 552.4725, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,848\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.18709838, 'policy_loss': -0.17969054, 'vf_loss': 0.3634719, 'vf_explained_var': 0.85984373, 'kl': 0.0073711076, 'entropy': 552.5979, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,858\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.15980604, 'policy_loss': -0.2092944, 'vf_loss': 0.36060226, 'vf_explained_var': 0.85955095, 'kl': 0.018884875, 'entropy': 552.70685, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,869\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.1408412, 'policy_loss': -0.21635158, 'vf_loss': 0.34355366, 'vf_explained_var': 0.866824, 'kl': 0.03030917, 'entropy': 552.7711, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,880\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.14186706, 'policy_loss': -0.21945441, 'vf_loss': 0.34375235, 'vf_explained_var': 0.86670226, 'kl': 0.039042518, 'entropy': 552.79175, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,890\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.13380595, 'policy_loss': -0.22108434, 'vf_loss': 0.33488464, 'vf_explained_var': 0.870024, 'kl': 0.044456888, 'entropy': 552.7788, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,901\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.1266324, 'policy_loss': -0.22158849, 'vf_loss': 0.32726422, 'vf_explained_var': 0.87295175, 'kl': 0.046570435, 'entropy': 552.74054, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,912\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.11534979, 'policy_loss': -0.2219655, 'vf_loss': 0.31630003, 'vf_explained_var': 0.87732536, 'kl': 0.046700627, 'entropy': 552.6921, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,924\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.10487267, 'policy_loss': -0.22229166, 'vf_loss': 0.30670276, 'vf_explained_var': 0.880904, 'kl': 0.045470145, 'entropy': 552.6446, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,934\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.10227615, 'policy_loss': -0.22239925, 'vf_loss': 0.30509475, 'vf_explained_var': 0.8817544, 'kl': 0.043512512, 'entropy': 552.60114, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,945\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.098298095, 'policy_loss': -0.22252719, 'vf_loss': 0.3022902, 'vf_explained_var': 0.88298845, 'kl': 0.041189138, 'entropy': 552.56464, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,955\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0916078, 'policy_loss': -0.22260945, 'vf_loss': 0.29676244, 'vf_explained_var': 0.8850829, 'kl': 0.03878847, 'entropy': 552.5371, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,966\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.08523369, 'policy_loss': -0.22263508, 'vf_loss': 0.2914996, 'vf_explained_var': 0.8874645, 'kl': 0.036375847, 'entropy': 552.5197, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,980\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.07906392, 'policy_loss': -0.22253837, 'vf_loss': 0.2863456, 'vf_explained_var': 0.88880426, 'kl': 0.03390383, 'entropy': 552.51166, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:24,993\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.07182034, 'policy_loss': -0.22266549, 'vf_loss': 0.28029105, 'vf_explained_var': 0.8910286, 'kl': 0.03154394, 'entropy': 552.5129, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,004\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.067255616, 'policy_loss': -0.22266184, 'vf_loss': 0.27671793, 'vf_explained_var': 0.89277035, 'kl': 0.029332304, 'entropy': 552.5172, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,015\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.06220748, 'policy_loss': -0.2226728, 'vf_loss': 0.27258536, 'vf_explained_var': 0.8944387, 'kl': 0.027322, 'entropy': 552.5223, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,025\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.05916814, 'policy_loss': -0.22268414, 'vf_loss': 0.27040136, 'vf_explained_var': 0.89493746, 'kl': 0.025446536, 'entropy': 552.5274, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,036\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.05809142, 'policy_loss': -0.22266062, 'vf_loss': 0.27005473, 'vf_explained_var': 0.895147, 'kl': 0.023771808, 'entropy': 552.5313, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,047\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.051414028, 'policy_loss': -0.22246213, 'vf_loss': 0.26384315, 'vf_explained_var': 0.897789, 'kl': 0.022295704, 'entropy': 552.5373, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,057\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.05518264, 'policy_loss': -0.22263615, 'vf_loss': 0.2683986, 'vf_explained_var': 0.89617985, 'kl': 0.02093376, 'entropy': 552.53656, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,068\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.053835955, 'policy_loss': -0.22231126, 'vf_loss': 0.26727855, 'vf_explained_var': 0.896499, 'kl': 0.01970815, 'entropy': 552.52985, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,079\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.046939168, 'policy_loss': -0.22263215, 'vf_loss': 0.26118192, 'vf_explained_var': 0.89861566, 'kl': 0.018643135, 'entropy': 552.52405, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,091\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.047396164, 'policy_loss': -0.2221498, 'vf_loss': 0.26151022, 'vf_explained_var': 0.8983275, 'kl': 0.017857177, 'entropy': 552.52057, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,102\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.04434206, 'policy_loss': -0.22264974, 'vf_loss': 0.25931546, 'vf_explained_var': 0.8993025, 'kl': 0.017058596, 'entropy': 552.51935, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,114\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.04135961, 'policy_loss': -0.22251852, 'vf_loss': 0.2565615, 'vf_explained_var': 0.9004817, 'kl': 0.016259192, 'entropy': 552.51636, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,125\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.034029532, 'policy_loss': -0.22266255, 'vf_loss': 0.24965279, 'vf_explained_var': 0.9034187, 'kl': 0.015642967, 'entropy': 552.50854, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,137\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.03137135, 'policy_loss': -0.22259243, 'vf_loss': 0.24714224, 'vf_explained_var': 0.90431046, 'kl': 0.015158967, 'entropy': 552.504, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,148\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.02808862, 'policy_loss': -0.22265077, 'vf_loss': 0.24418189, 'vf_explained_var': 0.9052563, 'kl': 0.014572233, 'entropy': 552.5046, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:42:25,159\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.02703621, 'policy_loss': -0.22266324, 'vf_loss': 0.24340439, 'vf_explained_var': 0.9054551, 'kl': 0.013988982, 'entropy': 552.5066, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-42-25\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.784642442316555\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 40\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.506591796875\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013988981954753399\n",
      "        model: {}\n",
      "        policy_loss: -0.22266323864459991\n",
      "        total_loss: 0.027036210522055626\n",
      "        vf_explained_var: 0.9054551124572754\n",
      "        vf_loss: 0.24340438842773438\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.47777777777778\n",
      "    ram_util_percent: 62.58333333333332\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15716641177099552\n",
      "    mean_env_wait_ms: 543.3715233129833\n",
      "    mean_inference_ms: 1.489369305048325\n",
      "    mean_raw_obs_processing_ms: 2.081540756835257\n",
      "  time_since_restore: 424.87303137779236\n",
      "  time_this_iter_s: 34.67822623252869\n",
      "  time_total_s: 424.87303137779236\n",
      "  timers:\n",
      "    learn_throughput: 1080.068\n",
      "    learn_time_ms: 462.934\n",
      "    load_throughput: 28785.434\n",
      "    load_time_ms: 17.37\n",
      "    sample_throughput: 9.506\n",
      "    sample_time_ms: 52596.541\n",
      "    update_time_ms: 4.317\n",
      "  timestamp: 1604403745\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 8\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:42:29,167\tWARNING util.py:139 -- The `process_trial` operation took 3.208836078643799 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:42:29,840\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.6712229251861572 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         424.873</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\"> 2.78464</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "tion_logp': np.ndarray((100,), dtype=float32, min=-588.129, max=-518.421, mean=-550.648),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-3.993, max=4.668, mean=-0.007),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-1.704, max=2.019, mean=0.232),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=302035210.0, max=302035210.0, mean=302035210.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4623.497, mean=124.213),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.867),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-3.993, max=4.668, mean=-0.007),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=8.0, max=8.0, mean=8.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.016, max=4.439, mean=2.67),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=0.652, max=3.773, mean=2.438)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:43:04,260\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.087, max=0.096, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-588.129, max=-518.421, mean=-550.648),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-3.993, max=4.668, mean=-0.007),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-1.704, max=2.019, mean=0.232),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=302035210.0, max=302035210.0, mean=302035210.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4623.497, mean=124.213),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.867),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-3.993, max=4.668, mean=-0.007),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=8.0, max=8.0, mean=8.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.016, max=4.439, mean=2.67),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=0.652, max=3.773, mean=2.438)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,719\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-4.612, max=4.725, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.055, max=0.183, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.036),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.087, max=0.096, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-590.259, max=-513.108, mean=-551.975),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.612, max=4.725, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-5.495, max=3.515, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.036),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.612, max=4.725, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.055, max=0.183, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.354, max=4.439, mean=0.824),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.423, max=3.773, mean=0.807)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,719\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,720\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,731\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.36886442, 'policy_loss': 0.01945397, 'vf_loss': 0.34904656, 'vf_explained_var': 0.8842935, 'kl': 0.00080872397, 'entropy': 552.4974, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,742\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.16481726, 'policy_loss': -0.17067777, 'vf_loss': 0.33243075, 'vf_explained_var': 0.889807, 'kl': 0.006809438, 'entropy': 552.5177, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,752\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.11912787, 'policy_loss': -0.20684254, 'vf_loss': 0.3179443, 'vf_explained_var': 0.89472884, 'kl': 0.01783578, 'entropy': 552.56396, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,763\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.10964244, 'policy_loss': -0.21497111, 'vf_loss': 0.31126407, 'vf_explained_var': 0.89733934, 'kl': 0.029665545, 'entropy': 552.6121, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,778\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.104849935, 'policy_loss': -0.21748705, 'vf_loss': 0.3048649, 'vf_explained_var': 0.8992589, 'kl': 0.03882685, 'entropy': 552.6314, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,791\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.100677855, 'policy_loss': -0.21826935, 'vf_loss': 0.2990672, 'vf_explained_var': 0.90093994, 'kl': 0.04417779, 'entropy': 552.62134, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,802\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.092149496, 'policy_loss': -0.21858664, 'vf_loss': 0.2900287, 'vf_explained_var': 0.9038381, 'kl': 0.046016514, 'entropy': 552.5982, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,813\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.08329753, 'policy_loss': -0.21890657, 'vf_loss': 0.2815552, 'vf_explained_var': 0.9065954, 'kl': 0.045886416, 'entropy': 552.57074, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,826\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0825265, 'policy_loss': -0.21911557, 'vf_loss': 0.28149402, 'vf_explained_var': 0.906581, 'kl': 0.04477344, 'entropy': 552.5396, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,837\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.06982841, 'policy_loss': -0.21912491, 'vf_loss': 0.26953736, 'vf_explained_var': 0.9106283, 'kl': 0.04314657, 'entropy': 552.51154, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,848\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.06862089, 'policy_loss': -0.2192473, 'vf_loss': 0.26936102, 'vf_explained_var': 0.91082144, 'kl': 0.041127097, 'entropy': 552.4917, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,860\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.061356697, 'policy_loss': -0.21931933, 'vf_loss': 0.26315543, 'vf_explained_var': 0.9130755, 'kl': 0.038934693, 'entropy': 552.47906, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,871\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.056244493, 'policy_loss': -0.21936466, 'vf_loss': 0.2591394, 'vf_explained_var': 0.91438407, 'kl': 0.036599543, 'entropy': 552.4727, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,882\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.051231876, 'policy_loss': -0.21938062, 'vf_loss': 0.25518206, 'vf_explained_var': 0.9157376, 'kl': 0.034289867, 'entropy': 552.4736, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,894\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.04940657, 'policy_loss': -0.21937232, 'vf_loss': 0.25431585, 'vf_explained_var': 0.915911, 'kl': 0.032140043, 'entropy': 552.48016, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,905\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.039511774, 'policy_loss': -0.2193501, 'vf_loss': 0.2453245, 'vf_explained_var': 0.9186709, 'kl': 0.030083051, 'entropy': 552.48975, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,916\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.03846923, 'policy_loss': -0.2194014, 'vf_loss': 0.24520116, 'vf_explained_var': 0.9188704, 'kl': 0.028154373, 'entropy': 552.5009, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,927\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.035551175, 'policy_loss': -0.21939819, 'vf_loss': 0.2430771, 'vf_explained_var': 0.9195308, 'kl': 0.02638273, 'entropy': 552.5105, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,939\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.028904846, 'policy_loss': -0.21941487, 'vf_loss': 0.23715584, 'vf_explained_var': 0.92147255, 'kl': 0.024808625, 'entropy': 552.5205, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,950\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.027363978, 'policy_loss': -0.21942143, 'vf_loss': 0.2362864, 'vf_explained_var': 0.9218888, 'kl': 0.023331078, 'entropy': 552.5276, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,961\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.023587873, 'policy_loss': -0.21941991, 'vf_loss': 0.23310411, 'vf_explained_var': 0.9229397, 'kl': 0.022008136, 'entropy': 552.532, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,973\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.01986032, 'policy_loss': -0.219431, 'vf_loss': 0.22993164, 'vf_explained_var': 0.92372936, 'kl': 0.02079935, 'entropy': 552.534, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,986\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.019637147, 'policy_loss': -0.21943939, 'vf_loss': 0.23022383, 'vf_explained_var': 0.92375344, 'kl': 0.019672627, 'entropy': 552.53424, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:04,998\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.015673084, 'policy_loss': -0.21940619, 'vf_loss': 0.2266885, 'vf_explained_var': 0.9249713, 'kl': 0.01864617, 'entropy': 552.5328, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:05,009\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.012637754, 'policy_loss': -0.21942234, 'vf_loss': 0.22408618, 'vf_explained_var': 0.9257795, 'kl': 0.017719826, 'entropy': 552.53253, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:05,020\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.008465916, 'policy_loss': -0.21941245, 'vf_loss': 0.2202778, 'vf_explained_var': 0.92701054, 'kl': 0.016890133, 'entropy': 552.5334, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:05,033\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.006196777, 'policy_loss': -0.21943432, 'vf_loss': 0.21837531, 'vf_explained_var': 0.9277685, 'kl': 0.016123975, 'entropy': 552.5334, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:05,046\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.004276201, 'policy_loss': -0.21944232, 'vf_loss': 0.21677615, 'vf_explained_var': 0.9283281, 'kl': 0.0154274395, 'entropy': 552.532, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:05,059\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0030300543, 'policy_loss': -0.21940942, 'vf_loss': 0.21579337, 'vf_explained_var': 0.92851186, 'kl': 0.014769104, 'entropy': 552.52997, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:05,072\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0013315479, 'policy_loss': -0.21938764, 'vf_loss': 0.21167767, 'vf_explained_var': 0.9298164, 'kl': 0.01417428, 'entropy': 552.5267, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-43-05\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.7896937511671025\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 45\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5266723632812\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014174279756844044\n",
      "        model: {}\n",
      "        policy_loss: -0.21938763558864594\n",
      "        total_loss: -0.0013315478572621942\n",
      "        vf_explained_var: 0.9298164248466492\n",
      "        vf_loss: 0.2116776704788208\n",
      "    num_steps_sampled: 4500\n",
      "    num_steps_trained: 4500\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.792857142857144\n",
      "    ram_util_percent: 67.12142857142858\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1549032510520626\n",
      "    mean_env_wait_ms: 535.1838024729985\n",
      "    mean_inference_ms: 1.4589599506141808\n",
      "    mean_raw_obs_processing_ms: 2.0600453721532257\n",
      "  time_since_restore: 460.8099994659424\n",
      "  time_this_iter_s: 35.936968088150024\n",
      "  time_total_s: 460.8099994659424\n",
      "  timers:\n",
      "    learn_throughput: 1109.446\n",
      "    learn_time_ms: 450.676\n",
      "    load_throughput: 31488.769\n",
      "    load_time_ms: 15.879\n",
      "    sample_throughput: 9.861\n",
      "    sample_time_ms: 50704.657\n",
      "    update_time_ms: 4.123\n",
      "  timestamp: 1604403785\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4500\n",
      "  training_iteration: 9\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:43:09,345\tWARNING util.py:139 -- The `process_trial` operation took 3.4311318397521973 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:43:09,324\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:43:10,014\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.6686971187591553 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">          460.81</td><td style=\"text-align: right;\">4500</td><td style=\"text-align: right;\"> 2.78969</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,470\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,470\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,470\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,470\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,470\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,470\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,470\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,470\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,470\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,470\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,470\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,470\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,472\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,483\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.18829612, 'policy_loss': -0.033162568, 'vf_loss': 0.22112797, 'vf_explained_var': 0.92675585, 'kl': 0.00073498394, 'entropy': 552.52905, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,493\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.020392315, 'policy_loss': -0.18884183, 'vf_loss': 0.20613694, 'vf_explained_var': 0.93046004, 'kl': 0.006882695, 'entropy': 552.497, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,502\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.010546535, 'policy_loss': -0.21753044, 'vf_loss': 0.19995522, 'vf_explained_var': 0.9326653, 'kl': 0.015619268, 'entropy': 552.46027, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,511\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.019916667, 'policy_loss': -0.22462146, 'vf_loss': 0.1936254, 'vf_explained_var': 0.93435735, 'kl': 0.024620852, 'entropy': 552.4345, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,521\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.02368282, 'policy_loss': -0.22804344, 'vf_loss': 0.19017877, 'vf_explained_var': 0.93542844, 'kl': 0.031515192, 'entropy': 552.42456, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,532\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.028984604, 'policy_loss': -0.22979164, 'vf_loss': 0.18442051, 'vf_explained_var': 0.93730426, 'kl': 0.036414545, 'entropy': 552.4237, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,542\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.030589541, 'policy_loss': -0.23076518, 'vf_loss': 0.18265313, 'vf_explained_var': 0.9380823, 'kl': 0.03893893, 'entropy': 552.42523, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,553\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.034339577, 'policy_loss': -0.23130357, 'vf_loss': 0.17899837, 'vf_explained_var': 0.93938416, 'kl': 0.039923687, 'entropy': 552.42114, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,564\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.04021932, 'policy_loss': -0.23167317, 'vf_loss': 0.17361204, 'vf_explained_var': 0.9410181, 'kl': 0.03964844, 'entropy': 552.4165, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,579\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.044052433, 'policy_loss': -0.23186748, 'vf_loss': 0.17051041, 'vf_explained_var': 0.9421553, 'kl': 0.03845469, 'entropy': 552.4118, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,590\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.04914695, 'policy_loss': -0.23207577, 'vf_loss': 0.1664107, 'vf_explained_var': 0.9437032, 'kl': 0.036706924, 'entropy': 552.4089, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,601\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.05378312, 'policy_loss': -0.23226738, 'vf_loss': 0.16285041, 'vf_explained_var': 0.9447016, 'kl': 0.03474189, 'entropy': 552.4062, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,611\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.05674741, 'policy_loss': -0.23236541, 'vf_loss': 0.16083016, 'vf_explained_var': 0.94527656, 'kl': 0.032861847, 'entropy': 552.4039, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,621\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.060422618, 'policy_loss': -0.2324245, 'vf_loss': 0.1580775, 'vf_explained_var': 0.946455, 'kl': 0.030943051, 'entropy': 552.4068, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,632\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.062713295, 'policy_loss': -0.23243986, 'vf_loss': 0.15663157, 'vf_explained_var': 0.94696903, 'kl': 0.029099988, 'entropy': 552.41376, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,641\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06354485, 'policy_loss': -0.23249458, 'vf_loss': 0.15664977, 'vf_explained_var': 0.947176, 'kl': 0.027333235, 'entropy': 552.42145, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,651\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06852826, 'policy_loss': -0.23250999, 'vf_loss': 0.15244071, 'vf_explained_var': 0.94866705, 'kl': 0.025646767, 'entropy': 552.4295, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,661\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.072820686, 'policy_loss': -0.23254156, 'vf_loss': 0.14888911, 'vf_explained_var': 0.94947624, 'kl': 0.024070641, 'entropy': 552.4401, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,672\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07285738, 'policy_loss': -0.2325477, 'vf_loss': 0.1495071, 'vf_explained_var': 0.949325, 'kl': 0.02262938, 'entropy': 552.4517, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,682\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07561028, 'policy_loss': -0.232548, 'vf_loss': 0.14735411, 'vf_explained_var': 0.9501452, 'kl': 0.021296926, 'entropy': 552.4626, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,692\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.079312116, 'policy_loss': -0.23256361, 'vf_loss': 0.1442041, 'vf_explained_var': 0.95117164, 'kl': 0.020105343, 'entropy': 552.4725, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,704\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08214096, 'policy_loss': -0.23253173, 'vf_loss': 0.14184476, 'vf_explained_var': 0.95177346, 'kl': 0.018991096, 'entropy': 552.4804, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,715\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08319648, 'policy_loss': -0.23255067, 'vf_loss': 0.14122966, 'vf_explained_var': 0.95200664, 'kl': 0.018054545, 'entropy': 552.48413, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,727\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08437976, 'policy_loss': -0.2325626, 'vf_loss': 0.14045317, 'vf_explained_var': 0.95233756, 'kl': 0.017177036, 'entropy': 552.4869, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,738\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08503733, 'policy_loss': -0.23255801, 'vf_loss': 0.14016415, 'vf_explained_var': 0.9525204, 'kl': 0.016347846, 'entropy': 552.4905, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,748\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08518127, 'policy_loss': -0.23256929, 'vf_loss': 0.14037454, 'vf_explained_var': 0.9524846, 'kl': 0.015585494, 'entropy': 552.4954, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,759\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.087115854, 'policy_loss': -0.23257506, 'vf_loss': 0.13875955, 'vf_explained_var': 0.9530034, 'kl': 0.0148881115, 'entropy': 552.499, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,770\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.088196896, 'policy_loss': -0.23255713, 'vf_loss': 0.13796516, 'vf_explained_var': 0.953347, 'kl': 0.014211242, 'entropy': 552.4996, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,781\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08869434, 'policy_loss': -0.23256485, 'vf_loss': 0.13773458, 'vf_explained_var': 0.9531808, 'kl': 0.013635372, 'entropy': 552.49994, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:43:44,792\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09069272, 'policy_loss': -0.23254271, 'vf_loss': 0.1359477, 'vf_explained_var': 0.95384234, 'kl': 0.013116215, 'entropy': 552.5008, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-43-44\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.796871643854615\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 50\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5007934570312\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013116215355694294\n",
      "        model: {}\n",
      "        policy_loss: -0.2325427085161209\n",
      "        total_loss: -0.09069272130727768\n",
      "        vf_explained_var: 0.9538423418998718\n",
      "        vf_loss: 0.13594770431518555\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 5000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.017857142857146\n",
      "    ram_util_percent: 71.16071428571429\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15273290750948315\n",
      "    mean_env_wait_ms: 527.3867223717807\n",
      "    mean_inference_ms: 1.4311509104832085\n",
      "    mean_raw_obs_processing_ms: 2.0384534805884567\n",
      "  time_since_restore: 496.287531375885\n",
      "  time_this_iter_s: 35.47753190994263\n",
      "  time_total_s: 496.287531375885\n",
      "  timers:\n",
      "    learn_throughput: 1142.489\n",
      "    learn_time_ms: 437.641\n",
      "    load_throughput: 34403.454\n",
      "    load_time_ms: 14.533\n",
      "    sample_throughput: 10.173\n",
      "    sample_time_ms: 49148.782\n",
      "    update_time_ms: 3.925\n",
      "  timestamp: 1604403824\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 10\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:43:48,706\tWARNING util.py:139 -- The `process_trial` operation took 3.337515115737915 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:43:49,416\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7093279361724854 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         496.288</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\"> 2.79687</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:44:09,467\tINFO sampler.py:800 -- Preprocessed obs: np.ndarray((389,), dtype=float64, min=8.08, max=3805.818, mean=120.969)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:44:09,467\tINFO sampler.py:805 -- Filtered obs: np.ndarray((389,), dtype=float64, min=8.08, max=3805.818, mean=120.969)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:44:09,468\tINFO sampler.py:1223 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'info': {},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'obs': np.ndarray((389,), dtype=float64, min=8.08, max=3805.818, mean=120.969),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_action': np.ndarray((389,), dtype=float32, min=-2.64, max=2.667, mean=0.142),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_reward': 0.14260802209540602,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:44:09,468\tINFO tf_run_builder.py:87 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:44:09,469\tINFO sampler.py:1269 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': ( np.ndarray((1, 389), dtype=float32, min=-4.045, max=2.708, mean=-0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       { 'action_dist_inputs': np.ndarray((1, 778), dtype=float32, min=-0.036, max=0.049, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-569.853, max=-569.853, mean=-569.853),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=2.678, max=2.678, mean=2.678)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:44:09,818\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=8.37, max=2494.96, mean=117.533)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:44:09,818\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:44:22,856\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.12, max=0.137, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-588.743, max=-521.374, mean=-552.224),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.123, max=4.089, mean=0.006),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-2.392, max=2.106, mean=0.039),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=680634038.0, max=680634038.0, mean=680634038.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4573.498, mean=124.347),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.014),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.123, max=4.089, mean=0.006),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.182, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.182, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=10.0, max=10.0, mean=10.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.017, max=4.347, mean=2.615),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=0.212, max=4.134, mean=2.576)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:44:22,995\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.12, max=0.137, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-588.743, max=-521.374, mean=-552.224),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.123, max=4.089, mean=0.006),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-2.392, max=2.106, mean=0.039),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=680634038.0, max=680634038.0, mean=680634038.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4573.498, mean=124.347),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.014),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.123, max=4.089, mean=0.006),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.182, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.182, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=10.0, max=10.0, mean=10.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.017, max=4.347, mean=2.615),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=0.212, max=4.134, mean=2.576)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,502\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,513\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.26548722, 'policy_loss': 0.010108122, 'vf_loss': 0.255053, 'vf_explained_var': 0.9156468, 'kl': 0.0007247003, 'entropy': 552.5102, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,524\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.08038963, 'policy_loss': -0.15707664, 'vf_loss': 0.23526795, 'vf_explained_var': 0.9168791, 'kl': 0.0048850616, 'entropy': 552.5362, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,534\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.03948499, 'policy_loss': -0.19036818, 'vf_loss': 0.22411984, 'vf_explained_var': 0.920836, 'kl': 0.012740743, 'entropy': 552.5973, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,546\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.02492941, 'policy_loss': -0.19763434, 'vf_loss': 0.21293665, 'vf_explained_var': 0.9258855, 'kl': 0.021393523, 'entropy': 552.6529, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,557\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0071978937, 'policy_loss': -0.19933774, 'vf_loss': 0.1935155, 'vf_explained_var': 0.9314626, 'kl': 0.028933676, 'entropy': 552.6763, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,568\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.010914665, 'policy_loss': -0.20020251, 'vf_loss': 0.1958241, 'vf_explained_var': 0.93209714, 'kl': 0.03398454, 'entropy': 552.6645, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,578\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0022281825, 'policy_loss': -0.2008434, 'vf_loss': 0.18218188, 'vf_explained_var': 0.936023, 'kl': 0.036518563, 'entropy': 552.63165, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,589\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0013789106, 'policy_loss': -0.20108569, 'vf_loss': 0.18297602, 'vf_explained_var': 0.93565726, 'kl': 0.03717944, 'entropy': 552.5918, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,602\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0024422414, 'policy_loss': -0.20123513, 'vf_loss': 0.18230595, 'vf_explained_var': 0.935745, 'kl': 0.036637645, 'entropy': 552.553, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,613\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.01260716, 'policy_loss': -0.20131378, 'vf_loss': 0.1726876, 'vf_explained_var': 0.9392293, 'kl': 0.03559783, 'entropy': 552.5205, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,624\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.020281285, 'policy_loss': -0.20145361, 'vf_loss': 0.16580425, 'vf_explained_var': 0.9415377, 'kl': 0.034151252, 'entropy': 552.49554, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,636\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.02234135, 'policy_loss': -0.20151204, 'vf_loss': 0.16453211, 'vf_explained_var': 0.9419691, 'kl': 0.03253019, 'entropy': 552.48016, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,648\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.03189476, 'policy_loss': -0.20158578, 'vf_loss': 0.15583163, 'vf_explained_var': 0.94517916, 'kl': 0.030798642, 'entropy': 552.4731, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,660\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.035020225, 'policy_loss': -0.20160635, 'vf_loss': 0.153511, 'vf_explained_var': 0.9460406, 'kl': 0.02905587, 'entropy': 552.4732, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,671\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.039434317, 'policy_loss': -0.2016716, 'vf_loss': 0.14992101, 'vf_explained_var': 0.94728273, 'kl': 0.02736947, 'entropy': 552.47974, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,683\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.04343735, 'policy_loss': -0.2017018, 'vf_loss': 0.14667667, 'vf_explained_var': 0.94828564, 'kl': 0.025750572, 'entropy': 552.49005, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,695\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.045540854, 'policy_loss': -0.20172024, 'vf_loss': 0.14526752, 'vf_explained_var': 0.9486659, 'kl': 0.02424858, 'entropy': 552.5015, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,706\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.045315433, 'policy_loss': -0.20173852, 'vf_loss': 0.14613263, 'vf_explained_var': 0.94872403, 'kl': 0.022867655, 'entropy': 552.51166, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,717\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.051069427, 'policy_loss': -0.20174353, 'vf_loss': 0.14097033, 'vf_explained_var': 0.95042753, 'kl': 0.021563927, 'entropy': 552.51984, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,728\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.05151676, 'policy_loss': -0.20174347, 'vf_loss': 0.14107053, 'vf_explained_var': 0.95032215, 'kl': 0.02034708, 'entropy': 552.5267, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,740\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.057068337, 'policy_loss': -0.20175356, 'vf_loss': 0.13603391, 'vf_explained_var': 0.952015, 'kl': 0.019225126, 'entropy': 552.53143, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,751\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.058416497, 'policy_loss': -0.20174366, 'vf_loss': 0.1351322, 'vf_explained_var': 0.95241183, 'kl': 0.018211052, 'entropy': 552.535, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,762\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.059594274, 'policy_loss': -0.20175032, 'vf_loss': 0.13438517, 'vf_explained_var': 0.9528255, 'kl': 0.017268592, 'entropy': 552.53595, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,774\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.064685196, 'policy_loss': -0.2017514, 'vf_loss': 0.1296763, 'vf_explained_var': 0.9543994, 'kl': 0.016421946, 'entropy': 552.53705, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,785\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.062169153, 'policy_loss': -0.20171696, 'vf_loss': 0.13248582, 'vf_explained_var': 0.95326716, 'kl': 0.015693283, 'entropy': 552.53827, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,795\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06482651, 'policy_loss': -0.2017082, 'vf_loss': 0.13014978, 'vf_explained_var': 0.9539919, 'kl': 0.014959779, 'entropy': 552.5392, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,806\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06634167, 'policy_loss': -0.20174067, 'vf_loss': 0.12898044, 'vf_explained_var': 0.954459, 'kl': 0.014263486, 'entropy': 552.5388, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,817\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.071543135, 'policy_loss': -0.20175983, 'vf_loss': 0.12407342, 'vf_explained_var': 0.9562195, 'kl': 0.013651718, 'entropy': 552.53815, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,828\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07273433, 'policy_loss': -0.20176, 'vf_loss': 0.123146236, 'vf_explained_var': 0.95659965, 'kl': 0.013065432, 'entropy': 552.53815, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:44:23,839\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0724159, 'policy_loss': -0.201769, 'vf_loss': 0.12371721, 'vf_explained_var': 0.9565236, 'kl': 0.012524168, 'entropy': 552.5381, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-44-23\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.7714239227903152\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 55\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5380859375\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012524168007075787\n",
      "        model: {}\n",
      "        policy_loss: -0.20176899433135986\n",
      "        total_loss: -0.07241590321063995\n",
      "        vf_explained_var: 0.956523597240448\n",
      "        vf_loss: 0.12371721118688583\n",
      "    num_steps_sampled: 5500\n",
      "    num_steps_trained: 5500\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.661818181818184\n",
      "    ram_util_percent: 72.83454545454545\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1506800336244467\n",
      "    mean_env_wait_ms: 520.0500658466021\n",
      "    mean_inference_ms: 1.4057740064463293\n",
      "    mean_raw_obs_processing_ms: 2.017948651248451\n",
      "  time_since_restore: 531.4539453983307\n",
      "  time_this_iter_s: 35.16641402244568\n",
      "  time_total_s: 531.4539453983307\n",
      "  timers:\n",
      "    learn_throughput: 1263.497\n",
      "    learn_time_ms: 395.727\n",
      "    load_throughput: 65621.718\n",
      "    load_time_ms: 7.619\n",
      "    sample_throughput: 11.271\n",
      "    sample_time_ms: 44362.746\n",
      "    update_time_ms: 3.635\n",
      "  timestamp: 1604403863\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5500\n",
      "  training_iteration: 11\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:44:27,977\tWARNING util.py:139 -- The `process_trial` operation took 3.2979981899261475 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:44:27,955\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:44:28,646\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.6685142517089844 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         531.454</td><td style=\"text-align: right;\">5500</td><td style=\"text-align: right;\"> 2.77142</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:02,876\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-5.207, max=4.66, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.052, max=0.182, mean=0.027),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=129.925),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.111, max=0.167, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-597.022, max=-516.559, mean=-551.389),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-5.207, max=4.66, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-4.743, max=6.404, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=129.925),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-5.207, max=4.66, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.052, max=0.182, mean=0.027),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.29, max=4.428, mean=0.775),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.61, max=4.196, mean=0.679)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:02,877\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:02,886\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:02,915\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.2044589, 'policy_loss': -0.0034949332, 'vf_loss': 0.20756936, 'vf_explained_var': 0.9244695, 'kl': 0.00085441186, 'entropy': 552.54156, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:02,934\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.023240434, 'policy_loss': -0.16445617, 'vf_loss': 0.18426324, 'vf_explained_var': 0.93169755, 'kl': 0.0076296427, 'entropy': 552.5377, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:02,951\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0013402601, 'policy_loss': -0.20001654, 'vf_loss': 0.19359677, 'vf_explained_var': 0.9277312, 'kl': 0.017244546, 'entropy': 552.5384, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:02,969\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0136448, 'policy_loss': -0.21099055, 'vf_loss': 0.18539415, 'vf_explained_var': 0.9302891, 'kl': 0.026559174, 'entropy': 552.52814, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:02,985\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.026338438, 'policy_loss': -0.2145595, 'vf_loss': 0.17291033, 'vf_explained_var': 0.9356162, 'kl': 0.034023773, 'entropy': 552.5171, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,001\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.026353292, 'policy_loss': -0.21564174, 'vf_loss': 0.17184372, 'vf_explained_var': 0.9357807, 'kl': 0.03876608, 'entropy': 552.50146, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,019\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.03252842, 'policy_loss': -0.21614091, 'vf_loss': 0.16514096, 'vf_explained_var': 0.93859005, 'kl': 0.041047852, 'entropy': 552.4815, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,035\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.033619672, 'policy_loss': -0.21662784, 'vf_loss': 0.1640058, 'vf_explained_var': 0.9389715, 'kl': 0.042227466, 'entropy': 552.4615, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,052\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.040838856, 'policy_loss': -0.21697687, 'vf_loss': 0.15728329, 'vf_explained_var': 0.9414785, 'kl': 0.041899383, 'entropy': 552.446, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,069\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.041549478, 'policy_loss': -0.21714993, 'vf_loss': 0.15730393, 'vf_explained_var': 0.9417453, 'kl': 0.04065896, 'entropy': 552.4394, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,087\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.046693206, 'policy_loss': -0.21722274, 'vf_loss': 0.15292627, 'vf_explained_var': 0.94343895, 'kl': 0.03911839, 'entropy': 552.4393, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,104\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.048796777, 'policy_loss': -0.21726592, 'vf_loss': 0.15165147, 'vf_explained_var': 0.9432953, 'kl': 0.037372563, 'entropy': 552.445, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,121\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.049735922, 'policy_loss': -0.21733065, 'vf_loss': 0.15156513, 'vf_explained_var': 0.9436171, 'kl': 0.035621293, 'entropy': 552.4547, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,144\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.05531529, 'policy_loss': -0.21736844, 'vf_loss': 0.14686494, 'vf_explained_var': 0.9450309, 'kl': 0.033751544, 'entropy': 552.4673, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,165\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.057596732, 'policy_loss': -0.21738498, 'vf_loss': 0.14538556, 'vf_explained_var': 0.9458625, 'kl': 0.032005966, 'entropy': 552.48, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,182\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.060395908, 'policy_loss': -0.21741761, 'vf_loss': 0.14339317, 'vf_explained_var': 0.9468805, 'kl': 0.030285643, 'entropy': 552.4907, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,201\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06476614, 'policy_loss': -0.21742178, 'vf_loss': 0.13977177, 'vf_explained_var': 0.94808155, 'kl': 0.028630832, 'entropy': 552.49927, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,218\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.068012245, 'policy_loss': -0.2174303, 'vf_loss': 0.137253, 'vf_explained_var': 0.9489849, 'kl': 0.02703341, 'entropy': 552.5044, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,234\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06811751, 'policy_loss': -0.21745528, 'vf_loss': 0.13783933, 'vf_explained_var': 0.94880486, 'kl': 0.025552103, 'entropy': 552.5085, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,249\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06936815, 'policy_loss': -0.2174397, 'vf_loss': 0.13720103, 'vf_explained_var': 0.9489722, 'kl': 0.02415665, 'entropy': 552.5125, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,265\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0728691, 'policy_loss': -0.21743037, 'vf_loss': 0.13427432, 'vf_explained_var': 0.9505582, 'kl': 0.022859894, 'entropy': 552.5173, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,280\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.073678404, 'policy_loss': -0.21745051, 'vf_loss': 0.13403802, 'vf_explained_var': 0.9503129, 'kl': 0.021631362, 'entropy': 552.5223, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,295\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07710015, 'policy_loss': -0.2174543, 'vf_loss': 0.13112397, 'vf_explained_var': 0.9512047, 'kl': 0.020511461, 'entropy': 552.5271, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,313\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0765802, 'policy_loss': -0.21742071, 'vf_loss': 0.13206477, 'vf_explained_var': 0.9513018, 'kl': 0.019501654, 'entropy': 552.5313, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,329\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07798498, 'policy_loss': -0.2174304, 'vf_loss': 0.13109578, 'vf_explained_var': 0.951775, 'kl': 0.018554738, 'entropy': 552.53455, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,345\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07908367, 'policy_loss': -0.21744661, 'vf_loss': 0.1303993, 'vf_explained_var': 0.9518251, 'kl': 0.017696902, 'entropy': 552.5395, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,363\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0813235, 'policy_loss': -0.21744232, 'vf_loss': 0.12848601, 'vf_explained_var': 0.9521103, 'kl': 0.016961848, 'entropy': 552.5446, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,377\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0798906, 'policy_loss': -0.21744569, 'vf_loss': 0.13021143, 'vf_explained_var': 0.95201653, 'kl': 0.01631921, 'entropy': 552.5479, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,391\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08130104, 'policy_loss': -0.21743967, 'vf_loss': 0.12908894, 'vf_explained_var': 0.9528065, 'kl': 0.015665995, 'entropy': 552.5497, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:03,406\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08563083, 'policy_loss': -0.21744323, 'vf_loss': 0.12503417, 'vf_explained_var': 0.9542721, 'kl': 0.015062697, 'entropy': 552.55096, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-45-03\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.7671030763258484\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 60\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5509643554688\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015062697231769562\n",
      "        model: {}\n",
      "        policy_loss: -0.21744322776794434\n",
      "        total_loss: -0.08563082665205002\n",
      "        vf_explained_var: 0.9542720913887024\n",
      "        vf_loss: 0.1250341683626175\n",
      "    num_steps_sampled: 6000\n",
      "    num_steps_trained: 6000\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.707142857142856\n",
      "    ram_util_percent: 75.13571428571429\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14875338520999196\n",
      "    mean_env_wait_ms: 513.1999281722901\n",
      "    mean_inference_ms: 1.3826537784875095\n",
      "    mean_raw_obs_processing_ms: 2.000822987641819\n",
      "  time_since_restore: 566.9236054420471\n",
      "  time_this_iter_s: 35.46966004371643\n",
      "  time_total_s: 566.9236054420471\n",
      "  timers:\n",
      "    learn_throughput: 1239.784\n",
      "    learn_time_ms: 403.296\n",
      "    load_throughput: 53097.698\n",
      "    load_time_ms: 9.417\n",
      "    sample_throughput: 11.793\n",
      "    sample_time_ms: 42398.329\n",
      "    update_time_ms: 3.839\n",
      "  timestamp: 1604403903\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6000\n",
      "  training_iteration: 12\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:45:08,074\tWARNING util.py:139 -- The `process_trial` operation took 3.6938250064849854 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:45:08,900\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.8249988555908203 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 8.4/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         566.924</td><td style=\"text-align: right;\">6000</td><td style=\"text-align: right;\">  2.7671</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "action_logp': np.ndarray((1,), dtype=float32, min=-555.448, max=-555.448, mean=-555.448),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=1.994, max=1.994, mean=1.994)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:45:28,330\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=7.51, max=2419.59, mean=115.001)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:45:28,330\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:45:43,165\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.123, max=0.179, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-578.652, max=-521.524, mean=-552.042),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.404, max=4.463, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-1.451, max=2.33, mean=-0.147),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=1690902110.0, max=1690902110.0, mean=1690902110.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4680.51, mean=124.335),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.986),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.404, max=4.463, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.179, mean=0.066),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.179, mean=0.066),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=12.0, max=12.0, mean=12.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.015, max=4.265, mean=2.544),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=0.157, max=4.388, mean=2.691)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:45:43,297\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.123, max=0.179, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-578.652, max=-521.524, mean=-552.042),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.404, max=4.463, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-1.451, max=2.33, mean=-0.147),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=1690902110.0, max=1690902110.0, mean=1690902110.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4680.51, mean=124.335),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.986),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.404, max=4.463, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.179, mean=0.066),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.179, mean=0.066),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=12.0, max=12.0, mean=12.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.015, max=4.265, mean=2.544),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=0.157, max=4.388, mean=2.691)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,831\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,831\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,831\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,831\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,831\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,831\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,831\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,831\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,831\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,831\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,831\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,831\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,833\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,844\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.23715925, 'policy_loss': 0.047136392, 'vf_loss': 0.18970685, 'vf_explained_var': 0.9251167, 'kl': 0.0007022391, 'entropy': 552.5549, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,854\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.07369066, 'policy_loss': -0.10146061, 'vf_loss': 0.17179395, 'vf_explained_var': 0.93221945, 'kl': 0.0074606943, 'entropy': 552.60175, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,864\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.042855855, 'policy_loss': -0.13206312, 'vf_loss': 0.16747983, 'vf_explained_var': 0.933315, 'kl': 0.016531484, 'entropy': 552.6462, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,874\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0341548, 'policy_loss': -0.13966484, 'vf_loss': 0.16293128, 'vf_explained_var': 0.9352233, 'kl': 0.024196407, 'entropy': 552.65533, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,885\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.028374672, 'policy_loss': -0.14229757, 'vf_loss': 0.15709375, 'vf_explained_var': 0.93768865, 'kl': 0.03017442, 'entropy': 552.64215, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,895\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.020806527, 'policy_loss': -0.1433679, 'vf_loss': 0.14918388, 'vf_explained_var': 0.9406857, 'kl': 0.033312295, 'entropy': 552.6094, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,905\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.025438681, 'policy_loss': -0.14437793, 'vf_loss': 0.15427686, 'vf_explained_var': 0.9390009, 'kl': 0.03453279, 'entropy': 552.56793, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,915\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.017982451, 'policy_loss': -0.14499791, 'vf_loss': 0.14719962, 'vf_explained_var': 0.9414411, 'kl': 0.035068378, 'entropy': 552.52423, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,925\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.01429603, 'policy_loss': -0.145492, 'vf_loss': 0.1439593, 'vf_explained_var': 0.94289714, 'kl': 0.035174932, 'entropy': 552.4873, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,936\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.012295979, 'policy_loss': -0.14572524, 'vf_loss': 0.14253934, 'vf_explained_var': 0.943279, 'kl': 0.0344042, 'entropy': 552.4627, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,949\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.008207467, 'policy_loss': -0.14587511, 'vf_loss': 0.13920383, 'vf_explained_var': 0.94457096, 'kl': 0.033063892, 'entropy': 552.45514, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,963\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0041316473, 'policy_loss': -0.14576197, 'vf_loss': 0.13567966, 'vf_explained_var': 0.94620275, 'kl': 0.03158653, 'entropy': 552.457, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,974\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0026361246, 'policy_loss': -0.14601147, 'vf_loss': 0.13520291, 'vf_explained_var': 0.9462528, 'kl': 0.029877106, 'entropy': 552.46796, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,984\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.00050604594, 'policy_loss': -0.14603478, 'vf_loss': 0.13387515, 'vf_explained_var': 0.94694144, 'kl': 0.02814594, 'entropy': 552.4833, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:43,994\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0035413664, 'policy_loss': -0.14608032, 'vf_loss': 0.13055755, 'vf_explained_var': 0.9482713, 'kl': 0.02662535, 'entropy': 552.4981, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,005\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0052668825, 'policy_loss': -0.14610066, 'vf_loss': 0.12948887, 'vf_explained_var': 0.94861215, 'kl': 0.025210908, 'entropy': 552.51105, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,014\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0068198093, 'policy_loss': -0.14609852, 'vf_loss': 0.1285749, 'vf_explained_var': 0.9489887, 'kl': 0.023786275, 'entropy': 552.5198, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,025\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.009519058, 'policy_loss': -0.14610067, 'vf_loss': 0.12648529, 'vf_explained_var': 0.94986486, 'kl': 0.022436276, 'entropy': 552.5267, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,035\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.009737526, 'policy_loss': -0.1461272, 'vf_loss': 0.12683219, 'vf_explained_var': 0.9496686, 'kl': 0.021238863, 'entropy': 552.5304, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,045\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.011756323, 'policy_loss': -0.14610086, 'vf_loss': 0.1252907, 'vf_explained_var': 0.9503159, 'kl': 0.02011961, 'entropy': 552.53094, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,056\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.013406836, 'policy_loss': -0.14615093, 'vf_loss': 0.12416334, 'vf_explained_var': 0.95072603, 'kl': 0.019068327, 'entropy': 552.5347, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,066\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.015524679, 'policy_loss': -0.14614132, 'vf_loss': 0.12249193, 'vf_explained_var': 0.9513016, 'kl': 0.018054908, 'entropy': 552.5379, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,076\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.015741978, 'policy_loss': -0.1461085, 'vf_loss': 0.12264929, 'vf_explained_var': 0.95123297, 'kl': 0.017149376, 'entropy': 552.5378, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,088\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.017905345, 'policy_loss': -0.1461481, 'vf_loss': 0.120882995, 'vf_explained_var': 0.95192903, 'kl': 0.016355015, 'entropy': 552.5378, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,099\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.019367445, 'policy_loss': -0.14616452, 'vf_loss': 0.11976028, 'vf_explained_var': 0.95245194, 'kl': 0.015637303, 'entropy': 552.53876, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,109\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.01998496, 'policy_loss': -0.14616318, 'vf_loss': 0.119445406, 'vf_explained_var': 0.9526085, 'kl': 0.014961831, 'entropy': 552.539, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,120\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.02174705, 'policy_loss': -0.14616328, 'vf_loss': 0.1179719, 'vf_explained_var': 0.95319825, 'kl': 0.014320786, 'entropy': 552.54065, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,131\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.023414144, 'policy_loss': -0.14616275, 'vf_loss': 0.11657617, 'vf_explained_var': 0.9536994, 'kl': 0.013716552, 'entropy': 552.54034, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,142\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.023192493, 'policy_loss': -0.14615668, 'vf_loss': 0.1170428, 'vf_explained_var': 0.9534388, 'kl': 0.013158634, 'entropy': 552.5379, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:45:44,152\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.023535391, 'policy_loss': -0.14615321, 'vf_loss': 0.11693909, 'vf_explained_var': 0.95350695, 'kl': 0.012619439, 'entropy': 552.5363, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-45-44\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.775115418854675\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 65\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5363159179688\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012619438581168652\n",
      "        model: {}\n",
      "        policy_loss: -0.14615321159362793\n",
      "        total_loss: -0.023535391315817833\n",
      "        vf_explained_var: 0.9535069465637207\n",
      "        vf_loss: 0.11693909019231796\n",
      "    num_steps_sampled: 6500\n",
      "    num_steps_trained: 6500\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.46666666666667\n",
      "    ram_util_percent: 57.473684210526315\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14697322447902358\n",
      "    mean_env_wait_ms: 506.8874603068221\n",
      "    mean_inference_ms: 1.3616927716674512\n",
      "    mean_raw_obs_processing_ms: 1.9845073855905035\n",
      "  time_since_restore: 603.0325162410736\n",
      "  time_this_iter_s: 36.10891079902649\n",
      "  time_total_s: 603.0325162410736\n",
      "  timers:\n",
      "    learn_throughput: 1314.203\n",
      "    learn_time_ms: 380.459\n",
      "    load_throughput: 103821.462\n",
      "    load_time_ms: 4.816\n",
      "    sample_throughput: 12.692\n",
      "    sample_time_ms: 39395.64\n",
      "    update_time_ms: 2.705\n",
      "  timestamp: 1604403944\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6500\n",
      "  training_iteration: 13\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:45:48,190\tWARNING util.py:139 -- The `process_trial` operation took 3.203415870666504 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:45:48,169\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:45:48,857\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.6665871143341064 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 9.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         603.033</td><td style=\"text-align: right;\">6500</td><td style=\"text-align: right;\"> 2.77512</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,048\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,059\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.23028517, 'policy_loss': 0.025837613, 'vf_loss': 0.20410444, 'vf_explained_var': 0.9314235, 'kl': 0.00076247356, 'entropy': 552.54614, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,070\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.03977662, 'policy_loss': -0.14281137, 'vf_loss': 0.17981865, 'vf_explained_var': 0.93872887, 'kl': 0.00615414, 'entropy': 552.53455, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,081\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.009281841, 'policy_loss': -0.1804068, 'vf_loss': 0.18356018, 'vf_explained_var': 0.9383056, 'kl': 0.013618712, 'entropy': 552.5411, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,091\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.01626766, 'policy_loss': -0.18952383, 'vf_loss': 0.16305876, 'vf_explained_var': 0.9442007, 'kl': 0.022660935, 'entropy': 552.5549, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,101\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.022652954, 'policy_loss': -0.19236898, 'vf_loss': 0.15616278, 'vf_explained_var': 0.94622916, 'kl': 0.030118315, 'entropy': 552.5542, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,111\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.015538161, 'policy_loss': -0.19364636, 'vf_loss': 0.16233762, 'vf_explained_var': 0.9435918, 'kl': 0.03504576, 'entropy': 552.5469, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,121\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.029113153, 'policy_loss': -0.1943835, 'vf_loss': 0.14845617, 'vf_explained_var': 0.9489643, 'kl': 0.037364785, 'entropy': 552.5325, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,130\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.029414361, 'policy_loss': -0.19463949, 'vf_loss': 0.14812452, 'vf_explained_var': 0.9487064, 'kl': 0.03800137, 'entropy': 552.513, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,140\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.035296503, 'policy_loss': -0.19486248, 'vf_loss': 0.14265308, 'vf_explained_var': 0.95051336, 'kl': 0.037584223, 'entropy': 552.4915, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,150\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.03850249, 'policy_loss': -0.19494355, 'vf_loss': 0.13987784, 'vf_explained_var': 0.951554, 'kl': 0.036807206, 'entropy': 552.4722, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,160\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.04442197, 'policy_loss': -0.19499199, 'vf_loss': 0.13459276, 'vf_explained_var': 0.9533321, 'kl': 0.035505064, 'entropy': 552.46106, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,170\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.046410054, 'policy_loss': -0.19501525, 'vf_loss': 0.13336629, 'vf_explained_var': 0.9536679, 'kl': 0.033864237, 'entropy': 552.45514, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,180\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.04972418, 'policy_loss': -0.19503017, 'vf_loss': 0.13083543, 'vf_explained_var': 0.9549415, 'kl': 0.03215681, 'entropy': 552.4544, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,190\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.05261752, 'policy_loss': -0.1950646, 'vf_loss': 0.12868354, 'vf_explained_var': 0.95555156, 'kl': 0.030585667, 'entropy': 552.4575, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,200\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.05388244, 'policy_loss': -0.19491243, 'vf_loss': 0.12790485, 'vf_explained_var': 0.9556256, 'kl': 0.029166982, 'entropy': 552.46295, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,210\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.056576073, 'policy_loss': -0.19503473, 'vf_loss': 0.12592964, 'vf_explained_var': 0.95613974, 'kl': 0.027842253, 'entropy': 552.4705, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,221\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.060831297, 'policy_loss': -0.19509359, 'vf_loss': 0.122315906, 'vf_explained_var': 0.9575837, 'kl': 0.02654755, 'entropy': 552.4771, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,232\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.061956305, 'policy_loss': -0.19507892, 'vf_loss': 0.12174643, 'vf_explained_var': 0.95768595, 'kl': 0.02528041, 'entropy': 552.4827, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,242\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06401203, 'policy_loss': -0.19511263, 'vf_loss': 0.12025228, 'vf_explained_var': 0.9582655, 'kl': 0.02410732, 'entropy': 552.4876, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,252\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06777136, 'policy_loss': -0.19512409, 'vf_loss': 0.11700065, 'vf_explained_var': 0.9593651, 'kl': 0.023004599, 'entropy': 552.4924, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,262\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06802703, 'policy_loss': -0.19510245, 'vf_loss': 0.11719499, 'vf_explained_var': 0.959265, 'kl': 0.021956505, 'entropy': 552.49713, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,272\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07001429, 'policy_loss': -0.19508469, 'vf_loss': 0.11563316, 'vf_explained_var': 0.9598654, 'kl': 0.02097161, 'entropy': 552.5015, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,283\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06985887, 'policy_loss': -0.19508319, 'vf_loss': 0.116137065, 'vf_explained_var': 0.9597087, 'kl': 0.020193871, 'entropy': 552.5008, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,293\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.072258405, 'policy_loss': -0.19513412, 'vf_loss': 0.1141269, 'vf_explained_var': 0.96036464, 'kl': 0.019441834, 'entropy': 552.5025, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,304\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.073301286, 'policy_loss': -0.19512664, 'vf_loss': 0.11342612, 'vf_explained_var': 0.96058303, 'kl': 0.018664984, 'entropy': 552.5078, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,315\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07532974, 'policy_loss': -0.19514112, 'vf_loss': 0.11174506, 'vf_explained_var': 0.9611458, 'kl': 0.017925141, 'entropy': 552.51483, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,326\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0763913, 'policy_loss': -0.1951344, 'vf_loss': 0.11100811, 'vf_explained_var': 0.96145755, 'kl': 0.017188858, 'entropy': 552.5214, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,337\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07584106, 'policy_loss': -0.19513017, 'vf_loss': 0.11188414, 'vf_explained_var': 0.96116924, 'kl': 0.01645551, 'entropy': 552.5316, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,348\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.077347785, 'policy_loss': -0.19514509, 'vf_loss': 0.110684186, 'vf_explained_var': 0.961713, 'kl': 0.015806904, 'entropy': 552.5411, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:46:23,359\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07832121, 'policy_loss': -0.19511753, 'vf_loss': 0.10993261, 'vf_explained_var': 0.96190494, 'kl': 0.015252677, 'entropy': 552.5482, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-46-23\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.7674314314001194\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 70\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5482177734375\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015252676792442799\n",
      "        model: {}\n",
      "        policy_loss: -0.1951175332069397\n",
      "        total_loss: -0.07832121104001999\n",
      "        vf_explained_var: 0.9619049429893494\n",
      "        vf_loss: 0.10993260890245438\n",
      "    num_steps_sampled: 7000\n",
      "    num_steps_trained: 7000\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.957142857142856\n",
      "    ram_util_percent: 61.34285714285714\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14531687069492383\n",
      "    mean_env_wait_ms: 501.02362680229083\n",
      "    mean_inference_ms: 1.3425027871220345\n",
      "    mean_raw_obs_processing_ms: 1.9687608680283721\n",
      "  time_since_restore: 638.2319140434265\n",
      "  time_this_iter_s: 35.199397802352905\n",
      "  time_total_s: 638.2319140434265\n",
      "  timers:\n",
      "    learn_throughput: 1384.024\n",
      "    learn_time_ms: 361.265\n",
      "    load_throughput: 113569.518\n",
      "    load_time_ms: 4.403\n",
      "    sample_throughput: 13.504\n",
      "    sample_time_ms: 37025.281\n",
      "    update_time_ms: 2.627\n",
      "  timestamp: 1604403983\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7000\n",
      "  training_iteration: 14\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:46:27,439\tWARNING util.py:139 -- The `process_trial` operation took 3.3175621032714844 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:46:28,172\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7321295738220215 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         638.232</td><td style=\"text-align: right;\">7000</td><td style=\"text-align: right;\"> 2.76743</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "592.206, max=-516.782, mean=-552.99),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.457, max=3.901, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-1.822, max=2.443, mean=-0.095),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=1401388473.0, max=1401388473.0, mean=1401388473.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4652.181, mean=124.136),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.795),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.457, max=3.901, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.18, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.18, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=14.0, max=14.0, mean=14.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.014, max=4.315, mean=2.58),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=-0.077, max=4.406, mean=2.675)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:47:02,097\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.179, max=0.187, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-592.206, max=-516.782, mean=-552.99),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.457, max=3.901, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-1.822, max=2.443, mean=-0.095),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=1401388473.0, max=1401388473.0, mean=1401388473.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4652.181, mean=124.136),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.795),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.457, max=3.901, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.18, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.18, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=14.0, max=14.0, mean=14.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.014, max=4.315, mean=2.58),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=-0.077, max=4.406, mean=2.675)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,575\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-4.457, max=4.208, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.054, max=0.18, mean=0.027),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.034),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.179, max=0.187, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-597.602, max=-515.847, mean=-552.526),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.457, max=4.208, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-6.855, max=6.261, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.034),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.457, max=4.208, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.054, max=0.18, mean=0.027),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.349, max=4.315, mean=0.771),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.591, max=4.406, mean=0.742)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,576\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,577\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,588\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.20763971, 'policy_loss': 0.05587411, 'vf_loss': 0.151302, 'vf_explained_var': 0.9469576, 'kl': 0.0010302746, 'entropy': 552.5615, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,598\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.05384933, 'policy_loss': -0.084815584, 'vf_loss': 0.13459986, 'vf_explained_var': 0.9531093, 'kl': 0.009033459, 'entropy': 552.62946, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,608\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.02331732, 'policy_loss': -0.119328044, 'vf_loss': 0.13439421, 'vf_explained_var': 0.9534227, 'kl': 0.018335853, 'entropy': 552.6997, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,620\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.013961767, 'policy_loss': -0.12755843, 'vf_loss': 0.1300954, 'vf_explained_var': 0.9553148, 'kl': 0.025388395, 'entropy': 552.74646, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,630\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.011524826, 'policy_loss': -0.12953465, 'vf_loss': 0.12738802, 'vf_explained_var': 0.95563126, 'kl': 0.03038101, 'entropy': 552.76996, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,641\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0061706826, 'policy_loss': -0.1320303, 'vf_loss': 0.12296, 'vf_explained_var': 0.9568906, 'kl': 0.03386876, 'entropy': 552.77435, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,651\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0059047616, 'policy_loss': -0.13280194, 'vf_loss': 0.12298008, 'vf_explained_var': 0.9577367, 'kl': 0.03494806, 'entropy': 552.7508, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,662\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0034187709, 'policy_loss': -0.13313954, 'vf_loss': 0.12082473, 'vf_explained_var': 0.95868236, 'kl': 0.034963477, 'entropy': 552.7046, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,672\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0013969665, 'policy_loss': -0.13328026, 'vf_loss': 0.11624045, 'vf_explained_var': 0.95962733, 'kl': 0.034761902, 'entropy': 552.6504, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,683\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0028573275, 'policy_loss': -0.1333418, 'vf_loss': 0.120834224, 'vf_explained_var': 0.959342, 'kl': 0.034144226, 'entropy': 552.6065, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,695\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.00053584576, 'policy_loss': -0.13344468, 'vf_loss': 0.11802888, 'vf_explained_var': 0.9602571, 'kl': 0.033066582, 'entropy': 552.58105, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,705\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0059887567, 'policy_loss': -0.13365413, 'vf_loss': 0.113392346, 'vf_explained_var': 0.9611387, 'kl': 0.0317179, 'entropy': 552.5728, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,715\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.009381925, 'policy_loss': -0.13378212, 'vf_loss': 0.11075759, 'vf_explained_var': 0.961651, 'kl': 0.030316874, 'entropy': 552.5759, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,725\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.012711276, 'policy_loss': -0.1337989, 'vf_loss': 0.10804218, 'vf_explained_var': 0.962445, 'kl': 0.028989904, 'entropy': 552.58203, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,735\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.014913251, 'policy_loss': -0.13388313, 'vf_loss': 0.10636524, 'vf_explained_var': 0.96331865, 'kl': 0.028010273, 'entropy': 552.5843, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,746\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.01712558, 'policy_loss': -0.13395518, 'vf_loss': 0.10470939, 'vf_explained_var': 0.96374744, 'kl': 0.02693379, 'entropy': 552.5886, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,757\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.01447134, 'policy_loss': -0.13399075, 'vf_loss': 0.107865095, 'vf_explained_var': 0.9627784, 'kl': 0.025898457, 'entropy': 552.59406, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,768\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.020273602, 'policy_loss': -0.13402103, 'vf_loss': 0.102561235, 'vf_explained_var': 0.96469647, 'kl': 0.024858236, 'entropy': 552.59546, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,779\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.019295221, 'policy_loss': -0.13404141, 'vf_loss': 0.103999704, 'vf_explained_var': 0.96434444, 'kl': 0.023881063, 'entropy': 552.5934, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,789\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.022128413, 'policy_loss': -0.13406517, 'vf_loss': 0.10162964, 'vf_explained_var': 0.964834, 'kl': 0.02290473, 'entropy': 552.5894, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,800\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.02146718, 'policy_loss': -0.13408089, 'vf_loss': 0.10272359, 'vf_explained_var': 0.96420723, 'kl': 0.021978064, 'entropy': 552.5847, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,811\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.024737157, 'policy_loss': -0.13409604, 'vf_loss': 0.09987531, 'vf_explained_var': 0.96543294, 'kl': 0.02107463, 'entropy': 552.58124, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,821\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.024714917, 'policy_loss': -0.13410714, 'vf_loss': 0.10029769, 'vf_explained_var': 0.96548194, 'kl': 0.020210074, 'entropy': 552.5793, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,832\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.026994133, 'policy_loss': -0.13411511, 'vf_loss': 0.098356865, 'vf_explained_var': 0.96587497, 'kl': 0.01947586, 'entropy': 552.5777, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,843\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.029987598, 'policy_loss': -0.13413364, 'vf_loss': 0.09570252, 'vf_explained_var': 0.96657974, 'kl': 0.01876338, 'entropy': 552.57794, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,854\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.028675504, 'policy_loss': -0.13413906, 'vf_loss': 0.09732145, 'vf_explained_var': 0.96620435, 'kl': 0.018093545, 'entropy': 552.57806, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,865\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.025591694, 'policy_loss': -0.13412027, 'vf_loss': 0.10068563, 'vf_explained_var': 0.965236, 'kl': 0.017428752, 'entropy': 552.5772, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,876\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.024687052, 'policy_loss': -0.13413563, 'vf_loss': 0.10186828, 'vf_explained_var': 0.964988, 'kl': 0.016845157, 'entropy': 552.5734, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,887\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.029718636, 'policy_loss': -0.13412367, 'vf_loss': 0.0970727, 'vf_explained_var': 0.9662531, 'kl': 0.01629405, 'entropy': 552.5676, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:02,897\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.029342659, 'policy_loss': -0.13407563, 'vf_loss': 0.097658806, 'vf_explained_var': 0.96613485, 'kl': 0.01572035, 'entropy': 552.5623, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-47-02\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.7628638968234362\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 75\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5623168945312\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015720350667834282\n",
      "        model: {}\n",
      "        policy_loss: -0.13407562673091888\n",
      "        total_loss: -0.029342658817768097\n",
      "        vf_explained_var: 0.9661348462104797\n",
      "        vf_loss: 0.09765880554914474\n",
      "    num_steps_sampled: 7500\n",
      "    num_steps_trained: 7500\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.489285714285717\n",
      "    ram_util_percent: 64.76428571428572\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14377354904553863\n",
      "    mean_env_wait_ms: 495.586989928704\n",
      "    mean_inference_ms: 1.324868068975893\n",
      "    mean_raw_obs_processing_ms: 1.9538108301542427\n",
      "  time_since_restore: 673.7192351818085\n",
      "  time_this_iter_s: 35.48732113838196\n",
      "  time_total_s: 673.7192351818085\n",
      "  timers:\n",
      "    learn_throughput: 1436.779\n",
      "    learn_time_ms: 348.001\n",
      "    load_throughput: 108769.495\n",
      "    load_time_ms: 4.597\n",
      "    sample_throughput: 14.176\n",
      "    sample_time_ms: 35271.072\n",
      "    update_time_ms: 2.547\n",
      "  timestamp: 1604404022\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7500\n",
      "  training_iteration: 15\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:47:06,897\tWARNING util.py:139 -- The `process_trial` operation took 3.2044970989227295 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:47:06,877\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:47:07,599\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7008881568908691 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         673.719</td><td style=\"text-align: right;\">7500</td><td style=\"text-align: right;\"> 2.76286</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,156\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,157\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,157\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,157\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,157\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,157\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,157\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,157\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,157\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,157\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,157\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,157\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,159\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,171\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.17088325, 'policy_loss': -0.022831315, 'vf_loss': 0.19328676, 'vf_explained_var': 0.9321351, 'kl': 0.0009506953, 'entropy': 552.5456, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,181\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.013268277, 'policy_loss': -0.16563077, 'vf_loss': 0.17490228, 'vf_explained_var': 0.9365361, 'kl': 0.008881764, 'entropy': 552.5186, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,192\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.029230276, 'policy_loss': -0.20679468, 'vf_loss': 0.16843228, 'vf_explained_var': 0.93956107, 'kl': 0.020293599, 'entropy': 552.5071, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,202\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.050687928, 'policy_loss': -0.21839957, 'vf_loss': 0.15476431, 'vf_explained_var': 0.94385546, 'kl': 0.028771812, 'entropy': 552.53314, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,213\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.050622594, 'policy_loss': -0.22465432, 'vf_loss': 0.1576811, 'vf_explained_var': 0.9431111, 'kl': 0.03633468, 'entropy': 552.56134, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,224\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.05725615, 'policy_loss': -0.22556292, 'vf_loss': 0.14951332, 'vf_explained_var': 0.9456963, 'kl': 0.041763216, 'entropy': 552.5881, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,235\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.05947231, 'policy_loss': -0.22738016, 'vf_loss': 0.14835298, 'vf_explained_var': 0.94621986, 'kl': 0.04345526, 'entropy': 552.6006, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,245\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06476086, 'policy_loss': -0.2279489, 'vf_loss': 0.14362486, 'vf_explained_var': 0.9479217, 'kl': 0.04347378, 'entropy': 552.6037, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,257\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.072395764, 'policy_loss': -0.22809392, 'vf_loss': 0.13642646, 'vf_explained_var': 0.9508019, 'kl': 0.042825956, 'entropy': 552.5993, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,268\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07152239, 'policy_loss': -0.22810785, 'vf_loss': 0.13776232, 'vf_explained_var': 0.9508516, 'kl': 0.04182917, 'entropy': 552.59454, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,280\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07197175, 'policy_loss': -0.22793235, 'vf_loss': 0.13794686, 'vf_explained_var': 0.9507026, 'kl': 0.040030517, 'entropy': 552.5997, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,291\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07793189, 'policy_loss': -0.22842425, 'vf_loss': 0.13320361, 'vf_explained_var': 0.95199746, 'kl': 0.03841947, 'entropy': 552.6075, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,307\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08228284, 'policy_loss': -0.22849183, 'vf_loss': 0.12934078, 'vf_explained_var': 0.9532492, 'kl': 0.037484903, 'entropy': 552.60394, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,320\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08639872, 'policy_loss': -0.2284723, 'vf_loss': 0.12592919, 'vf_explained_var': 0.9542853, 'kl': 0.03587646, 'entropy': 552.5974, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,331\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09423586, 'policy_loss': -0.22850095, 'vf_loss': 0.119224094, 'vf_explained_var': 0.95712733, 'kl': 0.033424452, 'entropy': 552.5905, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,342\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09273704, 'policy_loss': -0.2285099, 'vf_loss': 0.12182852, 'vf_explained_var': 0.9566915, 'kl': 0.030987479, 'entropy': 552.58453, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,353\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09686612, 'policy_loss': -0.22844873, 'vf_loss': 0.11858684, 'vf_explained_var': 0.9576535, 'kl': 0.028879479, 'entropy': 552.57886, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,364\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0994604, 'policy_loss': -0.22839397, 'vf_loss': 0.116652556, 'vf_explained_var': 0.95792025, 'kl': 0.027291158, 'entropy': 552.5752, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,375\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10154595, 'policy_loss': -0.22833927, 'vf_loss': 0.115128644, 'vf_explained_var': 0.95857334, 'kl': 0.025921518, 'entropy': 552.5769, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,386\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1043202, 'policy_loss': -0.22850494, 'vf_loss': 0.11312462, 'vf_explained_var': 0.95920986, 'kl': 0.024578, 'entropy': 552.5864, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,396\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1062252, 'policy_loss': -0.22856015, 'vf_loss': 0.11181035, 'vf_explained_var': 0.9595421, 'kl': 0.023387993, 'entropy': 552.59894, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,408\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10972186, 'policy_loss': -0.2285641, 'vf_loss': 0.108769596, 'vf_explained_var': 0.96086365, 'kl': 0.022383707, 'entropy': 552.6089, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,419\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.109885216, 'policy_loss': -0.22852893, 'vf_loss': 0.109005, 'vf_explained_var': 0.9606171, 'kl': 0.02141943, 'entropy': 552.6114, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,432\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.110895075, 'policy_loss': -0.22854678, 'vf_loss': 0.10841959, 'vf_explained_var': 0.9607912, 'kl': 0.020515824, 'entropy': 552.60925, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,443\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11295674, 'policy_loss': -0.22849059, 'vf_loss': 0.10667586, 'vf_explained_var': 0.9614806, 'kl': 0.019684369, 'entropy': 552.60516, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,454\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11463409, 'policy_loss': -0.22858995, 'vf_loss': 0.10541455, 'vf_explained_var': 0.961827, 'kl': 0.01898072, 'entropy': 552.60846, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,466\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.115127444, 'policy_loss': -0.22846802, 'vf_loss': 0.10502652, 'vf_explained_var': 0.96196413, 'kl': 0.01847565, 'entropy': 552.61053, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,478\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11688787, 'policy_loss': -0.22855224, 'vf_loss': 0.10360477, 'vf_explained_var': 0.9624975, 'kl': 0.017910233, 'entropy': 552.6065, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,489\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1177299, 'policy_loss': -0.22857405, 'vf_loss': 0.103027016, 'vf_explained_var': 0.9627289, 'kl': 0.017371422, 'entropy': 552.60095, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:47:43,501\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.118373536, 'policy_loss': -0.22860001, 'vf_loss': 0.1026763, 'vf_explained_var': 0.9627483, 'kl': 0.016778165, 'entropy': 552.59454, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-47-43\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.7689846013859185\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 80\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5945434570312\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016778165474534035\n",
      "        model: {}\n",
      "        policy_loss: -0.22860001027584076\n",
      "        total_loss: -0.11837353557348251\n",
      "        vf_explained_var: 0.9627482891082764\n",
      "        vf_loss: 0.10267630219459534\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 8000\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.796491228070174\n",
      "    ram_util_percent: 59.11052631578948\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14235259641973516\n",
      "    mean_env_wait_ms: 490.5823085003837\n",
      "    mean_inference_ms: 1.3087374493143393\n",
      "    mean_raw_obs_processing_ms: 1.9404353970416246\n",
      "  time_since_restore: 710.3536682128906\n",
      "  time_this_iter_s: 36.63443303108215\n",
      "  time_total_s: 710.3536682128906\n",
      "  timers:\n",
      "    learn_throughput: 1439.621\n",
      "    learn_time_ms: 347.314\n",
      "    load_throughput: 113160.772\n",
      "    load_time_ms: 4.418\n",
      "    sample_throughput: 14.213\n",
      "    sample_time_ms: 35179.311\n",
      "    update_time_ms: 2.543\n",
      "  timestamp: 1604404063\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 16\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:47:47,595\tWARNING util.py:139 -- The `process_trial` operation took 3.45133376121521 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:47:48,283\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.6874408721923828 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         710.354</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\"> 2.76898</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:48:06,892\tINFO sampler.py:800 -- Preprocessed obs: np.ndarray((389,), dtype=float64, min=7.15, max=2346.14, mean=110.246)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:48:06,892\tINFO sampler.py:805 -- Filtered obs: np.ndarray((389,), dtype=float64, min=7.15, max=2346.14, mean=110.246)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:48:06,892\tINFO sampler.py:1223 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'info': {},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'obs': np.ndarray((389,), dtype=float64, min=7.15, max=2346.14, mean=110.246),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_action': np.ndarray((389,), dtype=float32, min=-2.664, max=2.979, mean=-0.008),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_reward': 0.13785263261329983,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:48:06,892\tINFO tf_run_builder.py:87 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:48:06,894\tINFO sampler.py:1269 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': ( np.ndarray((1, 389), dtype=float32, min=-3.489, max=3.013, mean=0.004),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       { 'action_dist_inputs': np.ndarray((1, 778), dtype=float32, min=-0.052, max=0.04, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-542.331, max=-542.331, mean=-542.331),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=2.577, max=2.577, mean=2.577)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:48:07,255\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=7.15, max=2346.14, mean=110.178)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:48:07,255\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:48:29,273\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.176, max=0.202, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-578.782, max=-517.198, mean=-551.654),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.021, max=4.005, mean=0.007),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-1.072, max=2.564, mean=-0.086),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=1831054076.0, max=1831054076.0, mean=1831054076.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4717.036, mean=124.636),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.296),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.021, max=4.005, mean=0.007),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.181, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.181, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=16.0, max=16.0, mean=16.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.013, max=4.346, mean=2.58),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=0.033, max=4.595, mean=2.666)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:48:29,465\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.176, max=0.202, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-578.782, max=-517.198, mean=-551.654),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.021, max=4.005, mean=0.007),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-1.072, max=2.564, mean=-0.086),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=1831054076.0, max=1831054076.0, mean=1831054076.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4717.036, mean=124.636),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.296),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.021, max=4.005, mean=0.007),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.181, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.181, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=16.0, max=16.0, mean=16.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.013, max=4.346, mean=2.58),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=0.033, max=4.595, mean=2.666)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,212\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,234\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.16581039, 'policy_loss': 0.04359144, 'vf_loss': 0.12181324, 'vf_explained_var': 0.96015865, 'kl': 0.00090162974, 'entropy': 552.5992, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,246\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.009931943, 'policy_loss': -0.10171523, 'vf_loss': 0.10852239, 'vf_explained_var': 0.9631428, 'kl': 0.0069439397, 'entropy': 552.5523, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,260\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.031754505, 'policy_loss': -0.14501502, 'vf_loss': 0.1062735, 'vf_explained_var': 0.9637409, 'kl': 0.015526671, 'entropy': 552.48706, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,273\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.03945973, 'policy_loss': -0.15352546, 'vf_loss': 0.10289023, 'vf_explained_var': 0.96491355, 'kl': 0.024834437, 'entropy': 552.43134, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,287\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.045094013, 'policy_loss': -0.15715303, 'vf_loss': 0.098088406, 'vf_explained_var': 0.9668701, 'kl': 0.03104586, 'entropy': 552.37616, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,300\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.050080586, 'policy_loss': -0.15854488, 'vf_loss': 0.09274755, 'vf_explained_var': 0.96864104, 'kl': 0.034926128, 'entropy': 552.3416, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,313\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.052423086, 'policy_loss': -0.15926069, 'vf_loss': 0.09036082, 'vf_explained_var': 0.9695247, 'kl': 0.0366151, 'entropy': 552.3377, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,326\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.057287324, 'policy_loss': -0.15952916, 'vf_loss': 0.08564713, 'vf_explained_var': 0.97101474, 'kl': 0.03687716, 'entropy': 552.35547, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,341\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.062216837, 'policy_loss': -0.15964876, 'vf_loss': 0.08111343, 'vf_explained_var': 0.97251487, 'kl': 0.036263313, 'entropy': 552.38654, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,354\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.063521184, 'policy_loss': -0.15985392, 'vf_loss': 0.080491684, 'vf_explained_var': 0.9726958, 'kl': 0.035202358, 'entropy': 552.4191, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,368\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.060085803, 'policy_loss': -0.15984246, 'vf_loss': 0.084433734, 'vf_explained_var': 0.97144204, 'kl': 0.03405096, 'entropy': 552.44653, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,385\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.060745973, 'policy_loss': -0.15998721, 'vf_loss': 0.08458292, 'vf_explained_var': 0.9714363, 'kl': 0.032574043, 'entropy': 552.46497, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,402\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06187485, 'policy_loss': -0.16001469, 'vf_loss': 0.08413752, 'vf_explained_var': 0.971586, 'kl': 0.031116247, 'entropy': 552.4785, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,415\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06547648, 'policy_loss': -0.16001283, 'vf_loss': 0.08120261, 'vf_explained_var': 0.97255975, 'kl': 0.029630529, 'entropy': 552.4922, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,429\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06480287, 'policy_loss': -0.15996002, 'vf_loss': 0.08254223, 'vf_explained_var': 0.972013, 'kl': 0.028033154, 'entropy': 552.5053, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,441\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06612814, 'policy_loss': -0.1600288, 'vf_loss': 0.0819418, 'vf_explained_var': 0.9722512, 'kl': 0.026575252, 'entropy': 552.5166, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,453\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06912259, 'policy_loss': -0.1600777, 'vf_loss': 0.07960387, 'vf_explained_var': 0.97317666, 'kl': 0.025224978, 'entropy': 552.5301, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,465\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06841157, 'policy_loss': -0.16007075, 'vf_loss': 0.080848955, 'vf_explained_var': 0.97261477, 'kl': 0.024022723, 'entropy': 552.5407, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,478\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06996679, 'policy_loss': -0.16007717, 'vf_loss': 0.07981717, 'vf_explained_var': 0.97302294, 'kl': 0.022873754, 'entropy': 552.5486, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,492\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.071528055, 'policy_loss': -0.16008717, 'vf_loss': 0.078741446, 'vf_explained_var': 0.9734841, 'kl': 0.021817064, 'entropy': 552.5516, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,504\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07260103, 'policy_loss': -0.1600957, 'vf_loss': 0.078125484, 'vf_explained_var': 0.973639, 'kl': 0.020820424, 'entropy': 552.55054, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,516\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07343731, 'policy_loss': -0.16007845, 'vf_loss': 0.077672884, 'vf_explained_var': 0.97374517, 'kl': 0.01992946, 'entropy': 552.5501, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,528\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07612061, 'policy_loss': -0.16010225, 'vf_loss': 0.07539956, 'vf_explained_var': 0.9745431, 'kl': 0.019071283, 'entropy': 552.5546, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,540\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0731565, 'policy_loss': -0.16009907, 'vf_loss': 0.07872724, 'vf_explained_var': 0.9735327, 'kl': 0.018256346, 'entropy': 552.5629, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,553\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.076596774, 'policy_loss': -0.16010518, 'vf_loss': 0.075643286, 'vf_explained_var': 0.9745447, 'kl': 0.017478054, 'entropy': 552.5715, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,567\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08201885, 'policy_loss': -0.16000679, 'vf_loss': 0.07044505, 'vf_explained_var': 0.97626257, 'kl': 0.016761998, 'entropy': 552.57904, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,579\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.071385905, 'policy_loss': -0.1601197, 'vf_loss': 0.08146713, 'vf_explained_var': 0.9725506, 'kl': 0.01614816, 'entropy': 552.57886, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,591\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07697233, 'policy_loss': -0.16012417, 'vf_loss': 0.07616077, 'vf_explained_var': 0.97433764, 'kl': 0.015535687, 'entropy': 552.5762, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,604\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07456147, 'policy_loss': -0.16011782, 'vf_loss': 0.0788417, 'vf_explained_var': 0.9736206, 'kl': 0.014921469, 'entropy': 552.5736, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:48:30,616\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07903314, 'policy_loss': -0.16010289, 'vf_loss': 0.07460743, 'vf_explained_var': 0.97499007, 'kl': 0.014360726, 'entropy': 552.5726, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-48-30\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.762948638630463\n",
      "  episode_reward_min: -2.1876813561291266\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 85\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5725708007812\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01436072587966919\n",
      "        model: {}\n",
      "        policy_loss: -0.16010288894176483\n",
      "        total_loss: -0.07903313636779785\n",
      "        vf_explained_var: 0.9749900698661804\n",
      "        vf_loss: 0.07460743188858032\n",
      "    num_steps_sampled: 8500\n",
      "    num_steps_trained: 8500\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.34477611940299\n",
      "    ram_util_percent: 70.01044776119403\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14109816873780828\n",
      "    mean_env_wait_ms: 486.16916541387593\n",
      "    mean_inference_ms: 1.2944205338968915\n",
      "    mean_raw_obs_processing_ms: 1.9293605338358402\n",
      "  time_since_restore: 753.4180541038513\n",
      "  time_this_iter_s: 43.06438589096069\n",
      "  time_total_s: 753.4180541038513\n",
      "  timers:\n",
      "    learn_throughput: 1403.163\n",
      "    learn_time_ms: 356.338\n",
      "    load_throughput: 91405.459\n",
      "    load_time_ms: 5.47\n",
      "    sample_throughput: 13.909\n",
      "    sample_time_ms: 35948.654\n",
      "    update_time_ms: 2.955\n",
      "  timestamp: 1604404110\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8500\n",
      "  training_iteration: 17\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:48:35,811\tWARNING util.py:139 -- The `process_trial` operation took 4.155807733535767 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:48:35,787\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:48:36,860\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 1.0465929508209229 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 9.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         753.418</td><td style=\"text-align: right;\">8500</td><td style=\"text-align: right;\"> 2.76295</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.18768</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,598\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-4.5, max=4.256, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.061, max=0.181, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.182),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.194, max=0.19, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-615.963, max=-514.062, mean=-552.815),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.5, max=4.256, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-8.592, max=5.603, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.182),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.5, max=4.256, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.061, max=0.181, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.536, max=4.413, mean=0.811),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.646, max=4.542, mean=0.745)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,598\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,599\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,610\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.15896207, 'policy_loss': 0.00680474, 'vf_loss': 0.15176675, 'vf_explained_var': 0.94753677, 'kl': 0.00086796423, 'entropy': 552.57715, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,620\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.005843894, 'policy_loss': -0.1485985, 'vf_loss': 0.13974363, 'vf_explained_var': 0.9513615, 'kl': 0.006691076, 'entropy': 552.56903, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,631\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.04016387, 'policy_loss': -0.18035363, 'vf_loss': 0.13326168, 'vf_explained_var': 0.95332575, 'kl': 0.015395676, 'entropy': 552.59644, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,642\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.043205187, 'policy_loss': -0.18750997, 'vf_loss': 0.13322122, 'vf_explained_var': 0.9532201, 'kl': 0.024630114, 'entropy': 552.6191, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,654\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.048414882, 'policy_loss': -0.19121622, 'vf_loss': 0.12901665, 'vf_explained_var': 0.95462066, 'kl': 0.030632578, 'entropy': 552.63824, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,665\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.05049066, 'policy_loss': -0.1924993, 'vf_loss': 0.1265192, 'vf_explained_var': 0.95597035, 'kl': 0.034421, 'entropy': 552.6379, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,676\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.053967427, 'policy_loss': -0.1933706, 'vf_loss': 0.12298086, 'vf_explained_var': 0.95670813, 'kl': 0.036494024, 'entropy': 552.6195, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,686\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.060576055, 'policy_loss': -0.19373207, 'vf_loss': 0.1165105, 'vf_explained_var': 0.9588866, 'kl': 0.03699001, 'entropy': 552.5972, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,696\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06377377, 'policy_loss': -0.19396298, 'vf_loss': 0.11379958, 'vf_explained_var': 0.95989746, 'kl': 0.036421385, 'entropy': 552.57416, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,706\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.065121986, 'policy_loss': -0.19427662, 'vf_loss': 0.11325953, 'vf_explained_var': 0.960094, 'kl': 0.03532244, 'entropy': 552.55493, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,717\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06787158, 'policy_loss': -0.19436347, 'vf_loss': 0.11106395, 'vf_explained_var': 0.96079683, 'kl': 0.03428435, 'entropy': 552.54095, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,728\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07229854, 'policy_loss': -0.1944837, 'vf_loss': 0.10729563, 'vf_explained_var': 0.9620052, 'kl': 0.033087794, 'entropy': 552.5342, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,738\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07294919, 'policy_loss': -0.19452603, 'vf_loss': 0.10731474, 'vf_explained_var': 0.961998, 'kl': 0.03169353, 'entropy': 552.5347, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,748\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0742492, 'policy_loss': -0.19455747, 'vf_loss': 0.1067194, 'vf_explained_var': 0.96219635, 'kl': 0.030197479, 'entropy': 552.54065, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,758\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07988963, 'policy_loss': -0.19457303, 'vf_loss': 0.10181389, 'vf_explained_var': 0.9640166, 'kl': 0.028598865, 'entropy': 552.5506, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,770\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07849225, 'policy_loss': -0.19457944, 'vf_loss': 0.10390943, 'vf_explained_var': 0.96330255, 'kl': 0.027061656, 'entropy': 552.5601, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,781\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07922736, 'policy_loss': -0.19459003, 'vf_loss': 0.10387, 'vf_explained_var': 0.96333957, 'kl': 0.025539266, 'entropy': 552.5679, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,791\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.083880365, 'policy_loss': -0.19458576, 'vf_loss': 0.09980694, 'vf_explained_var': 0.96464133, 'kl': 0.02421876, 'entropy': 552.56934, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,802\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.087635554, 'policy_loss': -0.19462885, 'vf_loss': 0.09658287, 'vf_explained_var': 0.9658882, 'kl': 0.023134286, 'entropy': 552.56573, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,812\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08717462, 'policy_loss': -0.19464315, 'vf_loss': 0.09753666, 'vf_explained_var': 0.96546173, 'kl': 0.022070872, 'entropy': 552.5617, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,824\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08779958, 'policy_loss': -0.19465983, 'vf_loss': 0.097377926, 'vf_explained_var': 0.9655612, 'kl': 0.021071842, 'entropy': 552.5584, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,834\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08931752, 'policy_loss': -0.1946376, 'vf_loss': 0.09626167, 'vf_explained_var': 0.9659299, 'kl': 0.02012979, 'entropy': 552.55554, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,845\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09111603, 'policy_loss': -0.19468372, 'vf_loss': 0.094879806, 'vf_explained_var': 0.9664478, 'kl': 0.019306364, 'entropy': 552.5545, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,855\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09210086, 'policy_loss': -0.19468625, 'vf_loss': 0.09423814, 'vf_explained_var': 0.9666116, 'kl': 0.018549472, 'entropy': 552.55444, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,867\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.093021154, 'policy_loss': -0.19468075, 'vf_loss': 0.09364637, 'vf_explained_var': 0.9668457, 'kl': 0.017807141, 'entropy': 552.5547, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,878\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09382898, 'policy_loss': -0.19466253, 'vf_loss': 0.09313818, 'vf_explained_var': 0.9670108, 'kl': 0.01710079, 'entropy': 552.5562, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,890\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.095593356, 'policy_loss': -0.19468768, 'vf_loss': 0.09166943, 'vf_explained_var': 0.9675269, 'kl': 0.016499734, 'entropy': 552.55743, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,901\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09651291, 'policy_loss': -0.19468653, 'vf_loss': 0.09101831, 'vf_explained_var': 0.9677668, 'kl': 0.015900664, 'entropy': 552.55817, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,912\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.095641024, 'policy_loss': -0.19468372, 'vf_loss': 0.09214586, 'vf_explained_var': 0.9673583, 'kl': 0.015326244, 'entropy': 552.55884, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:13,923\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09664611, 'policy_loss': -0.194681, 'vf_loss': 0.091380455, 'vf_explained_var': 0.967627, 'kl': 0.014787614, 'entropy': 552.5601, 'entropy_coeff': 0.0, 'model': {}}\n",
      "2020-11-03 12:49:15,468\tWARNING util.py:139 -- The `fetch_result` operation took 0.7327742576599121 seconds to complete, which may be a performance bottleneck.\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-49-13\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.7643377253571\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 90\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5601196289062\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014787614345550537\n",
      "        model: {}\n",
      "        policy_loss: -0.19468100368976593\n",
      "        total_loss: -0.09664610773324966\n",
      "        vf_explained_var: 0.9676269888877869\n",
      "        vf_loss: 0.09138045459985733\n",
      "    num_steps_sampled: 9000\n",
      "    num_steps_trained: 9000\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.61639344262296\n",
      "    ram_util_percent: 60.77540983606557\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13993744200635916\n",
      "    mean_env_wait_ms: 482.1088625604098\n",
      "    mean_inference_ms: 1.2812619347022698\n",
      "    mean_raw_obs_processing_ms: 1.918738501380941\n",
      "  time_since_restore: 791.5652668476105\n",
      "  time_this_iter_s: 38.147212743759155\n",
      "  time_total_s: 791.5652668476105\n",
      "  timers:\n",
      "    learn_throughput: 1406.57\n",
      "    learn_time_ms: 355.475\n",
      "    load_throughput: 86558.665\n",
      "    load_time_ms: 5.776\n",
      "    sample_throughput: 13.776\n",
      "    sample_time_ms: 36295.998\n",
      "    update_time_ms: 2.926\n",
      "  timestamp: 1604404153\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9000\n",
      "  training_iteration: 18\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:49:18,516\tWARNING util.py:139 -- The `process_trial` operation took 3.7809040546417236 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:49:19,181\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.664125919342041 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         791.565</td><td style=\"text-align: right;\">9000</td><td style=\"text-align: right;\"> 2.76434</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "29361)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-551.493, max=-551.493, mean=-551.493),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=3.23, max=3.23, mean=3.23)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:49:36,169\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=7.1, max=2446.01, mean=118.295)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:49:36,169\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:49:54,467\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.217, max=0.194, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-575.496, max=-514.466, mean=-551.149),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-3.944, max=4.684, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-0.929, max=2.157, mean=-0.021),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=1669616716.0, max=1669616716.0, mean=1669616716.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4532.381, mean=124.278),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.939),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-3.944, max=4.684, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.18, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.18, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=18.0, max=18.0, mean=18.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.011, max=4.344, mean=2.546),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=0.019, max=4.491, mean=2.566)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:49:54,606\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.217, max=0.194, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-575.496, max=-514.466, mean=-551.149),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-3.944, max=4.684, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-0.929, max=2.157, mean=-0.021),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=1669616716.0, max=1669616716.0, mean=1669616716.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4532.381, mean=124.278),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.939),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-3.944, max=4.684, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.18, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.18, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=18.0, max=18.0, mean=18.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.011, max=4.344, mean=2.546),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=0.019, max=4.491, mean=2.566)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,129\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,130\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,130\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,130\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,130\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,130\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,130\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,130\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,130\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,130\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,130\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,130\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,133\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,149\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.10288631, 'policy_loss': -0.037239026, 'vf_loss': 0.13904485, 'vf_explained_var': 0.95019794, 'kl': 0.002401057, 'entropy': 552.55835, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,163\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.051048633, 'policy_loss': -0.18132634, 'vf_loss': 0.1226976, 'vf_explained_var': 0.9536632, 'kl': 0.016844744, 'entropy': 552.6495, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,176\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08624045, 'policy_loss': -0.21653776, 'vf_loss': 0.11812341, 'vf_explained_var': 0.95581055, 'kl': 0.02705316, 'entropy': 552.7585, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,189\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09883457, 'policy_loss': -0.23138809, 'vf_loss': 0.116467945, 'vf_explained_var': 0.95665, 'kl': 0.035745744, 'entropy': 552.78217, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,202\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10384139, 'policy_loss': -0.23792791, 'vf_loss': 0.11488632, 'vf_explained_var': 0.957218, 'kl': 0.042667124, 'entropy': 552.7437, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,215\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10985178, 'policy_loss': -0.23984313, 'vf_loss': 0.109250516, 'vf_explained_var': 0.959038, 'kl': 0.04609078, 'entropy': 552.6946, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,227\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11918175, 'policy_loss': -0.24101812, 'vf_loss': 0.100675106, 'vf_explained_var': 0.9620261, 'kl': 0.04702501, 'entropy': 552.6646, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,238\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12320948, 'policy_loss': -0.24151123, 'vf_loss': 0.097135395, 'vf_explained_var': 0.9633048, 'kl': 0.047036365, 'entropy': 552.63666, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,249\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12733673, 'policy_loss': -0.24219137, 'vf_loss': 0.093789846, 'vf_explained_var': 0.96465755, 'kl': 0.046810705, 'entropy': 552.62006, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,261\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12695272, 'policy_loss': -0.24227493, 'vf_loss': 0.094648, 'vf_explained_var': 0.9644361, 'kl': 0.04594266, 'entropy': 552.6074, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,273\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13011645, 'policy_loss': -0.24234861, 'vf_loss': 0.0923297, 'vf_explained_var': 0.9649582, 'kl': 0.044227704, 'entropy': 552.5954, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,285\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13375369, 'policy_loss': -0.24243486, 'vf_loss': 0.08968437, 'vf_explained_var': 0.9659317, 'kl': 0.042215098, 'entropy': 552.5818, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,296\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13532542, 'policy_loss': -0.2425025, 'vf_loss': 0.089021206, 'vf_explained_var': 0.9677679, 'kl': 0.04034637, 'entropy': 552.5767, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,308\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13846438, 'policy_loss': -0.24253933, 'vf_loss': 0.086765796, 'vf_explained_var': 0.9677629, 'kl': 0.03846479, 'entropy': 552.5784, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,321\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1402218, 'policy_loss': -0.24262424, 'vf_loss': 0.08591571, 'vf_explained_var': 0.96761894, 'kl': 0.03663718, 'entropy': 552.5774, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,332\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14161283, 'policy_loss': -0.24258246, 'vf_loss': 0.08527451, 'vf_explained_var': 0.96811754, 'kl': 0.034878056, 'entropy': 552.57733, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,344\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14256234, 'policy_loss': -0.24264109, 'vf_loss': 0.085087456, 'vf_explained_var': 0.9681325, 'kl': 0.033314, 'entropy': 552.582, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,356\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14592637, 'policy_loss': -0.24261947, 'vf_loss': 0.08234185, 'vf_explained_var': 0.9689024, 'kl': 0.031891704, 'entropy': 552.58734, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,370\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14967307, 'policy_loss': -0.24264343, 'vf_loss': 0.07928211, 'vf_explained_var': 0.97049826, 'kl': 0.030418342, 'entropy': 552.5861, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,383\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15264367, 'policy_loss': -0.24267454, 'vf_loss': 0.07702202, 'vf_explained_var': 0.97064734, 'kl': 0.028908586, 'entropy': 552.5806, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,396\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1560142, 'policy_loss': -0.24267717, 'vf_loss': 0.07426479, 'vf_explained_var': 0.9720631, 'kl': 0.027551584, 'entropy': 552.57184, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,408\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15364403, 'policy_loss': -0.24267842, 'vf_loss': 0.0771987, 'vf_explained_var': 0.9717455, 'kl': 0.02630155, 'entropy': 552.56396, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,422\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15366952, 'policy_loss': -0.24267228, 'vf_loss': 0.07770146, 'vf_explained_var': 0.9705643, 'kl': 0.02511401, 'entropy': 552.56354, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,434\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15712158, 'policy_loss': -0.2426744, 'vf_loss': 0.07472, 'vf_explained_var': 0.9720537, 'kl': 0.024072869, 'entropy': 552.56165, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,446\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1588294, 'policy_loss': -0.24249311, 'vf_loss': 0.07330711, 'vf_explained_var': 0.9722859, 'kl': 0.023014614, 'entropy': 552.5588, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,459\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16107833, 'policy_loss': -0.24262369, 'vf_loss': 0.07160843, 'vf_explained_var': 0.97304887, 'kl': 0.02208206, 'entropy': 552.56366, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,471\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16226013, 'policy_loss': -0.24264432, 'vf_loss': 0.07085721, 'vf_explained_var': 0.97364616, 'kl': 0.021171153, 'entropy': 552.5713, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,485\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16320843, 'policy_loss': -0.24235539, 'vf_loss': 0.07009854, 'vf_explained_var': 0.9736735, 'kl': 0.020107621, 'entropy': 552.57355, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,498\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1647249, 'policy_loss': -0.2426311, 'vf_loss': 0.06918418, 'vf_explained_var': 0.9740049, 'kl': 0.019382223, 'entropy': 552.5711, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:49:55,510\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16524643, 'policy_loss': -0.24264438, 'vf_loss': 0.06894221, 'vf_explained_var': 0.97412795, 'kl': 0.018790515, 'entropy': 552.5703, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-49-55\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.7758962314127476\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 95\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5703125\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018790515139698982\n",
      "        model: {}\n",
      "        policy_loss: -0.24264438450336456\n",
      "        total_loss: -0.16524642705917358\n",
      "        vf_explained_var: 0.9741279482841492\n",
      "        vf_loss: 0.06894221156835556\n",
      "    num_steps_sampled: 9500\n",
      "    num_steps_trained: 9500\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 35.23965517241379\n",
      "    ram_util_percent: 65.80689655172414\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13886797128383654\n",
      "    mean_env_wait_ms: 478.3263785207851\n",
      "    mean_inference_ms: 1.2691401245339011\n",
      "    mean_raw_obs_processing_ms: 1.9087246302351795\n",
      "  time_since_restore: 828.5906817913055\n",
      "  time_this_iter_s: 37.02541494369507\n",
      "  time_total_s: 828.5906817913055\n",
      "  timers:\n",
      "    learn_throughput: 1396.768\n",
      "    learn_time_ms: 357.969\n",
      "    load_throughput: 87322.027\n",
      "    load_time_ms: 5.726\n",
      "    sample_throughput: 13.735\n",
      "    sample_time_ms: 36402.514\n",
      "    update_time_ms: 2.887\n",
      "  timestamp: 1604404195\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9500\n",
      "  training_iteration: 19\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:49:59,774\tWARNING util.py:139 -- The `process_trial` operation took 3.6340930461883545 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:49:59,752\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:50:00,557\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7826941013336182 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         828.591</td><td style=\"text-align: right;\">9500</td><td style=\"text-align: right;\">  2.7759</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,381\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,394\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.13788275, 'policy_loss': 0.018760199, 'vf_loss': 0.11880831, 'vf_explained_var': 0.95845574, 'kl': 0.0006982726, 'entropy': 552.5795, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,406\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.011318437, 'policy_loss': -0.12748474, 'vf_loss': 0.11266497, 'vf_explained_var': 0.95992154, 'kl': 0.0077807135, 'entropy': 552.5658, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,417\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.04892532, 'policy_loss': -0.16634245, 'vf_loss': 0.109536506, 'vf_explained_var': 0.96090764, 'kl': 0.017512498, 'entropy': 552.5677, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,426\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.060881, 'policy_loss': -0.1765952, 'vf_loss': 0.10441866, 'vf_explained_var': 0.9624775, 'kl': 0.02510117, 'entropy': 552.5891, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,437\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06141684, 'policy_loss': -0.17873086, 'vf_loss': 0.10300007, 'vf_explained_var': 0.9630738, 'kl': 0.031808805, 'entropy': 552.621, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,447\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.062858425, 'policy_loss': -0.18031366, 'vf_loss': 0.10138404, 'vf_explained_var': 0.96374846, 'kl': 0.035713766, 'entropy': 552.63275, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,459\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06334871, 'policy_loss': -0.18160427, 'vf_loss': 0.1012845, 'vf_explained_var': 0.9638297, 'kl': 0.037713494, 'entropy': 552.61896, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,471\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.070239834, 'policy_loss': -0.18195663, 'vf_loss': 0.09422056, 'vf_explained_var': 0.96632797, 'kl': 0.03888051, 'entropy': 552.60284, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,481\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.067385375, 'policy_loss': -0.18217196, 'vf_loss': 0.09716031, 'vf_explained_var': 0.9652608, 'kl': 0.03916951, 'entropy': 552.5893, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,492\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06955485, 'policy_loss': -0.18225063, 'vf_loss': 0.09548185, 'vf_explained_var': 0.9660526, 'kl': 0.038253214, 'entropy': 552.5854, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,502\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07569563, 'policy_loss': -0.18231876, 'vf_loss': 0.09001962, 'vf_explained_var': 0.9677129, 'kl': 0.036896683, 'entropy': 552.5887, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,513\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0788426, 'policy_loss': -0.18235905, 'vf_loss': 0.087538876, 'vf_explained_var': 0.968833, 'kl': 0.0355057, 'entropy': 552.59064, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,524\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08010165, 'policy_loss': -0.18240869, 'vf_loss': 0.08709353, 'vf_explained_var': 0.968762, 'kl': 0.033807814, 'entropy': 552.59, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,535\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.082689606, 'policy_loss': -0.18239921, 'vf_loss': 0.08525568, 'vf_explained_var': 0.96947956, 'kl': 0.032119837, 'entropy': 552.5898, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,545\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.084128164, 'policy_loss': -0.18247168, 'vf_loss': 0.08458921, 'vf_explained_var': 0.96975446, 'kl': 0.030565113, 'entropy': 552.5922, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,556\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08723787, 'policy_loss': -0.18247955, 'vf_loss': 0.08212218, 'vf_explained_var': 0.9705341, 'kl': 0.02915443, 'entropy': 552.597, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,566\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.088575274, 'policy_loss': -0.18247892, 'vf_loss': 0.0813807, 'vf_explained_var': 0.97075766, 'kl': 0.027828753, 'entropy': 552.602, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,576\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09296345, 'policy_loss': -0.18247385, 'vf_loss': 0.077523686, 'vf_explained_var': 0.97213006, 'kl': 0.026637143, 'entropy': 552.6059, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,586\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.092011094, 'policy_loss': -0.18244861, 'vf_loss': 0.07892694, 'vf_explained_var': 0.9716482, 'kl': 0.025579045, 'entropy': 552.607, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,597\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09473158, 'policy_loss': -0.18247966, 'vf_loss': 0.07669861, 'vf_explained_var': 0.97243214, 'kl': 0.024554444, 'entropy': 552.6074, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,608\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.094494335, 'policy_loss': -0.18251507, 'vf_loss': 0.07743219, 'vf_explained_var': 0.97231436, 'kl': 0.02353006, 'entropy': 552.6082, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,619\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09614573, 'policy_loss': -0.18252079, 'vf_loss': 0.076210715, 'vf_explained_var': 0.9726501, 'kl': 0.022587387, 'entropy': 552.60895, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,629\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09595558, 'policy_loss': -0.18251292, 'vf_loss': 0.076787144, 'vf_explained_var': 0.9726097, 'kl': 0.021711523, 'entropy': 552.61066, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,639\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.098256946, 'policy_loss': -0.18249826, 'vf_loss': 0.07483988, 'vf_explained_var': 0.97320575, 'kl': 0.020892039, 'entropy': 552.6122, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,650\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09977874, 'policy_loss': -0.18252283, 'vf_loss': 0.07368191, 'vf_explained_var': 0.9736034, 'kl': 0.020138161, 'entropy': 552.6094, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,662\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09876571, 'policy_loss': -0.18252085, 'vf_loss': 0.07502337, 'vf_explained_var': 0.9731702, 'kl': 0.01940394, 'entropy': 552.60785, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,673\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.100703485, 'policy_loss': -0.18253689, 'vf_loss': 0.073417164, 'vf_explained_var': 0.97368723, 'kl': 0.018702712, 'entropy': 552.6082, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,684\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.101265185, 'policy_loss': -0.18253507, 'vf_loss': 0.07315261, 'vf_explained_var': 0.9737709, 'kl': 0.018038418, 'entropy': 552.6104, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,694\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10229959, 'policy_loss': -0.18253882, 'vf_loss': 0.07240071, 'vf_explained_var': 0.9740216, 'kl': 0.01741893, 'entropy': 552.6123, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:50:37,705\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1030531, 'policy_loss': -0.18254256, 'vf_loss': 0.07190893, 'vf_explained_var': 0.974205, 'kl': 0.016845638, 'entropy': 552.61584, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-50-37\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.7793521610707286\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 100\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6158447265625\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016845637932419777\n",
      "        model: {}\n",
      "        policy_loss: -0.1825425624847412\n",
      "        total_loss: -0.10305310040712357\n",
      "        vf_explained_var: 0.9742050170898438\n",
      "        vf_loss: 0.07190892845392227\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 10000\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.599999999999994\n",
      "    ram_util_percent: 63.649999999999984\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13787621296931357\n",
      "    mean_env_wait_ms: 474.81909255366156\n",
      "    mean_inference_ms: 1.257975337771357\n",
      "    mean_raw_obs_processing_ms: 1.8990335937051999\n",
      "  time_since_restore: 866.5544648170471\n",
      "  time_this_iter_s: 37.96378302574158\n",
      "  time_total_s: 866.5544648170471\n",
      "  timers:\n",
      "    learn_throughput: 1395.173\n",
      "    learn_time_ms: 358.378\n",
      "    load_throughput: 88428.101\n",
      "    load_time_ms: 5.654\n",
      "    sample_throughput: 13.642\n",
      "    sample_time_ms: 36650.711\n",
      "    update_time_ms: 2.866\n",
      "  timestamp: 1604404237\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 20\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:50:41,753\tWARNING util.py:139 -- The `process_trial` operation took 3.2406089305877686 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:50:42,483\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.728708028793335 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 9.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         866.554</td><td style=\"text-align: right;\">10000</td><td style=\"text-align: right;\"> 2.77935</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "loat32, min=-577.985, max=-523.958, mean=-551.152),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.181, max=4.289, mean=0.008),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-1.652, max=2.047, mean=-0.035),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=568288034.0, max=568288034.0, mean=568288034.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4774.819, mean=125.166),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.765),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.181, max=4.289, mean=0.007),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.18, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.18, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=20.0, max=20.0, mean=20.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.016, max=4.392, mean=2.624),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=0.013, max=4.394, mean=2.658)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:51:19,754\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.196, max=0.229, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-577.985, max=-523.958, mean=-551.152),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.181, max=4.289, mean=0.008),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-1.652, max=2.047, mean=-0.035),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=568288034.0, max=568288034.0, mean=568288034.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4774.819, mean=125.166),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.765),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.181, max=4.289, mean=0.007),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.18, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.18, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=20.0, max=20.0, mean=20.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.016, max=4.392, mean=2.624),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=0.013, max=4.394, mean=2.658)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,445\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-4.492, max=4.289, mean=0.006),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.058, max=0.18, mean=0.026),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=129.924),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.196, max=0.229, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-594.563, max=-517.881, mean=-552.515),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.492, max=4.289, mean=0.006),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-8.202, max=5.901, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=129.924),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.492, max=4.289, mean=0.006),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.058, max=0.18, mean=0.026),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.409, max=4.392, mean=0.718),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.458, max=4.394, mean=0.822)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,445\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,446\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,459\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.16864704, 'policy_loss': 0.025127957, 'vf_loss': 0.14271422, 'vf_explained_var': 0.94973093, 'kl': 0.001788579, 'entropy': 552.6442, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,479\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.004841859, 'policy_loss': -0.13098738, 'vf_loss': 0.121201076, 'vf_explained_var': 0.9560959, 'kl': 0.010987642, 'entropy': 552.6602, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,493\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.04624489, 'policy_loss': -0.1709764, 'vf_loss': 0.115400515, 'vf_explained_var': 0.95779437, 'kl': 0.020735543, 'entropy': 552.6719, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,506\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.053880885, 'policy_loss': -0.18266542, 'vf_loss': 0.116178535, 'vf_explained_var': 0.95742255, 'kl': 0.028013436, 'entropy': 552.63763, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,520\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.054566905, 'policy_loss': -0.1866845, 'vf_loss': 0.11670446, 'vf_explained_var': 0.9572305, 'kl': 0.034251478, 'entropy': 552.58575, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,533\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06398268, 'policy_loss': -0.18813567, 'vf_loss': 0.106861174, 'vf_explained_var': 0.96052337, 'kl': 0.0384262, 'entropy': 552.53625, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,546\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06761764, 'policy_loss': -0.18972825, 'vf_loss': 0.10391122, 'vf_explained_var': 0.96156025, 'kl': 0.04044311, 'entropy': 552.49567, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,560\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07077917, 'policy_loss': -0.19008757, 'vf_loss': 0.100717135, 'vf_explained_var': 0.9625756, 'kl': 0.041313957, 'entropy': 552.46356, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,573\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.079574846, 'policy_loss': -0.1902988, 'vf_loss': 0.09214037, 'vf_explained_var': 0.96574736, 'kl': 0.04129685, 'entropy': 552.4442, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,586\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08116407, 'policy_loss': -0.1904064, 'vf_loss': 0.09102851, 'vf_explained_var': 0.9660015, 'kl': 0.040475164, 'entropy': 552.43915, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,599\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.085170664, 'policy_loss': -0.19041796, 'vf_loss': 0.08756563, 'vf_explained_var': 0.9672625, 'kl': 0.039292615, 'entropy': 552.4443, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,612\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08658435, 'policy_loss': -0.19041783, 'vf_loss': 0.08677287, 'vf_explained_var': 0.9676318, 'kl': 0.037912473, 'entropy': 552.45386, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,623\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08921939, 'policy_loss': -0.19045325, 'vf_loss': 0.08490816, 'vf_explained_var': 0.96826094, 'kl': 0.03627934, 'entropy': 552.4686, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,635\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09058408, 'policy_loss': -0.19046015, 'vf_loss': 0.08431431, 'vf_explained_var': 0.968435, 'kl': 0.034581695, 'entropy': 552.4914, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,648\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09277937, 'policy_loss': -0.19046779, 'vf_loss': 0.0828472, 'vf_explained_var': 0.96899575, 'kl': 0.03298054, 'entropy': 552.5161, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,660\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09436885, 'policy_loss': -0.1904865, 'vf_loss': 0.08201109, 'vf_explained_var': 0.96935993, 'kl': 0.03134793, 'entropy': 552.53986, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,672\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09777173, 'policy_loss': -0.1904999, 'vf_loss': 0.07935, 'vf_explained_var': 0.97034234, 'kl': 0.029729294, 'entropy': 552.5588, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,684\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.098917045, 'policy_loss': -0.19042747, 'vf_loss': 0.07883907, 'vf_explained_var': 0.97050184, 'kl': 0.028158516, 'entropy': 552.57367, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,697\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10160044, 'policy_loss': -0.19053717, 'vf_loss': 0.07682059, 'vf_explained_var': 0.97122437, 'kl': 0.026924787, 'entropy': 552.5783, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,710\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10264971, 'policy_loss': -0.19054063, 'vf_loss': 0.07628844, 'vf_explained_var': 0.97144604, 'kl': 0.02578327, 'entropy': 552.58057, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,723\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10349476, 'policy_loss': -0.19054966, 'vf_loss': 0.07598654, 'vf_explained_var': 0.9715719, 'kl': 0.024596347, 'entropy': 552.58453, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,736\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11054953, 'policy_loss': -0.19041705, 'vf_loss': 0.06937235, 'vf_explained_var': 0.97411793, 'kl': 0.023322627, 'entropy': 552.5916, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,748\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1047734, 'policy_loss': -0.19025593, 'vf_loss': 0.07550738, 'vf_explained_var': 0.9717652, 'kl': 0.022167003, 'entropy': 552.5969, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,760\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.106312454, 'policy_loss': -0.19051377, 'vf_loss': 0.07457631, 'vf_explained_var': 0.97209436, 'kl': 0.021388957, 'entropy': 552.59247, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,772\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.106057666, 'policy_loss': -0.19053519, 'vf_loss': 0.07525069, 'vf_explained_var': 0.9718663, 'kl': 0.020504104, 'entropy': 552.6005, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,785\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10770606, 'policy_loss': -0.19052567, 'vf_loss': 0.07400868, 'vf_explained_var': 0.9723522, 'kl': 0.019579835, 'entropy': 552.6087, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,797\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10939956, 'policy_loss': -0.19051379, 'vf_loss': 0.07265612, 'vf_explained_var': 0.9728088, 'kl': 0.018795786, 'entropy': 552.61084, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,810\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.109045446, 'policy_loss': -0.19054155, 'vf_loss': 0.07332587, 'vf_explained_var': 0.97256947, 'kl': 0.018156031, 'entropy': 552.60913, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,823\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10997858, 'policy_loss': -0.19053884, 'vf_loss': 0.07269519, 'vf_explained_var': 0.97281283, 'kl': 0.017477991, 'entropy': 552.61163, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:51:20,835\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.111007124, 'policy_loss': -0.19053668, 'vf_loss': 0.07196403, 'vf_explained_var': 0.97311354, 'kl': 0.016812276, 'entropy': 552.61554, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-51-20\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.768836929949698\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 105\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6155395507812\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0168122760951519\n",
      "        model: {}\n",
      "        policy_loss: -0.19053667783737183\n",
      "        total_loss: -0.11100712418556213\n",
      "        vf_explained_var: 0.9731135368347168\n",
      "        vf_loss: 0.07196403294801712\n",
      "    num_steps_sampled: 10500\n",
      "    num_steps_trained: 10500\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.71774193548387\n",
      "    ram_util_percent: 63.85322580645161\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13618602970723734\n",
      "    mean_env_wait_ms: 467.4989838830317\n",
      "    mean_inference_ms: 1.220251644005315\n",
      "    mean_raw_obs_processing_ms: 1.8906343098407594\n",
      "  time_since_restore: 905.6669750213623\n",
      "  time_this_iter_s: 39.112510204315186\n",
      "  time_total_s: 905.6669750213623\n",
      "  timers:\n",
      "    learn_throughput: 1375.246\n",
      "    learn_time_ms: 363.571\n",
      "    load_throughput: 84623.66\n",
      "    load_time_ms: 5.909\n",
      "    sample_throughput: 13.499\n",
      "    sample_time_ms: 37039.801\n",
      "    update_time_ms: 2.89\n",
      "  timestamp: 1604404280\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10500\n",
      "  training_iteration: 21\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:51:25,505\tWARNING util.py:139 -- The `process_trial` operation took 3.771239995956421 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:51:25,480\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:51:26,222\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7166028022766113 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.4/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         905.667</td><td style=\"text-align: right;\">10500</td><td style=\"text-align: right;\"> 2.76884</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,918\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,918\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,918\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,918\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,918\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,918\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,919\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,919\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,919\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,919\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,919\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,919\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,923\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,934\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.11085156, 'policy_loss': -0.002327266, 'vf_loss': 0.11271682, 'vf_explained_var': 0.96401185, 'kl': 0.0010266837, 'entropy': 552.58624, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,945\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.035216942, 'policy_loss': -0.14530517, 'vf_loss': 0.10647174, 'vf_explained_var': 0.9656272, 'kl': 0.008036642, 'entropy': 552.60767, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,956\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07975557, 'policy_loss': -0.19020395, 'vf_loss': 0.10289129, 'vf_explained_var': 0.96669674, 'kl': 0.016793532, 'entropy': 552.5695, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,967\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08476346, 'policy_loss': -0.20151468, 'vf_loss': 0.10533751, 'vf_explained_var': 0.9659597, 'kl': 0.025363773, 'entropy': 552.53937, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,978\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.089008816, 'policy_loss': -0.20479505, 'vf_loss': 0.10139143, 'vf_explained_var': 0.96698886, 'kl': 0.0319885, 'entropy': 552.52374, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,988\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09659454, 'policy_loss': -0.20605488, 'vf_loss': 0.09323239, 'vf_explained_var': 0.9694461, 'kl': 0.0360622, 'entropy': 552.51166, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:03,999\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09750683, 'policy_loss': -0.2067524, 'vf_loss': 0.09222865, 'vf_explained_var': 0.97020674, 'kl': 0.037815362, 'entropy': 552.5074, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,010\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10095602, 'policy_loss': -0.20725171, 'vf_loss': 0.08919815, 'vf_explained_var': 0.97121733, 'kl': 0.037994567, 'entropy': 552.5109, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,021\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10469221, 'policy_loss': -0.20738876, 'vf_loss': 0.08593318, 'vf_explained_var': 0.972116, 'kl': 0.037251953, 'entropy': 552.5203, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,032\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10749645, 'policy_loss': -0.20752303, 'vf_loss': 0.08371975, 'vf_explained_var': 0.97303814, 'kl': 0.036237437, 'entropy': 552.5334, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,042\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11107967, 'policy_loss': -0.20754041, 'vf_loss': 0.08059064, 'vf_explained_var': 0.97390604, 'kl': 0.035266876, 'entropy': 552.5454, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,053\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11225661, 'policy_loss': -0.20790552, 'vf_loss': 0.080263965, 'vf_explained_var': 0.9741256, 'kl': 0.034188792, 'entropy': 552.55176, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,064\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11442131, 'policy_loss': -0.20801212, 'vf_loss': 0.078782864, 'vf_explained_var': 0.97468233, 'kl': 0.032906562, 'entropy': 552.5488, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,075\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11626669, 'policy_loss': -0.20807363, 'vf_loss': 0.07762241, 'vf_explained_var': 0.9751282, 'kl': 0.031521183, 'entropy': 552.5422, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,086\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.119760774, 'policy_loss': -0.20810683, 'vf_loss': 0.07477668, 'vf_explained_var': 0.97600204, 'kl': 0.030154161, 'entropy': 552.53876, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,098\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.121004105, 'policy_loss': -0.20814395, 'vf_loss': 0.074170254, 'vf_explained_var': 0.9762976, 'kl': 0.02882134, 'entropy': 552.5406, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,110\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12193505, 'policy_loss': -0.2080587, 'vf_loss': 0.073748305, 'vf_explained_var': 0.976346, 'kl': 0.027500741, 'entropy': 552.5461, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,121\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12205469, 'policy_loss': -0.20817614, 'vf_loss': 0.0742787, 'vf_explained_var': 0.9763914, 'kl': 0.026317248, 'entropy': 552.5532, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,132\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12491716, 'policy_loss': -0.20818336, 'vf_loss': 0.07190647, 'vf_explained_var': 0.9770953, 'kl': 0.02524391, 'entropy': 552.55524, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,143\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1235137, 'policy_loss': -0.2081774, 'vf_loss': 0.07375043, 'vf_explained_var': 0.9763848, 'kl': 0.024251735, 'entropy': 552.5557, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,154\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12546171, 'policy_loss': -0.20818496, 'vf_loss': 0.07227091, 'vf_explained_var': 0.97693044, 'kl': 0.023227448, 'entropy': 552.55634, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,166\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12653919, 'policy_loss': -0.2081725, 'vf_loss': 0.07164673, 'vf_explained_var': 0.9771698, 'kl': 0.022192346, 'entropy': 552.5561, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,180\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12652458, 'policy_loss': -0.20818251, 'vf_loss': 0.072088934, 'vf_explained_var': 0.97697836, 'kl': 0.021264425, 'entropy': 552.55536, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,191\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12766968, 'policy_loss': -0.20817626, 'vf_loss': 0.07131762, 'vf_explained_var': 0.9774227, 'kl': 0.020419916, 'entropy': 552.5543, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,203\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12882592, 'policy_loss': -0.20817775, 'vf_loss': 0.07051487, 'vf_explained_var': 0.9774465, 'kl': 0.01963774, 'entropy': 552.5594, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,214\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12872519, 'policy_loss': -0.20815082, 'vf_loss': 0.070923164, 'vf_explained_var': 0.9773331, 'kl': 0.018894402, 'entropy': 552.56586, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,225\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13045198, 'policy_loss': -0.20817357, 'vf_loss': 0.06947235, 'vf_explained_var': 0.97783214, 'kl': 0.018331693, 'entropy': 552.5711, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,237\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13053936, 'policy_loss': -0.20818943, 'vf_loss': 0.06959287, 'vf_explained_var': 0.977807, 'kl': 0.017904883, 'entropy': 552.5727, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,249\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13059078, 'policy_loss': -0.2081867, 'vf_loss': 0.06979001, 'vf_explained_var': 0.9777728, 'kl': 0.017346492, 'entropy': 552.5684, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:04,260\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13121606, 'policy_loss': -0.20815958, 'vf_loss': 0.069395036, 'vf_explained_var': 0.977959, 'kl': 0.016774407, 'entropy': 552.5638, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-52-04\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.779313358050141\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 110\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5637817382812\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016774406656622887\n",
      "        model: {}\n",
      "        policy_loss: -0.20815958082675934\n",
      "        total_loss: -0.13121606409549713\n",
      "        vf_explained_var: 0.9779589772224426\n",
      "        vf_loss: 0.0693950355052948\n",
      "    num_steps_sampled: 11000\n",
      "    num_steps_trained: 11000\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.85737704918033\n",
      "    ram_util_percent: 72.48688524590163\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1346438604626454\n",
      "    mean_env_wait_ms: 460.48559990826584\n",
      "    mean_inference_ms: 1.1959120001127426\n",
      "    mean_raw_obs_processing_ms: 1.8816023656093588\n",
      "  time_since_restore: 944.4564254283905\n",
      "  time_this_iter_s: 38.7894504070282\n",
      "  time_total_s: 944.4564254283905\n",
      "  timers:\n",
      "    learn_throughput: 1447.945\n",
      "    learn_time_ms: 345.317\n",
      "    load_throughput: 114783.503\n",
      "    load_time_ms: 4.356\n",
      "    sample_throughput: 13.372\n",
      "    sample_time_ms: 37392.611\n",
      "    update_time_ms: 2.522\n",
      "  timestamp: 1604404324\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11000\n",
      "  training_iteration: 22\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:52:08,648\tWARNING util.py:139 -- The `process_trial` operation took 3.4540469646453857 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:52:09,405\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7556579113006592 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         944.456</td><td style=\"text-align: right;\">11000</td><td style=\"text-align: right;\"> 2.77931</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:52:25,601\tINFO sampler.py:800 -- Preprocessed obs: np.ndarray((389,), dtype=float64, min=7.2, max=2441.93, mean=122.024)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:52:25,603\tINFO sampler.py:805 -- Filtered obs: np.ndarray((389,), dtype=float64, min=7.2, max=2441.93, mean=122.024)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:52:25,604\tINFO sampler.py:1223 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'info': {},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'obs': np.ndarray((389,), dtype=float64, min=7.2, max=2441.93, mean=122.024),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_action': np.ndarray((389,), dtype=float32, min=-2.815, max=3.216, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_reward': 0.07981654012727935,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:52:25,604\tINFO tf_run_builder.py:87 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:52:25,606\tINFO sampler.py:1269 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': ( np.ndarray((1, 389), dtype=float32, min=-2.23, max=2.501, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       { 'action_dist_inputs': np.ndarray((1, 778), dtype=float32, min=-0.058, max=0.055, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-540.398, max=-540.398, mean=-540.398),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=3.556, max=3.556, mean=3.556)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:52:25,997\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=7.1, max=2446.01, mean=118.323)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:52:25,997\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:52:45,798\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.205, max=0.201, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-591.901, max=-519.603, mean=-552.413),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.196, max=3.863, mean=-0.006),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-1.167, max=2.363, mean=0.033),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=622828328.0, max=622828328.0, mean=622828328.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4695.595, mean=124.642),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.31),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.196, max=3.863, mean=-0.006),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=22.0, max=22.0, mean=22.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.017, max=4.449, mean=2.674),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=-0.044, max=4.381, mean=2.641)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:52:45,937\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.205, max=0.201, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-591.901, max=-519.603, mean=-552.413),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.196, max=3.863, mean=-0.006),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-1.167, max=2.363, mean=0.033),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=622828328.0, max=622828328.0, mean=622828328.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4695.595, mean=124.642),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.31),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.196, max=3.863, mean=-0.006),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=22.0, max=22.0, mean=22.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.017, max=4.449, mean=2.674),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=-0.044, max=4.381, mean=2.641)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,536\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,547\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.108475365, 'policy_loss': 0.0048408336, 'vf_loss': 0.10330226, 'vf_explained_var': 0.9619592, 'kl': 0.0007384375, 'entropy': 552.5645, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,558\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.046989497, 'policy_loss': -0.14933336, 'vf_loss': 0.09919858, 'vf_explained_var': 0.9635795, 'kl': 0.00698947, 'entropy': 552.48535, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,568\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08240845, 'policy_loss': -0.18545575, 'vf_loss': 0.094819464, 'vf_explained_var': 0.9655643, 'kl': 0.018284125, 'entropy': 552.4382, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,579\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09278747, 'policy_loss': -0.19476451, 'vf_loss': 0.09068126, 'vf_explained_var': 0.96674037, 'kl': 0.025101712, 'entropy': 552.4157, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,591\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09551772, 'policy_loss': -0.19782038, 'vf_loss': 0.08953845, 'vf_explained_var': 0.96701354, 'kl': 0.028364995, 'entropy': 552.3702, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,602\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09603573, 'policy_loss': -0.19945355, 'vf_loss': 0.08913233, 'vf_explained_var': 0.9673779, 'kl': 0.031745594, 'entropy': 552.3239, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,613\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10091681, 'policy_loss': -0.20055616, 'vf_loss': 0.08433318, 'vf_explained_var': 0.96901685, 'kl': 0.03401367, 'entropy': 552.31335, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,624\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10235836, 'policy_loss': -0.2012996, 'vf_loss': 0.08367106, 'vf_explained_var': 0.96915, 'kl': 0.033933703, 'entropy': 552.3372, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,636\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10784329, 'policy_loss': -0.20171683, 'vf_loss': 0.078975655, 'vf_explained_var': 0.9710714, 'kl': 0.033106398, 'entropy': 552.3757, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,648\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10930715, 'policy_loss': -0.2020932, 'vf_loss': 0.078084625, 'vf_explained_var': 0.97131133, 'kl': 0.032669835, 'entropy': 552.4045, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,661\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.110660695, 'policy_loss': -0.20221086, 'vf_loss': 0.07723841, 'vf_explained_var': 0.97152394, 'kl': 0.031803917, 'entropy': 552.4224, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,674\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11232978, 'policy_loss': -0.2022839, 'vf_loss': 0.07611987, 'vf_explained_var': 0.9719989, 'kl': 0.03074278, 'entropy': 552.4322, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,689\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11375322, 'policy_loss': -0.20230925, 'vf_loss': 0.07530103, 'vf_explained_var': 0.97242147, 'kl': 0.029455604, 'entropy': 552.4329, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,704\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11581874, 'policy_loss': -0.20232117, 'vf_loss': 0.07384985, 'vf_explained_var': 0.9729416, 'kl': 0.028116867, 'entropy': 552.43317, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,716\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11750264, 'policy_loss': -0.2023326, 'vf_loss': 0.072771065, 'vf_explained_var': 0.9732353, 'kl': 0.026797531, 'entropy': 552.4399, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,728\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.119416095, 'policy_loss': -0.20234603, 'vf_loss': 0.07143552, 'vf_explained_var': 0.97378683, 'kl': 0.025543144, 'entropy': 552.4516, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,738\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.121291555, 'policy_loss': -0.20235564, 'vf_loss': 0.07008436, 'vf_explained_var': 0.974313, 'kl': 0.024399376, 'entropy': 552.464, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,749\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12180149, 'policy_loss': -0.20236428, 'vf_loss': 0.070052974, 'vf_explained_var': 0.9742956, 'kl': 0.023355192, 'entropy': 552.4743, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,761\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12253243, 'policy_loss': -0.20234442, 'vf_loss': 0.069755815, 'vf_explained_var': 0.97441226, 'kl': 0.02234708, 'entropy': 552.4803, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,772\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1222954, 'policy_loss': -0.20236404, 'vf_loss': 0.07045854, 'vf_explained_var': 0.974139, 'kl': 0.021355813, 'entropy': 552.4842, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,783\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12441689, 'policy_loss': -0.2023717, 'vf_loss': 0.06877363, 'vf_explained_var': 0.9747718, 'kl': 0.020402627, 'entropy': 552.488, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,794\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12325809, 'policy_loss': -0.20237172, 'vf_loss': 0.070327766, 'vf_explained_var': 0.97420853, 'kl': 0.019524122, 'entropy': 552.49396, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,805\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12593132, 'policy_loss': -0.20237404, 'vf_loss': 0.06802732, 'vf_explained_var': 0.9750312, 'kl': 0.018700883, 'entropy': 552.5019, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,817\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12442488, 'policy_loss': -0.20238136, 'vf_loss': 0.06991191, 'vf_explained_var': 0.97440344, 'kl': 0.01787681, 'entropy': 552.50995, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,834\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12653224, 'policy_loss': -0.20238437, 'vf_loss': 0.0681397, 'vf_explained_var': 0.9749875, 'kl': 0.017138747, 'entropy': 552.5169, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,849\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12820528, 'policy_loss': -0.2023897, 'vf_loss': 0.06674847, 'vf_explained_var': 0.975478, 'kl': 0.016524347, 'entropy': 552.52356, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,863\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12738787, 'policy_loss': -0.20238721, 'vf_loss': 0.06782067, 'vf_explained_var': 0.97507423, 'kl': 0.015952637, 'entropy': 552.5297, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,877\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12789758, 'policy_loss': -0.20238738, 'vf_loss': 0.067574635, 'vf_explained_var': 0.9751827, 'kl': 0.015367076, 'entropy': 552.5367, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,888\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12782748, 'policy_loss': -0.20236032, 'vf_loss': 0.067859225, 'vf_explained_var': 0.97509867, 'kl': 0.014830227, 'entropy': 552.54175, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:52:46,898\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12829219, 'policy_loss': -0.20237881, 'vf_loss': 0.067639686, 'vf_explained_var': 0.975105, 'kl': 0.014326557, 'entropy': 552.5441, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-52-46\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.77943532359043\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 115\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5441284179688\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014326556585729122\n",
      "        model: {}\n",
      "        policy_loss: -0.20237880945205688\n",
      "        total_loss: -0.12829218804836273\n",
      "        vf_explained_var: 0.9751049876213074\n",
      "        vf_loss: 0.06763968616724014\n",
      "    num_steps_sampled: 11500\n",
      "    num_steps_trained: 11500\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.60333333333334\n",
      "    ram_util_percent: 75.81333333333335\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13170911564165677\n",
      "    mean_env_wait_ms: 451.7417886724754\n",
      "    mean_inference_ms: 1.1670284936844895\n",
      "    mean_raw_obs_processing_ms: 1.8494769328914904\n",
      "  time_since_restore: 982.7398083209991\n",
      "  time_this_iter_s: 38.28338289260864\n",
      "  time_total_s: 982.7398083209991\n",
      "  timers:\n",
      "    learn_throughput: 1429.953\n",
      "    learn_time_ms: 349.662\n",
      "    load_throughput: 114298.047\n",
      "    load_time_ms: 4.375\n",
      "    sample_throughput: 13.296\n",
      "    sample_time_ms: 37605.776\n",
      "    update_time_ms: 2.538\n",
      "  timestamp: 1604404366\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11500\n",
      "  training_iteration: 23\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:52:51,239\tWARNING util.py:139 -- The `process_trial` operation took 3.5239169597625732 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:52:51,217\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:52:51,945\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7056288719177246 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">          982.74</td><td style=\"text-align: right;\">11500</td><td style=\"text-align: right;\"> 2.77944</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,665\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-4.399, max=4.635, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.056, max=0.179, mean=0.029),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.05),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.193, max=0.22, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-607.208, max=-515.455, mean=-552.752),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.399, max=4.635, mean=0.004),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-8.4, max=6.063, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.05),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.399, max=4.635, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.056, max=0.179, mean=0.029),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.415, max=4.325, mean=0.837),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.332, max=4.572, mean=0.807)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,665\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,666\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,683\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.12076509, 'policy_loss': -0.005127681, 'vf_loss': 0.125506, 'vf_explained_var': 0.9531891, 'kl': 0.0008594792, 'entropy': 552.5386, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,695\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.027034407, 'policy_loss': -0.1525556, 'vf_loss': 0.1211699, 'vf_explained_var': 0.95611686, 'kl': 0.009669489, 'entropy': 552.64307, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,707\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08830654, 'policy_loss': -0.2021354, 'vf_loss': 0.10411958, 'vf_explained_var': 0.96103376, 'kl': 0.021576205, 'entropy': 552.69403, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,720\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09277334, 'policy_loss': -0.21075696, 'vf_loss': 0.10491478, 'vf_explained_var': 0.9608144, 'kl': 0.029041873, 'entropy': 552.70087, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,732\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.096841134, 'policy_loss': -0.21515758, 'vf_loss': 0.10251126, 'vf_explained_var': 0.9615665, 'kl': 0.03512271, 'entropy': 552.68976, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,743\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09481568, 'policy_loss': -0.21681505, 'vf_loss': 0.104126394, 'vf_explained_var': 0.96103233, 'kl': 0.03971773, 'entropy': 552.67035, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,754\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10170529, 'policy_loss': -0.21763314, 'vf_loss': 0.09701407, 'vf_explained_var': 0.96364456, 'kl': 0.042030644, 'entropy': 552.6574, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,766\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.103283264, 'policy_loss': -0.21810512, 'vf_loss': 0.095965624, 'vf_explained_var': 0.96408397, 'kl': 0.04190277, 'entropy': 552.6495, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,780\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11012482, 'policy_loss': -0.21826243, 'vf_loss': 0.089592986, 'vf_explained_var': 0.96630377, 'kl': 0.04121025, 'entropy': 552.6408, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,792\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11096201, 'policy_loss': -0.21860313, 'vf_loss': 0.0896253, 'vf_explained_var': 0.9662478, 'kl': 0.040035244, 'entropy': 552.62695, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,804\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11251289, 'policy_loss': -0.21872301, 'vf_loss': 0.08869759, 'vf_explained_var': 0.96665376, 'kl': 0.038916748, 'entropy': 552.61053, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,817\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11715839, 'policy_loss': -0.21880949, 'vf_loss': 0.08466265, 'vf_explained_var': 0.9683835, 'kl': 0.037752133, 'entropy': 552.5988, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,830\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11688819, 'policy_loss': -0.2189352, 'vf_loss': 0.08570207, 'vf_explained_var': 0.9681639, 'kl': 0.036322147, 'entropy': 552.59564, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,843\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12104645, 'policy_loss': -0.2189648, 'vf_loss': 0.08233064, 'vf_explained_var': 0.9691141, 'kl': 0.034639325, 'entropy': 552.5954, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,855\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1215777, 'policy_loss': -0.21898426, 'vf_loss': 0.08259013, 'vf_explained_var': 0.96945286, 'kl': 0.032925397, 'entropy': 552.59393, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,867\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1245257, 'policy_loss': -0.21901168, 'vf_loss': 0.08040988, 'vf_explained_var': 0.96963197, 'kl': 0.031280275, 'entropy': 552.59155, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,880\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12433686, 'policy_loss': -0.21904762, 'vf_loss': 0.08132649, 'vf_explained_var': 0.9695434, 'kl': 0.029742876, 'entropy': 552.58777, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,892\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12820114, 'policy_loss': -0.21907647, 'vf_loss': 0.078162484, 'vf_explained_var': 0.9704593, 'kl': 0.02825073, 'entropy': 552.58344, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,904\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12811638, 'policy_loss': -0.21909219, 'vf_loss': 0.07887566, 'vf_explained_var': 0.9704578, 'kl': 0.026889198, 'entropy': 552.58026, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,917\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12915383, 'policy_loss': -0.21911353, 'vf_loss': 0.078398116, 'vf_explained_var': 0.97038865, 'kl': 0.02569238, 'entropy': 552.57806, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,930\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1309648, 'policy_loss': -0.21912064, 'vf_loss': 0.077117674, 'vf_explained_var': 0.97083807, 'kl': 0.0245293, 'entropy': 552.5742, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,944\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13103713, 'policy_loss': -0.21915776, 'vf_loss': 0.07755008, 'vf_explained_var': 0.9707529, 'kl': 0.02349008, 'entropy': 552.5712, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,956\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13255577, 'policy_loss': -0.21918507, 'vf_loss': 0.07649752, 'vf_explained_var': 0.9711041, 'kl': 0.022515051, 'entropy': 552.5688, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,969\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13438654, 'policy_loss': -0.21918792, 'vf_loss': 0.075079374, 'vf_explained_var': 0.9715769, 'kl': 0.021604443, 'entropy': 552.5679, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,981\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13336699, 'policy_loss': -0.21916305, 'vf_loss': 0.076461844, 'vf_explained_var': 0.9711314, 'kl': 0.020742686, 'entropy': 552.56836, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:28,994\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13227265, 'policy_loss': -0.21919751, 'vf_loss': 0.07794727, 'vf_explained_var': 0.97073466, 'kl': 0.019950258, 'entropy': 552.56494, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:29,006\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13308428, 'policy_loss': -0.2192092, 'vf_loss': 0.077463426, 'vf_explained_var': 0.97107005, 'kl': 0.019247746, 'entropy': 552.5618, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:29,018\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13612707, 'policy_loss': -0.21921474, 'vf_loss': 0.07471999, 'vf_explained_var': 0.97155595, 'kl': 0.018594848, 'entropy': 552.5607, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:29,030\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13562511, 'policy_loss': -0.2192172, 'vf_loss': 0.07550786, 'vf_explained_var': 0.97146004, 'kl': 0.017964976, 'entropy': 552.5612, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:53:29,041\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1361852, 'policy_loss': -0.21920697, 'vf_loss': 0.0752132, 'vf_explained_var': 0.97171617, 'kl': 0.017352358, 'entropy': 552.5619, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-53-29\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.7762043213775325\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 120\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5618896484375\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017352357506752014\n",
      "        model: {}\n",
      "        policy_loss: -0.21920697391033173\n",
      "        total_loss: -0.1361851990222931\n",
      "        vf_explained_var: 0.9717161655426025\n",
      "        vf_loss: 0.07521320134401321\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 12000\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.83166666666667\n",
      "    ram_util_percent: 75.76500000000001\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12902408751076458\n",
      "    mean_env_wait_ms: 442.930763775593\n",
      "    mean_inference_ms: 1.1412323484210787\n",
      "    mean_raw_obs_processing_ms: 1.8199784861201507\n",
      "  time_since_restore: 1020.5734782218933\n",
      "  time_this_iter_s: 37.833669900894165\n",
      "  time_total_s: 1020.5734782218933\n",
      "  timers:\n",
      "    learn_throughput: 1404.485\n",
      "    learn_time_ms: 356.002\n",
      "    load_throughput: 100383.507\n",
      "    load_time_ms: 4.981\n",
      "    sample_throughput: 13.206\n",
      "    sample_time_ms: 37862.204\n",
      "    update_time_ms: 2.562\n",
      "  timestamp: 1604404409\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 24\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:53:33,708\tWARNING util.py:139 -- The `process_trial` operation took 3.792558193206787 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:53:34,782\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 1.0739150047302246 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         1020.57</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">  2.7762</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "': np.ndarray((1,), dtype=float32, min=-559.983, max=-559.983, mean=-559.983),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=3.822, max=3.822, mean=3.822)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:53:51,799\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=7.5, max=2450.0, mean=126.082)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:53:51,799\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:54:14,221\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.199, max=0.246, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-614.577, max=-520.737, mean=-554.804),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.066, max=4.284, mean=-0.006),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-0.47, max=2.228, mean=0.088),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=499632162.0, max=499632162.0, mean=499632162.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4792.34, mean=124.381),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.969),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.066, max=4.284, mean=-0.005),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.181, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.181, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=24.0, max=24.0, mean=24.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.013, max=4.408, mean=2.614),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=-0.085, max=4.438, mean=2.526)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:54:14,376\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.199, max=0.246, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-614.577, max=-520.737, mean=-554.804),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.066, max=4.284, mean=-0.006),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-0.47, max=2.228, mean=0.088),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=499632162.0, max=499632162.0, mean=499632162.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4792.34, mean=124.381),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.969),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.066, max=4.284, mean=-0.005),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.181, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.181, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=24.0, max=24.0, mean=24.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.013, max=4.408, mean=2.614),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=-0.085, max=4.438, mean=2.526)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,066\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,067\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,067\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,067\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,067\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,068\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,068\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,068\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,068\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,068\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,068\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,068\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,083\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,106\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.12053142, 'policy_loss': 0.031878278, 'vf_loss': 0.087904125, 'vf_explained_var': 0.97242814, 'kl': 0.0016644822, 'entropy': 552.5382, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,119\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.013277723, 'policy_loss': -0.09446561, 'vf_loss': 0.0761598, 'vf_explained_var': 0.97570044, 'kl': 0.011173551, 'entropy': 552.55316, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,130\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.058903113, 'policy_loss': -0.14085859, 'vf_loss': 0.071396045, 'vf_explained_var': 0.97670335, 'kl': 0.023465415, 'entropy': 552.5507, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,142\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07367841, 'policy_loss': -0.1561804, 'vf_loss': 0.06776785, 'vf_explained_var': 0.9777189, 'kl': 0.03274251, 'entropy': 552.5186, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,154\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08186397, 'policy_loss': -0.1602789, 'vf_loss': 0.060984004, 'vf_explained_var': 0.9801715, 'kl': 0.038735393, 'entropy': 552.49677, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,166\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08187793, 'policy_loss': -0.16210784, 'vf_loss': 0.06112133, 'vf_explained_var': 0.9796901, 'kl': 0.042463522, 'entropy': 552.4838, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,178\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08548418, 'policy_loss': -0.16272853, 'vf_loss': 0.058012087, 'vf_explained_var': 0.98121905, 'kl': 0.042738397, 'entropy': 552.461, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,190\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.089266896, 'policy_loss': -0.1632892, 'vf_loss': 0.055126164, 'vf_explained_var': 0.98185366, 'kl': 0.041991454, 'entropy': 552.4453, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,202\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09086186, 'policy_loss': -0.16354777, 'vf_loss': 0.05401816, 'vf_explained_var': 0.982109, 'kl': 0.04148389, 'entropy': 552.4531, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,214\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.091778874, 'policy_loss': -0.16395934, 'vf_loss': 0.05377735, 'vf_explained_var': 0.9822531, 'kl': 0.040895823, 'entropy': 552.48236, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,226\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09487841, 'policy_loss': -0.16409178, 'vf_loss': 0.051246736, 'vf_explained_var': 0.98305506, 'kl': 0.039925843, 'entropy': 552.50726, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,238\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09614093, 'policy_loss': -0.16435546, 'vf_loss': 0.050960492, 'vf_explained_var': 0.9831179, 'kl': 0.038342305, 'entropy': 552.53296, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,250\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09847898, 'policy_loss': -0.16447109, 'vf_loss': 0.049459696, 'vf_explained_var': 0.98363686, 'kl': 0.036738686, 'entropy': 552.554, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,262\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.100867964, 'policy_loss': -0.16457689, 'vf_loss': 0.047814246, 'vf_explained_var': 0.98422164, 'kl': 0.035321485, 'entropy': 552.5643, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,275\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10227102, 'policy_loss': -0.16458686, 'vf_loss': 0.047040362, 'vf_explained_var': 0.9844322, 'kl': 0.03394549, 'entropy': 552.5677, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,288\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.103693284, 'policy_loss': -0.16464323, 'vf_loss': 0.046395343, 'vf_explained_var': 0.9846819, 'kl': 0.032343566, 'entropy': 552.56836, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,300\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.105635814, 'policy_loss': -0.1646917, 'vf_loss': 0.045221563, 'vf_explained_var': 0.985079, 'kl': 0.030742994, 'entropy': 552.5677, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,312\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10623711, 'policy_loss': -0.16470763, 'vf_loss': 0.04529418, 'vf_explained_var': 0.98502684, 'kl': 0.029280782, 'entropy': 552.56525, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,324\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.106754325, 'policy_loss': -0.16469036, 'vf_loss': 0.045347262, 'vf_explained_var': 0.9849431, 'kl': 0.027975067, 'entropy': 552.56354, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,337\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10881882, 'policy_loss': -0.1647413, 'vf_loss': 0.043910276, 'vf_explained_var': 0.985468, 'kl': 0.026693812, 'entropy': 552.5654, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,349\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10926968, 'policy_loss': -0.16472901, 'vf_loss': 0.04395197, 'vf_explained_var': 0.98549074, 'kl': 0.025571942, 'entropy': 552.5706, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,361\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1105209, 'policy_loss': -0.16474304, 'vf_loss': 0.043178767, 'vf_explained_var': 0.9857514, 'kl': 0.024540856, 'entropy': 552.5754, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,372\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11075002, 'policy_loss': -0.16476713, 'vf_loss': 0.043409392, 'vf_explained_var': 0.98563653, 'kl': 0.023572743, 'entropy': 552.5774, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,384\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.111767374, 'policy_loss': -0.16478495, 'vf_loss': 0.042838093, 'vf_explained_var': 0.9858391, 'kl': 0.022621075, 'entropy': 552.5786, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,396\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1132601, 'policy_loss': -0.16478518, 'vf_loss': 0.041780155, 'vf_explained_var': 0.98622733, 'kl': 0.02165541, 'entropy': 552.5797, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,407\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.113802694, 'policy_loss': -0.1647778, 'vf_loss': 0.041692708, 'vf_explained_var': 0.9862277, 'kl': 0.020627601, 'entropy': 552.581, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,419\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11432928, 'policy_loss': -0.16464533, 'vf_loss': 0.041464232, 'vf_explained_var': 0.9862375, 'kl': 0.01967071, 'entropy': 552.58496, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,431\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11547425, 'policy_loss': -0.16477402, 'vf_loss': 0.04079913, 'vf_explained_var': 0.98648715, 'kl': 0.018890297, 'entropy': 552.5843, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,443\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.116089046, 'policy_loss': -0.16472512, 'vf_loss': 0.04048234, 'vf_explained_var': 0.98656386, 'kl': 0.018119395, 'entropy': 552.57904, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:15,454\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.116312176, 'policy_loss': -0.16473502, 'vf_loss': 0.040594548, 'vf_explained_var': 0.9865039, 'kl': 0.017396228, 'entropy': 552.5783, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-54-15\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.7676878516852956\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 125\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.5783081054688\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01739622838795185\n",
      "        model: {}\n",
      "        policy_loss: -0.16473501920700073\n",
      "        total_loss: -0.116312175989151\n",
      "        vf_explained_var: 0.9865038990974426\n",
      "        vf_loss: 0.04059454798698425\n",
      "    num_steps_sampled: 12500\n",
      "    num_steps_trained: 12500\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.980000000000004\n",
      "    ram_util_percent: 61.42461538461539\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12668749255324502\n",
      "    mean_env_wait_ms: 434.72519202002974\n",
      "    mean_inference_ms: 1.1189192633920926\n",
      "    mean_raw_obs_processing_ms: 1.793479297642128\n",
      "  time_since_restore: 1062.3935780525208\n",
      "  time_this_iter_s: 41.82009983062744\n",
      "  time_total_s: 1062.3935780525208\n",
      "  timers:\n",
      "    learn_throughput: 1384.689\n",
      "    learn_time_ms: 361.092\n",
      "    load_throughput: 74400.335\n",
      "    load_time_ms: 6.72\n",
      "    sample_throughput: 12.991\n",
      "    sample_time_ms: 38487.025\n",
      "    update_time_ms: 3.041\n",
      "  timestamp: 1604404455\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12500\n",
      "  training_iteration: 25\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:54:20,063\tWARNING util.py:139 -- The `process_trial` operation took 3.748465061187744 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:54:20,043\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:54:20,806\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7421948909759521 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 9.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         1062.39</td><td style=\"text-align: right;\">12500</td><td style=\"text-align: right;\"> 2.76769</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,277\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,289\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.078815736, 'policy_loss': -0.01729528, 'vf_loss': 0.09570676, 'vf_explained_var': 0.9644007, 'kl': 0.00089833373, 'entropy': 552.612, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,299\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08040096, 'policy_loss': -0.17191233, 'vf_loss': 0.08698719, 'vf_explained_var': 0.967721, 'kl': 0.010053772, 'entropy': 552.6504, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,310\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11401605, 'policy_loss': -0.20610712, 'vf_loss': 0.08176791, 'vf_explained_var': 0.9696846, 'kl': 0.022940373, 'entropy': 552.6936, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,320\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.117980786, 'policy_loss': -0.21512926, 'vf_loss': 0.08193112, 'vf_explained_var': 0.96935767, 'kl': 0.033816356, 'entropy': 552.727, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,331\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12627977, 'policy_loss': -0.22076046, 'vf_loss': 0.07688466, 'vf_explained_var': 0.97119313, 'kl': 0.039102327, 'entropy': 552.7505, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,342\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12413633, 'policy_loss': -0.2219188, 'vf_loss': 0.079158075, 'vf_explained_var': 0.97094077, 'kl': 0.041387532, 'entropy': 552.7773, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,352\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12740181, 'policy_loss': -0.22281013, 'vf_loss': 0.07639015, 'vf_explained_var': 0.9715007, 'kl': 0.042262614, 'entropy': 552.7907, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,363\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12988852, 'policy_loss': -0.22370435, 'vf_loss': 0.07510037, 'vf_explained_var': 0.97207326, 'kl': 0.04158995, 'entropy': 552.79456, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,374\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13547808, 'policy_loss': -0.22415106, 'vf_loss': 0.070701085, 'vf_explained_var': 0.9736158, 'kl': 0.039937545, 'entropy': 552.7768, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,385\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13911097, 'policy_loss': -0.22461693, 'vf_loss': 0.068645366, 'vf_explained_var': 0.97435683, 'kl': 0.037468012, 'entropy': 552.7464, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,396\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14222069, 'policy_loss': -0.22474311, 'vf_loss': 0.06682518, 'vf_explained_var': 0.97511595, 'kl': 0.034882713, 'entropy': 552.7143, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,407\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14325227, 'policy_loss': -0.2245226, 'vf_loss': 0.06644929, 'vf_explained_var': 0.97523755, 'kl': 0.032935683, 'entropy': 552.6879, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,418\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14571768, 'policy_loss': -0.22476535, 'vf_loss': 0.06501753, 'vf_explained_var': 0.9758165, 'kl': 0.031178132, 'entropy': 552.67163, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,428\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14736778, 'policy_loss': -0.22484137, 'vf_loss': 0.064156346, 'vf_explained_var': 0.97616005, 'kl': 0.0295939, 'entropy': 552.66486, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,439\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14932822, 'policy_loss': -0.22492522, 'vf_loss': 0.06277326, 'vf_explained_var': 0.97666997, 'kl': 0.02849724, 'entropy': 552.6543, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,449\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15143572, 'policy_loss': -0.22497816, 'vf_loss': 0.061301693, 'vf_explained_var': 0.97720003, 'kl': 0.027201675, 'entropy': 552.6419, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,460\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15119663, 'policy_loss': -0.22501563, 'vf_loss': 0.062095147, 'vf_explained_var': 0.9769531, 'kl': 0.02605296, 'entropy': 552.63385, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,471\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15202354, 'policy_loss': -0.22505747, 'vf_loss': 0.061805543, 'vf_explained_var': 0.97708756, 'kl': 0.02495201, 'entropy': 552.6289, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,482\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1532455, 'policy_loss': -0.22505791, 'vf_loss': 0.06109273, 'vf_explained_var': 0.9772939, 'kl': 0.023821605, 'entropy': 552.62506, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,493\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15506841, 'policy_loss': -0.22510934, 'vf_loss': 0.0597247, 'vf_explained_var': 0.97778755, 'kl': 0.022924995, 'entropy': 552.6184, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,504\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15600534, 'policy_loss': -0.22510207, 'vf_loss': 0.059164613, 'vf_explained_var': 0.97802633, 'kl': 0.022071356, 'entropy': 552.61444, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,514\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1565953, 'policy_loss': -0.22509475, 'vf_loss': 0.05896597, 'vf_explained_var': 0.9781456, 'kl': 0.021185523, 'entropy': 552.61646, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,526\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15691213, 'policy_loss': -0.22513407, 'vf_loss': 0.059028536, 'vf_explained_var': 0.97817326, 'kl': 0.020429801, 'entropy': 552.6192, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,541\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15826266, 'policy_loss': -0.22515625, 'vf_loss': 0.058018874, 'vf_explained_var': 0.978497, 'kl': 0.019721594, 'entropy': 552.6188, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,556\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15811473, 'policy_loss': -0.22516733, 'vf_loss': 0.058474857, 'vf_explained_var': 0.9783589, 'kl': 0.019061668, 'entropy': 552.61554, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,568\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15962653, 'policy_loss': -0.22517443, 'vf_loss': 0.05726434, 'vf_explained_var': 0.9787848, 'kl': 0.018407943, 'entropy': 552.6113, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,580\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15994924, 'policy_loss': -0.22517844, 'vf_loss': 0.057208154, 'vf_explained_var': 0.97879815, 'kl': 0.017824542, 'entropy': 552.6081, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,591\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16055165, 'policy_loss': -0.22518821, 'vf_loss': 0.056876946, 'vf_explained_var': 0.97891355, 'kl': 0.017243603, 'entropy': 552.60706, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,602\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1613559, 'policy_loss': -0.22519052, 'vf_loss': 0.056318868, 'vf_explained_var': 0.97912675, 'kl': 0.01670166, 'entropy': 552.60925, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:54:58,614\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16241014, 'policy_loss': -0.22520292, 'vf_loss': 0.05551711, 'vf_explained_var': 0.97943515, 'kl': 0.016168088, 'entropy': 552.6131, 'entropy_coeff': 0.0, 'model': {}}\n",
      "2020-11-03 12:55:00,245\tWARNING util.py:139 -- The `fetch_result` operation took 0.818946123123169 seconds to complete, which may be a performance bottleneck.\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-54-58\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.183503972470761\n",
      "  episode_reward_mean: 2.76500630123241\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 130\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6130981445312\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01616808772087097\n",
      "        model: {}\n",
      "        policy_loss: -0.22520291805267334\n",
      "        total_loss: -0.16241014003753662\n",
      "        vf_explained_var: 0.97943514585495\n",
      "        vf_loss: 0.05551711097359657\n",
      "    num_steps_sampled: 13000\n",
      "    num_steps_trained: 13000\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.85081967213115\n",
      "    ram_util_percent: 62.9704918032787\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12479342323349239\n",
      "    mean_env_wait_ms: 428.1413038539863\n",
      "    mean_inference_ms: 1.1010632952271828\n",
      "    mean_raw_obs_processing_ms: 1.7727601554987131\n",
      "  time_since_restore: 1100.9745450019836\n",
      "  time_this_iter_s: 38.58096694946289\n",
      "  time_total_s: 1100.9745450019836\n",
      "  timers:\n",
      "    learn_throughput: 1386.991\n",
      "    learn_time_ms: 360.493\n",
      "    load_throughput: 75625.915\n",
      "    load_time_ms: 6.611\n",
      "    sample_throughput: 12.926\n",
      "    sample_time_ms: 38682.382\n",
      "    update_time_ms: 3.031\n",
      "  timestamp: 1604404498\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13000\n",
      "  training_iteration: 26\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:55:03,281\tWARNING util.py:139 -- The `process_trial` operation took 3.8555409908294678 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:55:03,987\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7051849365234375 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.4/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         1100.97</td><td style=\"text-align: right;\">13000</td><td style=\"text-align: right;\"> 2.76501</td><td style=\"text-align: right;\">              7.1835</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "type=float32, min=-590.765, max=-527.182, mean=-551.804),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-3.853, max=4.245, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-0.806, max=2.319, mean=0.129),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=1461732799.0, max=1461732799.0, mean=1461732799.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4741.493, mean=124.274),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.906),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-3.853, max=4.245, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.18, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.18, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=26.0, max=26.0, mean=26.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.015, max=4.306, mean=2.575),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=-0.023, max=4.249, mean=2.447)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:55:41,658\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.188, max=0.256, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-590.765, max=-527.182, mean=-551.804),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-3.853, max=4.245, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-0.806, max=2.319, mean=0.129),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=1461732799.0, max=1461732799.0, mean=1461732799.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4741.493, mean=124.274),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.906),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-3.853, max=4.245, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.18, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=0.0, max=0.18, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=26.0, max=26.0, mean=26.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.015, max=4.306, mean=2.575),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=-0.023, max=4.249, mean=2.447)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,248\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-4.426, max=4.489, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.057, max=0.18, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=129.944),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.188, max=0.256, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-591.303, max=-517.043, mean=-553.324),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.426, max=4.489, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-7.893, max=6.133, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=129.944),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.426, max=4.489, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.057, max=0.18, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.435, max=4.306, mean=0.83),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.462, max=4.249, mean=0.758)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,249\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,249\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,261\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.11565381, 'policy_loss': -0.033098865, 'vf_loss': 0.14778204, 'vf_explained_var': 0.94696957, 'kl': 0.0021569654, 'entropy': 552.5815, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,272\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.050148506, 'policy_loss': -0.18876316, 'vf_loss': 0.13251907, 'vf_explained_var': 0.95335263, 'kl': 0.013545737, 'entropy': 552.5247, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,285\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09845006, 'policy_loss': -0.22567974, 'vf_loss': 0.11690238, 'vf_explained_var': 0.95670366, 'kl': 0.022949554, 'entropy': 552.5869, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,298\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11320594, 'policy_loss': -0.23971416, 'vf_loss': 0.11325873, 'vf_explained_var': 0.9582848, 'kl': 0.02944333, 'entropy': 552.6509, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,308\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.115491904, 'policy_loss': -0.2446583, 'vf_loss': 0.11359199, 'vf_explained_var': 0.95779705, 'kl': 0.034609795, 'entropy': 552.6786, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,319\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12334576, 'policy_loss': -0.24696904, 'vf_loss': 0.10634727, 'vf_explained_var': 0.95963526, 'kl': 0.038391132, 'entropy': 552.6966, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,330\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12975536, 'policy_loss': -0.24827522, 'vf_loss': 0.10017749, 'vf_explained_var': 0.96224385, 'kl': 0.040760826, 'entropy': 552.71875, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,341\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1283627, 'policy_loss': -0.24904077, 'vf_loss': 0.1018238, 'vf_explained_var': 0.9614337, 'kl': 0.041898374, 'entropy': 552.7332, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,353\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13224216, 'policy_loss': -0.24941331, 'vf_loss': 0.0983007, 'vf_explained_var': 0.9626506, 'kl': 0.041934352, 'entropy': 552.73804, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,363\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13455604, 'policy_loss': -0.24971269, 'vf_loss': 0.0965571, 'vf_explained_var': 0.96341944, 'kl': 0.041332312, 'entropy': 552.72906, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,375\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13815965, 'policy_loss': -0.24982841, 'vf_loss': 0.09367447, 'vf_explained_var': 0.9645334, 'kl': 0.0399873, 'entropy': 552.70953, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,386\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13776936, 'policy_loss': -0.24987562, 'vf_loss': 0.094884336, 'vf_explained_var': 0.96395165, 'kl': 0.03827101, 'entropy': 552.68427, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,398\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14135535, 'policy_loss': -0.24997997, 'vf_loss': 0.092039146, 'vf_explained_var': 0.96508837, 'kl': 0.036856588, 'entropy': 552.6666, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,409\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1458981, 'policy_loss': -0.24999547, 'vf_loss': 0.08813105, 'vf_explained_var': 0.9664108, 'kl': 0.03548078, 'entropy': 552.6621, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,420\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14565444, 'policy_loss': -0.24956767, 'vf_loss': 0.08848852, 'vf_explained_var': 0.9665685, 'kl': 0.03427709, 'entropy': 552.66516, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,431\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14879087, 'policy_loss': -0.25000894, 'vf_loss': 0.08641276, 'vf_explained_var': 0.9672448, 'kl': 0.032900717, 'entropy': 552.65466, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,442\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1498399, 'policy_loss': -0.25003156, 'vf_loss': 0.08585063, 'vf_explained_var': 0.9673589, 'kl': 0.031868983, 'entropy': 552.6449, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,453\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15304722, 'policy_loss': -0.25001636, 'vf_loss': 0.083108135, 'vf_explained_var': 0.96830684, 'kl': 0.030802215, 'entropy': 552.6423, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,464\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15349162, 'policy_loss': -0.2500453, 'vf_loss': 0.083217025, 'vf_explained_var': 0.9683673, 'kl': 0.029637048, 'entropy': 552.6458, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,476\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15520085, 'policy_loss': -0.250059, 'vf_loss': 0.082061924, 'vf_explained_var': 0.96870416, 'kl': 0.028436078, 'entropy': 552.65497, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,491\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15730171, 'policy_loss': -0.25006878, 'vf_loss': 0.080456324, 'vf_explained_var': 0.9692748, 'kl': 0.027357213, 'entropy': 552.66583, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,504\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15874217, 'policy_loss': -0.2500786, 'vf_loss': 0.07939598, 'vf_explained_var': 0.9697338, 'kl': 0.026534317, 'entropy': 552.6691, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,517\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15985373, 'policy_loss': -0.25000134, 'vf_loss': 0.07862224, 'vf_explained_var': 0.9700517, 'kl': 0.025611939, 'entropy': 552.6591, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,529\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16052173, 'policy_loss': -0.25010175, 'vf_loss': 0.07837993, 'vf_explained_var': 0.97009426, 'kl': 0.024889035, 'entropy': 552.63983, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,541\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1591631, 'policy_loss': -0.25009176, 'vf_loss': 0.08007664, 'vf_explained_var': 0.9693248, 'kl': 0.024115546, 'entropy': 552.6291, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,552\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16143548, 'policy_loss': -0.25010395, 'vf_loss': 0.07821397, 'vf_explained_var': 0.9699959, 'kl': 0.023232207, 'entropy': 552.627, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,564\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16309531, 'policy_loss': -0.2500722, 'vf_loss': 0.07691119, 'vf_explained_var': 0.9705555, 'kl': 0.022368243, 'entropy': 552.6332, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,576\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16324587, 'policy_loss': -0.25009966, 'vf_loss': 0.07705633, 'vf_explained_var': 0.9706356, 'kl': 0.021772146, 'entropy': 552.63806, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,587\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1638893, 'policy_loss': -0.2501252, 'vf_loss': 0.076675914, 'vf_explained_var': 0.97073895, 'kl': 0.021244466, 'entropy': 552.64014, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:55:42,599\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1646698, 'policy_loss': -0.2501178, 'vf_loss': 0.07616536, 'vf_explained_var': 0.9708732, 'kl': 0.020628145, 'entropy': 552.63873, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-55-42\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 6.923357326814718\n",
      "  episode_reward_mean: 2.7760079209624844\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 135\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6387329101562\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020628144964575768\n",
      "        model: {}\n",
      "        policy_loss: -0.25011780858039856\n",
      "        total_loss: -0.16466979682445526\n",
      "        vf_explained_var: 0.9708731770515442\n",
      "        vf_loss: 0.07616536319255829\n",
      "    num_steps_sampled: 13500\n",
      "    num_steps_trained: 13500\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.823809523809516\n",
      "    ram_util_percent: 67.17936507936507\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12329172922112941\n",
      "    mean_env_wait_ms: 422.88041698392436\n",
      "    mean_inference_ms: 1.0867267164038672\n",
      "    mean_raw_obs_processing_ms: 1.7564672058011939\n",
      "  time_since_restore: 1140.3228487968445\n",
      "  time_this_iter_s: 39.34830379486084\n",
      "  time_total_s: 1140.3228487968445\n",
      "  timers:\n",
      "    learn_throughput: 1408.499\n",
      "    learn_time_ms: 354.988\n",
      "    load_throughput: 86034.181\n",
      "    load_time_ms: 5.812\n",
      "    sample_throughput: 13.049\n",
      "    sample_time_ms: 38318.58\n",
      "    update_time_ms: 2.625\n",
      "  timestamp: 1604404542\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13500\n",
      "  training_iteration: 27\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:55:47,052\tWARNING util.py:139 -- The `process_trial` operation took 3.5919528007507324 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:55:47,027\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:55:47,763\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7099580764770508 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         1140.32</td><td style=\"text-align: right;\">13500</td><td style=\"text-align: right;\"> 2.77601</td><td style=\"text-align: right;\">             6.92336</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,520\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,520\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,520\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,520\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,520\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,520\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,520\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,521\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,521\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,521\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,521\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,521\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,523\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,535\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.13229598, 'policy_loss': 0.02251122, 'vf_loss': 0.108901925, 'vf_explained_var': 0.96350497, 'kl': 0.0013078976, 'entropy': 552.6054, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,545\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.011260497, 'policy_loss': -0.115166165, 'vf_loss': 0.09421667, 'vf_explained_var': 0.9688018, 'kl': 0.014354087, 'entropy': 552.43256, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,556\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.054808836, 'policy_loss': -0.1659461, 'vf_loss': 0.0934925, 'vf_explained_var': 0.9690806, 'kl': 0.026140379, 'entropy': 552.3892, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,567\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0726087, 'policy_loss': -0.17898428, 'vf_loss': 0.08571657, 'vf_explained_var': 0.97126704, 'kl': 0.030605957, 'entropy': 552.4627, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,577\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0784628, 'policy_loss': -0.18391746, 'vf_loss': 0.08395511, 'vf_explained_var': 0.9720204, 'kl': 0.03185118, 'entropy': 552.5236, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,587\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08524016, 'policy_loss': -0.18602759, 'vf_loss': 0.078743815, 'vf_explained_var': 0.9738941, 'kl': 0.03265718, 'entropy': 552.5552, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,597\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08507755, 'policy_loss': -0.18672991, 'vf_loss': 0.07853059, 'vf_explained_var': 0.9740091, 'kl': 0.03425447, 'entropy': 552.5808, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,608\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09010946, 'policy_loss': -0.18717833, 'vf_loss': 0.07401705, 'vf_explained_var': 0.975358, 'kl': 0.03415085, 'entropy': 552.601, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,618\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0919969, 'policy_loss': -0.18765052, 'vf_loss': 0.07296255, 'vf_explained_var': 0.9755214, 'kl': 0.03361642, 'entropy': 552.60114, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,629\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09314995, 'policy_loss': -0.18803997, 'vf_loss': 0.07262043, 'vf_explained_var': 0.9756295, 'kl': 0.03299198, 'entropy': 552.5791, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,639\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09623363, 'policy_loss': -0.18816368, 'vf_loss': 0.07031866, 'vf_explained_var': 0.97656363, 'kl': 0.03201685, 'entropy': 552.55524, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,650\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.098474234, 'policy_loss': -0.18825616, 'vf_loss': 0.06916266, 'vf_explained_var': 0.9770152, 'kl': 0.030547066, 'entropy': 552.5521, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,661\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1010764, 'policy_loss': -0.18820356, 'vf_loss': 0.06765968, 'vf_explained_var': 0.97763586, 'kl': 0.028840682, 'entropy': 552.5694, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,671\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10251331, 'policy_loss': -0.18834366, 'vf_loss': 0.06749254, 'vf_explained_var': 0.9775262, 'kl': 0.027167117, 'entropy': 552.593, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,681\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10338193, 'policy_loss': -0.18838239, 'vf_loss': 0.06765297, 'vf_explained_var': 0.97755533, 'kl': 0.025700016, 'entropy': 552.61426, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,692\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10488677, 'policy_loss': -0.18840443, 'vf_loss': 0.067054346, 'vf_explained_var': 0.97778684, 'kl': 0.024390087, 'entropy': 552.6296, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,702\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10638813, 'policy_loss': -0.18842214, 'vf_loss': 0.06652188, 'vf_explained_var': 0.9779408, 'kl': 0.02298093, 'entropy': 552.6396, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,712\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10836824, 'policy_loss': -0.18838806, 'vf_loss': 0.06542879, 'vf_explained_var': 0.97830313, 'kl': 0.021616342, 'entropy': 552.6443, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,722\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10877236, 'policy_loss': -0.18834716, 'vf_loss': 0.06597038, 'vf_explained_var': 0.9781451, 'kl': 0.02015468, 'entropy': 552.64764, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,733\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.110762745, 'policy_loss': -0.18793301, 'vf_loss': 0.06436854, 'vf_explained_var': 0.97862726, 'kl': 0.018965555, 'entropy': 552.6464, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,745\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11159622, 'policy_loss': -0.18843262, 'vf_loss': 0.064655654, 'vf_explained_var': 0.9784832, 'kl': 0.018045522, 'entropy': 552.6369, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,756\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11218832, 'policy_loss': -0.18843818, 'vf_loss': 0.06471937, 'vf_explained_var': 0.9785586, 'kl': 0.017082205, 'entropy': 552.63776, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,768\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11328483, 'policy_loss': -0.18835805, 'vf_loss': 0.06408126, 'vf_explained_var': 0.9787693, 'kl': 0.016284404, 'entropy': 552.637, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,779\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11363828, 'policy_loss': -0.18841748, 'vf_loss': 0.06406491, 'vf_explained_var': 0.9787237, 'kl': 0.015873007, 'entropy': 552.6274, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,792\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11453953, 'policy_loss': -0.18839943, 'vf_loss': 0.06333944, 'vf_explained_var': 0.9789584, 'kl': 0.015585889, 'entropy': 552.62177, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,802\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.116043486, 'policy_loss': -0.18845992, 'vf_loss': 0.062385082, 'vf_explained_var': 0.9792569, 'kl': 0.014861259, 'entropy': 552.62274, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,813\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11607987, 'policy_loss': -0.18831219, 'vf_loss': 0.0628267, 'vf_explained_var': 0.9790859, 'kl': 0.013934251, 'entropy': 552.6357, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,824\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11713118, 'policy_loss': -0.18835449, 'vf_loss': 0.062187225, 'vf_explained_var': 0.9793666, 'kl': 0.013386798, 'entropy': 552.6449, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,836\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11786459, 'policy_loss': -0.18829656, 'vf_loss': 0.061713785, 'vf_explained_var': 0.97948295, 'kl': 0.0129158, 'entropy': 552.6458, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:56:25,858\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11721271, 'policy_loss': -0.18840979, 'vf_loss': 0.062729575, 'vf_explained_var': 0.97918385, 'kl': 0.012544427, 'entropy': 552.6363, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-56-25\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.063958879657779\n",
      "  episode_reward_mean: 2.776030749219716\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 140\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6362915039062\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012544427067041397\n",
      "        model: {}\n",
      "        policy_loss: -0.18840979039669037\n",
      "        total_loss: -0.11721271276473999\n",
      "        vf_explained_var: 0.9791838526725769\n",
      "        vf_loss: 0.06272957473993301\n",
      "    num_steps_sampled: 14000\n",
      "    num_steps_trained: 14000\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.28196721311476\n",
      "    ram_util_percent: 61.53770491803279\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12208358313249855\n",
      "    mean_env_wait_ms: 418.6400426396205\n",
      "    mean_inference_ms: 1.075021143119134\n",
      "    mean_raw_obs_processing_ms: 1.7433262396775961\n",
      "  time_since_restore: 1179.1693189144135\n",
      "  time_this_iter_s: 38.84647011756897\n",
      "  time_total_s: 1179.1693189144135\n",
      "  timers:\n",
      "    learn_throughput: 1403.855\n",
      "    learn_time_ms: 356.162\n",
      "    load_throughput: 88366.621\n",
      "    load_time_ms: 5.658\n",
      "    sample_throughput: 13.025\n",
      "    sample_time_ms: 38387.14\n",
      "    update_time_ms: 2.891\n",
      "  timestamp: 1604404585\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14000\n",
      "  training_iteration: 28\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:56:30,278\tWARNING util.py:139 -- The `process_trial` operation took 3.773275136947632 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:56:31,175\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.8970308303833008 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         1179.17</td><td style=\"text-align: right;\">14000</td><td style=\"text-align: right;\"> 2.77603</td><td style=\"text-align: right;\">             7.06396</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:56:47,408\tINFO sampler.py:800 -- Preprocessed obs: np.ndarray((389,), dtype=float64, min=7.28, max=2437.95, mean=123.257)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:56:47,408\tINFO sampler.py:805 -- Filtered obs: np.ndarray((389,), dtype=float64, min=7.28, max=2437.95, mean=123.257)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:56:47,408\tINFO sampler.py:1223 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'info': {},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'obs': np.ndarray((389,), dtype=float64, min=7.28, max=2437.95, mean=123.257),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_action': np.ndarray((389,), dtype=float32, min=-3.11, max=2.82, mean=-0.111),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_reward': 0.03363723989737866,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:56:47,409\tINFO tf_run_builder.py:87 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:56:47,410\tINFO sampler.py:1269 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': ( np.ndarray((1, 389), dtype=float32, min=-3.554, max=2.478, mean=0.033),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       { 'action_dist_inputs': np.ndarray((1, 778), dtype=float32, min=-0.06, max=0.047, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-541.309, max=-541.309, mean=-541.309),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=4.137, max=4.137, mean=4.137)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:56:47,781\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=7.01, max=2652.379, mean=122.627)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:56:47,782\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:57:08,505\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.24, max=0.274, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-586.536, max=-518.886, mean=-553.83),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.457, max=4.023, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-0.956, max=2.089, mean=-0.246),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=64167638.0, max=64167638.0, mean=64167638.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4778.792, mean=124.808),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.412),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.457, max=4.023, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.18, mean=0.066),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.18, mean=0.066),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=28.0, max=28.0, mean=28.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.009, max=4.265, mean=2.547),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=0.161, max=4.695, mean=2.793)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:57:08,642\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.24, max=0.274, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-586.536, max=-518.886, mean=-553.83),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.457, max=4.023, mean=-0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-0.956, max=2.089, mean=-0.246),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=64167638.0, max=64167638.0, mean=64167638.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4778.792, mean=124.808),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.412),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.457, max=4.023, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.18, mean=0.066),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.18, mean=0.066),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=28.0, max=28.0, mean=28.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.009, max=4.265, mean=2.547),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=0.161, max=4.695, mean=2.793)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,217\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,230\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.09997765, 'policy_loss': 0.0023012552, 'vf_loss': 0.09694826, 'vf_explained_var': 0.9658275, 'kl': 0.0010787406, 'entropy': 552.65265, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,244\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.03501618, 'policy_loss': -0.13056876, 'vf_loss': 0.08915011, 'vf_explained_var': 0.96670276, 'kl': 0.009485123, 'entropy': 552.6345, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,255\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08043004, 'policy_loss': -0.17601585, 'vf_loss': 0.08112561, 'vf_explained_var': 0.9693876, 'kl': 0.021422496, 'entropy': 552.58966, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,266\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0896401, 'policy_loss': -0.18795943, 'vf_loss': 0.08138897, 'vf_explained_var': 0.9695913, 'kl': 0.025081983, 'entropy': 552.6184, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,277\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09369702, 'policy_loss': -0.19340743, 'vf_loss': 0.081085876, 'vf_explained_var': 0.9698377, 'kl': 0.0275919, 'entropy': 552.65704, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,294\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10024715, 'policy_loss': -0.19573916, 'vf_loss': 0.07575844, 'vf_explained_var': 0.9713289, 'kl': 0.029234923, 'entropy': 552.66785, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,308\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09952444, 'policy_loss': -0.19710122, 'vf_loss': 0.076550536, 'vf_explained_var': 0.97163206, 'kl': 0.031149983, 'entropy': 552.6636, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,321\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.103080295, 'policy_loss': -0.19734229, 'vf_loss': 0.07304786, 'vf_explained_var': 0.9723671, 'kl': 0.03142837, 'entropy': 552.6849, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,335\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10688432, 'policy_loss': -0.19773895, 'vf_loss': 0.07007457, 'vf_explained_var': 0.97343874, 'kl': 0.030785253, 'entropy': 552.7149, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,349\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10849295, 'policy_loss': -0.197908, 'vf_loss': 0.069108255, 'vf_explained_var': 0.9738193, 'kl': 0.030084165, 'entropy': 552.72516, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,362\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10965571, 'policy_loss': -0.197648, 'vf_loss': 0.06849343, 'vf_explained_var': 0.97406095, 'kl': 0.028887162, 'entropy': 552.7067, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,376\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11080793, 'policy_loss': -0.19793789, 'vf_loss': 0.0688054, 'vf_explained_var': 0.9738285, 'kl': 0.027147515, 'entropy': 552.6916, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,391\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11185957, 'policy_loss': -0.19826335, 'vf_loss': 0.06872853, 'vf_explained_var': 0.9739539, 'kl': 0.026185548, 'entropy': 552.68463, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,405\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.113565624, 'policy_loss': -0.19833614, 'vf_loss': 0.06788362, 'vf_explained_var': 0.97439736, 'kl': 0.025017643, 'entropy': 552.6778, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,416\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.116105765, 'policy_loss': -0.19837613, 'vf_loss': 0.06635145, 'vf_explained_var': 0.97492296, 'kl': 0.023583585, 'entropy': 552.66754, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,426\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12014514, 'policy_loss': -0.19839631, 'vf_loss': 0.063246794, 'vf_explained_var': 0.97585267, 'kl': 0.022228673, 'entropy': 552.6592, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,436\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.119384505, 'policy_loss': -0.19840991, 'vf_loss': 0.06486089, 'vf_explained_var': 0.97529125, 'kl': 0.020984448, 'entropy': 552.6544, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,447\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.122824214, 'policy_loss': -0.19837992, 'vf_loss': 0.062185064, 'vf_explained_var': 0.9762599, 'kl': 0.01980837, 'entropy': 552.65936, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,459\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.121687554, 'policy_loss': -0.19838446, 'vf_loss': 0.06400373, 'vf_explained_var': 0.9756827, 'kl': 0.018804742, 'entropy': 552.6628, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,473\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.123907804, 'policy_loss': -0.19845204, 'vf_loss': 0.06254186, 'vf_explained_var': 0.9761916, 'kl': 0.017781286, 'entropy': 552.66583, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,485\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12553017, 'policy_loss': -0.1984526, 'vf_loss': 0.06155898, 'vf_explained_var': 0.9765243, 'kl': 0.016834741, 'entropy': 552.66815, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,496\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12660258, 'policy_loss': -0.19846259, 'vf_loss': 0.061077464, 'vf_explained_var': 0.9768081, 'kl': 0.015974142, 'entropy': 552.66187, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,509\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12872846, 'policy_loss': -0.19846286, 'vf_loss': 0.059545305, 'vf_explained_var': 0.97734666, 'kl': 0.015094946, 'entropy': 552.6564, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,522\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12893261, 'policy_loss': -0.19844948, 'vf_loss': 0.059876297, 'vf_explained_var': 0.97719735, 'kl': 0.014282286, 'entropy': 552.6572, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,534\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12914027, 'policy_loss': -0.19844608, 'vf_loss': 0.060066983, 'vf_explained_var': 0.97717476, 'kl': 0.013687141, 'entropy': 552.6601, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,547\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13084166, 'policy_loss': -0.19843389, 'vf_loss': 0.058780257, 'vf_explained_var': 0.9775854, 'kl': 0.013054806, 'entropy': 552.6601, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,559\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13152131, 'policy_loss': -0.19845669, 'vf_loss': 0.058578506, 'vf_explained_var': 0.9776296, 'kl': 0.012380552, 'entropy': 552.6595, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,571\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1317374, 'policy_loss': -0.19839655, 'vf_loss': 0.058645282, 'vf_explained_var': 0.97764903, 'kl': 0.011872408, 'entropy': 552.6621, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,581\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13222314, 'policy_loss': -0.1984417, 'vf_loss': 0.05855943, 'vf_explained_var': 0.9776899, 'kl': 0.011346861, 'entropy': 552.6613, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:09,593\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13275534, 'policy_loss': -0.19835669, 'vf_loss': 0.058167044, 'vf_explained_var': 0.9778094, 'kl': 0.011013761, 'entropy': 552.6569, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-57-09\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.063958879657779\n",
      "  episode_reward_mean: 2.765913725030151\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 145\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6569213867188\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011013761162757874\n",
      "        model: {}\n",
      "        policy_loss: -0.19835668802261353\n",
      "        total_loss: -0.1327553391456604\n",
      "        vf_explained_var: 0.9778094291687012\n",
      "        vf_loss: 0.05816704407334328\n",
      "    num_steps_sampled: 14500\n",
      "    num_steps_trained: 14500\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.780645161290316\n",
      "    ram_util_percent: 68.3983870967742\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12108244820736366\n",
      "    mean_env_wait_ms: 415.12297915548567\n",
      "    mean_inference_ms: 1.065299038006295\n",
      "    mean_raw_obs_processing_ms: 1.7325959717835653\n",
      "  time_since_restore: 1218.517638206482\n",
      "  time_this_iter_s: 39.34831929206848\n",
      "  time_total_s: 1218.517638206482\n",
      "  timers:\n",
      "    learn_throughput: 1404.651\n",
      "    learn_time_ms: 355.96\n",
      "    load_throughput: 91049.49\n",
      "    load_time_ms: 5.492\n",
      "    sample_throughput: 12.947\n",
      "    sample_time_ms: 38619.887\n",
      "    update_time_ms: 2.89\n",
      "  timestamp: 1604404629\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14500\n",
      "  training_iteration: 29\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:57:13,916\tWARNING util.py:139 -- The `process_trial` operation took 3.4790070056915283 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:57:13,895\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:57:14,709\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7931928634643555 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         1218.52</td><td style=\"text-align: right;\">14500</td><td style=\"text-align: right;\"> 2.76591</td><td style=\"text-align: right;\">             7.06396</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,574\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-4.381, max=4.312, mean=0.004),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.058, max=0.179, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=129.895),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.248, max=0.271, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-595.367, max=-507.914, mean=-552.242),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.381, max=4.312, mean=0.004),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-9.628, max=7.001, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=129.895),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.381, max=4.312, mean=0.004),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.058, max=0.179, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.506, max=4.277, mean=0.808),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.522, max=4.469, mean=0.726)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,574\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,575\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,588\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.046117216, 'policy_loss': -0.06442811, 'vf_loss': 0.10959697, 'vf_explained_var': 0.96193975, 'kl': 0.0014049738, 'entropy': 552.6525, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,601\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07514801, 'policy_loss': -0.18972701, 'vf_loss': 0.09969891, 'vf_explained_var': 0.96459216, 'kl': 0.022044579, 'entropy': 552.58124, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,612\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12852184, 'policy_loss': -0.24067907, 'vf_loss': 0.09468272, 'vf_explained_var': 0.96570945, 'kl': 0.02588814, 'entropy': 552.6597, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,623\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14319555, 'policy_loss': -0.25193045, 'vf_loss': 0.08939097, 'vf_explained_var': 0.96740454, 'kl': 0.02865766, 'entropy': 552.75995, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,635\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1477861, 'policy_loss': -0.26019534, 'vf_loss': 0.092933975, 'vf_explained_var': 0.96781254, 'kl': 0.028852254, 'entropy': 552.7082, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,647\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15401714, 'policy_loss': -0.26250452, 'vf_loss': 0.090120375, 'vf_explained_var': 0.9682686, 'kl': 0.027210364, 'entropy': 552.58624, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,658\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15447551, 'policy_loss': -0.26349685, 'vf_loss': 0.08887398, 'vf_explained_var': 0.9683605, 'kl': 0.02984791, 'entropy': 552.5155, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,670\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15762645, 'policy_loss': -0.26417094, 'vf_loss': 0.08725631, 'vf_explained_var': 0.9684653, 'kl': 0.02857506, 'entropy': 552.5273, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,682\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16144368, 'policy_loss': -0.26461962, 'vf_loss': 0.08379362, 'vf_explained_var': 0.96977806, 'kl': 0.028714567, 'entropy': 552.5693, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,694\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1632828, 'policy_loss': -0.26490995, 'vf_loss': 0.08221933, 'vf_explained_var': 0.9704721, 'kl': 0.028752357, 'entropy': 552.5835, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,707\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16583802, 'policy_loss': -0.2650289, 'vf_loss': 0.080733635, 'vf_explained_var': 0.9705605, 'kl': 0.027344039, 'entropy': 552.56604, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,720\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16917028, 'policy_loss': -0.2650935, 'vf_loss': 0.07847741, 'vf_explained_var': 0.97142196, 'kl': 0.025845654, 'entropy': 552.5415, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,732\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1717407, 'policy_loss': -0.2651684, 'vf_loss': 0.07700526, 'vf_explained_var': 0.97198343, 'kl': 0.024329565, 'entropy': 552.5345, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,745\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.174769, 'policy_loss': -0.26520243, 'vf_loss': 0.07492576, 'vf_explained_var': 0.97269374, 'kl': 0.022974325, 'entropy': 552.5492, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,757\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17744581, 'policy_loss': -0.26514354, 'vf_loss': 0.07298508, 'vf_explained_var': 0.97356623, 'kl': 0.021796511, 'entropy': 552.56793, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,768\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17821817, 'policy_loss': -0.26523337, 'vf_loss': 0.07293314, 'vf_explained_var': 0.97358465, 'kl': 0.020862311, 'entropy': 552.5798, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,780\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17997563, 'policy_loss': -0.2652038, 'vf_loss': 0.07190011, 'vf_explained_var': 0.9737968, 'kl': 0.019745281, 'entropy': 552.58844, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,792\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18078423, 'policy_loss': -0.26522064, 'vf_loss': 0.071771406, 'vf_explained_var': 0.9737847, 'kl': 0.018762993, 'entropy': 552.5947, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,804\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1832654, 'policy_loss': -0.26527634, 'vf_loss': 0.06988165, 'vf_explained_var': 0.97446436, 'kl': 0.01796931, 'entropy': 552.6015, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,817\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18440503, 'policy_loss': -0.26528642, 'vf_loss': 0.0693095, 'vf_explained_var': 0.97471046, 'kl': 0.01714349, 'entropy': 552.60626, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,829\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18609971, 'policy_loss': -0.26532766, 'vf_loss': 0.06822021, 'vf_explained_var': 0.9751014, 'kl': 0.01630778, 'entropy': 552.6109, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,841\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1871258, 'policy_loss': -0.26533338, 'vf_loss': 0.06779199, 'vf_explained_var': 0.97525495, 'kl': 0.015430476, 'entropy': 552.61395, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,853\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18798614, 'policy_loss': -0.26535308, 'vf_loss': 0.06741399, 'vf_explained_var': 0.97542435, 'kl': 0.014745136, 'entropy': 552.6149, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,865\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18803573, 'policy_loss': -0.26535285, 'vf_loss': 0.06783958, 'vf_explained_var': 0.97530967, 'kl': 0.014040776, 'entropy': 552.61725, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,877\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1884852, 'policy_loss': -0.2653228, 'vf_loss': 0.06777849, 'vf_explained_var': 0.97540087, 'kl': 0.013420881, 'entropy': 552.6191, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,890\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.19014215, 'policy_loss': -0.2653412, 'vf_loss': 0.066503935, 'vf_explained_var': 0.9757006, 'kl': 0.012881669, 'entropy': 552.6245, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,901\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1894918, 'policy_loss': -0.2652578, 'vf_loss': 0.06738493, 'vf_explained_var': 0.9755032, 'kl': 0.01241637, 'entropy': 552.63055, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,914\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1907996, 'policy_loss': -0.26534536, 'vf_loss': 0.06645819, 'vf_explained_var': 0.97584504, 'kl': 0.011981618, 'entropy': 552.6367, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,926\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.19132619, 'policy_loss': -0.26535812, 'vf_loss': 0.06619434, 'vf_explained_var': 0.97579974, 'kl': 0.011611227, 'entropy': 552.6412, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:57:51,939\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1906848, 'policy_loss': -0.26535088, 'vf_loss': 0.06707903, 'vf_explained_var': 0.9756391, 'kl': 0.011240036, 'entropy': 552.64594, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-57-51\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.063958879657779\n",
      "  episode_reward_mean: 2.7627458074649835\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 150\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6459350585938\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011240036226809025\n",
      "        model: {}\n",
      "        policy_loss: -0.265350878238678\n",
      "        total_loss: -0.19068479537963867\n",
      "        vf_explained_var: 0.9756391048431396\n",
      "        vf_loss: 0.06707902997732162\n",
      "    num_steps_sampled: 15000\n",
      "    num_steps_trained: 15000\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 35.937288135593214\n",
      "    ram_util_percent: 71.0813559322034\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12024191252803204\n",
      "    mean_env_wait_ms: 412.1787404279447\n",
      "    mean_inference_ms: 1.0571557559097569\n",
      "    mean_raw_obs_processing_ms: 1.723920221006121\n",
      "  time_since_restore: 1256.5713431835175\n",
      "  time_this_iter_s: 38.05370497703552\n",
      "  time_total_s: 1256.5713431835175\n",
      "  timers:\n",
      "    learn_throughput: 1389.06\n",
      "    learn_time_ms: 359.956\n",
      "    load_throughput: 86726.907\n",
      "    load_time_ms: 5.765\n",
      "    sample_throughput: 12.945\n",
      "    sample_time_ms: 38624.658\n",
      "    update_time_ms: 2.907\n",
      "  timestamp: 1604404671\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15000\n",
      "  training_iteration: 30\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:57:56,901\tWARNING util.py:139 -- The `process_trial` operation took 3.536497116088867 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:57:57,571\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.6695539951324463 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 8.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         1256.57</td><td style=\"text-align: right;\">15000</td><td style=\"text-align: right;\"> 2.76275</td><td style=\"text-align: right;\">             7.06396</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-514.094, max=-514.094, mean=-514.094),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=3.128, max=3.128, mean=3.128)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:58:14,497\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=7.28, max=4313.596, mean=123.206)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:58:14,498\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:58:33,663\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.223, max=0.263, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-590.683, max=-514.094, mean=-551.636),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.164, max=3.841, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-0.595, max=2.275, mean=0.154),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=1854873752.0, max=1854873752.0, mean=1854873752.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4736.833, mean=124.632),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.229),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.164, max=3.841, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=30.0, max=30.0, mean=30.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.018, max=4.45, mean=2.68),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=-0.009, max=4.531, mean=2.527)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:58:33,815\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.223, max=0.263, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-590.683, max=-514.094, mean=-551.636),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.164, max=3.841, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-0.595, max=2.275, mean=0.154),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=1854873752.0, max=1854873752.0, mean=1854873752.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4736.833, mean=124.632),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.229),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.164, max=3.841, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.183, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=30.0, max=30.0, mean=30.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.018, max=4.45, mean=2.68),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=-0.009, max=4.531, mean=2.527)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,430\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,430\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,430\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,430\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,430\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,430\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,430\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,430\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,430\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,430\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,430\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,430\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,432\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,445\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.13931932, 'policy_loss': 0.02545385, 'vf_loss': 0.11331413, 'vf_explained_var': 0.95758027, 'kl': 0.0008167843, 'entropy': 552.66327, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,456\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.0020811558, 'policy_loss': -0.10721752, 'vf_loss': 0.102705956, 'vf_explained_var': 0.9619507, 'kl': 0.009767012, 'entropy': 552.6728, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,467\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.053602625, 'policy_loss': -0.16350763, 'vf_loss': 0.09619447, 'vf_explained_var': 0.9630998, 'kl': 0.020311896, 'entropy': 552.69696, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,480\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.063133426, 'policy_loss': -0.17463215, 'vf_loss': 0.09355718, 'vf_explained_var': 0.9642127, 'kl': 0.026580064, 'entropy': 552.72455, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,491\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06838446, 'policy_loss': -0.1791244, 'vf_loss': 0.090447135, 'vf_explained_var': 0.9665, 'kl': 0.030063385, 'entropy': 552.7274, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,503\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07178552, 'policy_loss': -0.18078806, 'vf_loss': 0.08829755, 'vf_explained_var': 0.9662668, 'kl': 0.030674078, 'entropy': 552.6904, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,514\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07415542, 'policy_loss': -0.18167405, 'vf_loss': 0.08622255, 'vf_explained_var': 0.9677771, 'kl': 0.03154974, 'entropy': 552.6514, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,526\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.079726405, 'policy_loss': -0.18239725, 'vf_loss': 0.081245154, 'vf_explained_var': 0.96923184, 'kl': 0.03174178, 'entropy': 552.6335, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,539\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08268709, 'policy_loss': -0.18259676, 'vf_loss': 0.07893614, 'vf_explained_var': 0.96947813, 'kl': 0.031071937, 'entropy': 552.6348, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,552\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08387429, 'policy_loss': -0.18287404, 'vf_loss': 0.07860807, 'vf_explained_var': 0.96954423, 'kl': 0.030209899, 'entropy': 552.6348, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,563\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0863717, 'policy_loss': -0.18292807, 'vf_loss': 0.0769934, 'vf_explained_var': 0.9697295, 'kl': 0.02898218, 'entropy': 552.633, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,574\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08335399, 'policy_loss': -0.18294822, 'vf_loss': 0.08084109, 'vf_explained_var': 0.96927565, 'kl': 0.027782425, 'entropy': 552.63055, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,585\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08828177, 'policy_loss': -0.1830278, 'vf_loss': 0.07701569, 'vf_explained_var': 0.9701803, 'kl': 0.026267173, 'entropy': 552.63666, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,595\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.090607874, 'policy_loss': -0.18307078, 'vf_loss': 0.07563579, 'vf_explained_var': 0.9706524, 'kl': 0.024929097, 'entropy': 552.6496, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,607\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08770443, 'policy_loss': -0.18311085, 'vf_loss': 0.07941728, 'vf_explained_var': 0.9695294, 'kl': 0.023687636, 'entropy': 552.6605, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,617\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0918544, 'policy_loss': -0.18309246, 'vf_loss': 0.07609739, 'vf_explained_var': 0.97049004, 'kl': 0.022430614, 'entropy': 552.66656, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,628\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.090216964, 'policy_loss': -0.18313926, 'vf_loss': 0.078491576, 'vf_explained_var': 0.96963835, 'kl': 0.02137885, 'entropy': 552.6739, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,639\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.091000706, 'policy_loss': -0.18315075, 'vf_loss': 0.078439765, 'vf_explained_var': 0.9692817, 'kl': 0.020311564, 'entropy': 552.6778, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,650\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.095990665, 'policy_loss': -0.18315798, 'vf_loss': 0.07409411, 'vf_explained_var': 0.97064734, 'kl': 0.019367753, 'entropy': 552.6744, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,661\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0968175, 'policy_loss': -0.1831639, 'vf_loss': 0.07400848, 'vf_explained_var': 0.9710744, 'kl': 0.018278383, 'entropy': 552.6728, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,673\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10042123, 'policy_loss': -0.18308835, 'vf_loss': 0.071060605, 'vf_explained_var': 0.9720721, 'kl': 0.017194843, 'entropy': 552.6701, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,684\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1015413, 'policy_loss': -0.18314141, 'vf_loss': 0.07055709, 'vf_explained_var': 0.9721918, 'kl': 0.016360037, 'entropy': 552.66376, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,696\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10251844, 'policy_loss': -0.18315643, 'vf_loss': 0.070095435, 'vf_explained_var': 0.9724181, 'kl': 0.0156186, 'entropy': 552.66394, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,708\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10448208, 'policy_loss': -0.18317385, 'vf_loss': 0.06861561, 'vf_explained_var': 0.9728586, 'kl': 0.014927696, 'entropy': 552.66864, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,719\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10504759, 'policy_loss': -0.18318476, 'vf_loss': 0.06850018, 'vf_explained_var': 0.97286457, 'kl': 0.014277036, 'entropy': 552.6742, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,731\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10628978, 'policy_loss': -0.18317635, 'vf_loss': 0.06771725, 'vf_explained_var': 0.97313076, 'kl': 0.0135842, 'entropy': 552.67456, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,743\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.106344275, 'policy_loss': -0.18318503, 'vf_loss': 0.06812388, 'vf_explained_var': 0.97310513, 'kl': 0.0129138855, 'entropy': 552.67456, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,754\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.107146956, 'policy_loss': -0.18318999, 'vf_loss': 0.06764783, 'vf_explained_var': 0.97323203, 'kl': 0.0124373315, 'entropy': 552.67633, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,764\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10769347, 'policy_loss': -0.18318547, 'vf_loss': 0.06746323, 'vf_explained_var': 0.973075, 'kl': 0.011894462, 'entropy': 552.6779, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:58:34,776\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.109319866, 'policy_loss': -0.18319808, 'vf_loss': 0.06617787, 'vf_explained_var': 0.9736715, 'kl': 0.011407959, 'entropy': 552.6768, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-58-34\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.063958879657779\n",
      "  episode_reward_mean: 2.7726903813622097\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 155\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6768188476562\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011407959274947643\n",
      "        model: {}\n",
      "        policy_loss: -0.18319807946681976\n",
      "        total_loss: -0.10931986570358276\n",
      "        vf_explained_var: 0.9736714959144592\n",
      "        vf_loss: 0.0661778673529625\n",
      "    num_steps_sampled: 15500\n",
      "    num_steps_trained: 15500\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.43934426229508\n",
      "    ram_util_percent: 55.667213114754105\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11953651955245309\n",
      "    mean_env_wait_ms: 409.7109983534529\n",
      "    mean_inference_ms: 1.050310702860661\n",
      "    mean_raw_obs_processing_ms: 1.7167763506302414\n",
      "  time_since_restore: 1294.4757194519043\n",
      "  time_this_iter_s: 37.90437626838684\n",
      "  time_total_s: 1294.4757194519043\n",
      "  timers:\n",
      "    learn_throughput: 1406.836\n",
      "    learn_time_ms: 355.407\n",
      "    load_throughput: 89440.324\n",
      "    load_time_ms: 5.59\n",
      "    sample_throughput: 12.984\n",
      "    sample_time_ms: 38508.595\n",
      "    update_time_ms: 2.894\n",
      "  timestamp: 1604404714\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15500\n",
      "  training_iteration: 31\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:58:38,701\tWARNING util.py:139 -- The `process_trial` operation took 3.2888078689575195 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:58:38,681\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 12:58:39,371\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.6689670085906982 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 9.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         1294.48</td><td style=\"text-align: right;\">15500</td><td style=\"text-align: right;\"> 2.77269</td><td style=\"text-align: right;\">             7.06396</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,295\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,307\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.069793254, 'policy_loss': -0.018218016, 'vf_loss': 0.08694908, 'vf_explained_var': 0.97109604, 'kl': 0.0015736312, 'entropy': 552.5984, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,318\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.044716742, 'policy_loss': -0.1352381, 'vf_loss': 0.078753866, 'vf_explained_var': 0.9745963, 'kl': 0.017433316, 'entropy': 552.5898, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,329\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10315111, 'policy_loss': -0.1919965, 'vf_loss': 0.07143723, 'vf_explained_var': 0.97609204, 'kl': 0.025789857, 'entropy': 552.502, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,341\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12002108, 'policy_loss': -0.20869505, 'vf_loss': 0.068247, 'vf_explained_var': 0.9771285, 'kl': 0.030262208, 'entropy': 552.40625, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,352\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12433732, 'policy_loss': -0.21316074, 'vf_loss': 0.06292027, 'vf_explained_var': 0.9789591, 'kl': 0.03837503, 'entropy': 552.4012, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,362\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13093658, 'policy_loss': -0.21654962, 'vf_loss': 0.060157854, 'vf_explained_var': 0.9801731, 'kl': 0.037711386, 'entropy': 552.4942, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,373\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13466553, 'policy_loss': -0.21831308, 'vf_loss': 0.058417946, 'vf_explained_var': 0.9808797, 'kl': 0.03737716, 'entropy': 552.58246, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,383\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13906749, 'policy_loss': -0.21904385, 'vf_loss': 0.054632906, 'vf_explained_var': 0.9817956, 'kl': 0.03754585, 'entropy': 552.60785, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,394\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14544626, 'policy_loss': -0.21958643, 'vf_loss': 0.05013205, 'vf_explained_var': 0.9833102, 'kl': 0.035567593, 'entropy': 552.58575, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,405\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15074043, 'policy_loss': -0.21985205, 'vf_loss': 0.046328396, 'vf_explained_var': 0.9846575, 'kl': 0.033752922, 'entropy': 552.5527, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,416\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1543421, 'policy_loss': -0.21998823, 'vf_loss': 0.044193495, 'vf_explained_var': 0.9854307, 'kl': 0.031781673, 'entropy': 552.5336, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,426\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15857738, 'policy_loss': -0.22019495, 'vf_loss': 0.041694287, 'vf_explained_var': 0.9863406, 'kl': 0.029515995, 'entropy': 552.5384, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,437\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16330199, 'policy_loss': -0.22042538, 'vf_loss': 0.038626768, 'vf_explained_var': 0.9870741, 'kl': 0.027402436, 'entropy': 552.55206, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,448\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16460381, 'policy_loss': -0.22047935, 'vf_loss': 0.038473945, 'vf_explained_var': 0.9871324, 'kl': 0.02578015, 'entropy': 552.5641, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,460\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16665709, 'policy_loss': -0.22054322, 'vf_loss': 0.03744177, 'vf_explained_var': 0.9876192, 'kl': 0.024362018, 'entropy': 552.5711, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,471\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1678647, 'policy_loss': -0.22061591, 'vf_loss': 0.037132874, 'vf_explained_var': 0.9876668, 'kl': 0.023138283, 'entropy': 552.5829, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,482\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16963732, 'policy_loss': -0.22065103, 'vf_loss': 0.036360215, 'vf_explained_var': 0.98790455, 'kl': 0.021708941, 'entropy': 552.6008, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,494\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16924363, 'policy_loss': -0.22067952, 'vf_loss': 0.03783468, 'vf_explained_var': 0.9873782, 'kl': 0.020149916, 'entropy': 552.6189, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,505\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17159809, 'policy_loss': -0.22069578, 'vf_loss': 0.036304913, 'vf_explained_var': 0.98788804, 'kl': 0.018952208, 'entropy': 552.6277, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,516\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17254233, 'policy_loss': -0.22069506, 'vf_loss': 0.036025893, 'vf_explained_var': 0.9880647, 'kl': 0.017965676, 'entropy': 552.62274, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,528\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17428875, 'policy_loss': -0.22047174, 'vf_loss': 0.034327574, 'vf_explained_var': 0.98849803, 'kl': 0.017563606, 'entropy': 552.6064, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,539\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17364578, 'policy_loss': -0.22051038, 'vf_loss': 0.03554662, 'vf_explained_var': 0.98846203, 'kl': 0.016767358, 'entropy': 552.5977, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,551\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1770281, 'policy_loss': -0.22064416, 'vf_loss': 0.033035476, 'vf_explained_var': 0.98891044, 'kl': 0.015674928, 'entropy': 552.60016, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,564\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17535041, 'policy_loss': -0.22072737, 'vf_loss': 0.035570674, 'vf_explained_var': 0.98852897, 'kl': 0.01452783, 'entropy': 552.6103, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,576\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.178071, 'policy_loss': -0.22073723, 'vf_loss': 0.033196602, 'vf_explained_var': 0.98888654, 'kl': 0.014029088, 'entropy': 552.6171, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,587\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17787832, 'policy_loss': -0.22069995, 'vf_loss': 0.033785637, 'vf_explained_var': 0.9889119, 'kl': 0.013386697, 'entropy': 552.6171, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,599\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1771984, 'policy_loss': -0.22071952, 'vf_loss': 0.035078697, 'vf_explained_var': 0.98892456, 'kl': 0.012507301, 'entropy': 552.6142, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,611\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17737989, 'policy_loss': -0.22071369, 'vf_loss': 0.035141625, 'vf_explained_var': 0.9885287, 'kl': 0.012136559, 'entropy': 552.6062, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,624\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17898506, 'policy_loss': -0.22071989, 'vf_loss': 0.03386872, 'vf_explained_var': 0.98893255, 'kl': 0.011653524, 'entropy': 552.59686, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:17,637\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18053691, 'policy_loss': -0.22075246, 'vf_loss': 0.032882564, 'vf_explained_var': 0.9891467, 'kl': 0.010863674, 'entropy': 552.59375, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-59-17\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.063958879657779\n",
      "  episode_reward_mean: 2.7703524224037217\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 160\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.59375\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010863673873245716\n",
      "        model: {}\n",
      "        policy_loss: -0.22075246274471283\n",
      "        total_loss: -0.1805369108915329\n",
      "        vf_explained_var: 0.9891467094421387\n",
      "        vf_loss: 0.03288256376981735\n",
      "    num_steps_sampled: 16000\n",
      "    num_steps_trained: 16000\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.640983606557384\n",
      "    ram_util_percent: 62.36721311475411\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11894961153067211\n",
      "    mean_env_wait_ms: 407.65601573753804\n",
      "    mean_inference_ms: 1.044526073291597\n",
      "    mean_raw_obs_processing_ms: 1.7094691345488147\n",
      "  time_since_restore: 1333.4426445960999\n",
      "  time_this_iter_s: 38.96692514419556\n",
      "  time_total_s: 1333.4426445960999\n",
      "  timers:\n",
      "    learn_throughput: 1405.133\n",
      "    learn_time_ms: 355.838\n",
      "    load_throughput: 94237.928\n",
      "    load_time_ms: 5.306\n",
      "    sample_throughput: 12.978\n",
      "    sample_time_ms: 38526.024\n",
      "    update_time_ms: 2.942\n",
      "  timestamp: 1604404757\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 32\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 12:59:21,689\tWARNING util.py:139 -- The `process_trial` operation took 3.2245378494262695 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 12:59:22,507\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.8159968852996826 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.4/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         1333.44</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\"> 2.77035</td><td style=\"text-align: right;\">             7.06396</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                    'action_logp': np.ndarray((100,), dtype=float32, min=-590.609, max=-519.518, mean=-552.504),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.118, max=3.967, mean=-0.008),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-0.688, max=1.433, mean=-0.055),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=1016821658.0, max=1016821658.0, mean=1016821658.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4684.316, mean=124.195),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.849),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.118, max=3.967, mean=-0.007),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.178, mean=0.065),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.178, mean=0.066),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=32.0, max=32.0, mean=32.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.013, max=4.252, mean=2.515),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=0.105, max=4.525, mean=2.57)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 12:59:58,020\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.226, max=0.32, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-590.609, max=-519.518, mean=-552.504),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.118, max=3.967, mean=-0.008),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-0.688, max=1.433, mean=-0.055),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=1016821658.0, max=1016821658.0, mean=1016821658.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4684.316, mean=124.195),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.849),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.118, max=3.967, mean=-0.007),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.178, mean=0.065),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.178, mean=0.066),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=32.0, max=32.0, mean=32.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.013, max=4.252, mean=2.515),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=0.105, max=4.525, mean=2.57)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,590\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-4.353, max=4.65, mean=-0.003),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.06, max=0.178, mean=0.027),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.038),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.226, max=0.32, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-597.193, max=-517.229, mean=-552.931),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.353, max=4.65, mean=-0.003),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-10.462, max=4.008, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.038),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.353, max=4.65, mean=-0.003),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.06, max=0.178, mean=0.027),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.489, max=4.252, mean=0.755),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.528, max=4.525, mean=0.741)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,590\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,591\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,602\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.12538439, 'policy_loss': -0.0027435806, 'vf_loss': 0.12764151, 'vf_explained_var': 0.953172, 'kl': 0.00072068005, 'entropy': 552.59546, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,613\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.034019332, 'policy_loss': -0.14920829, 'vf_loss': 0.11093039, 'vf_explained_var': 0.9614153, 'kl': 0.006308984, 'entropy': 552.4948, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,625\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08625577, 'policy_loss': -0.1960891, 'vf_loss': 0.10125437, 'vf_explained_var': 0.9633363, 'kl': 0.012709592, 'entropy': 552.4771, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,637\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09937355, 'policy_loss': -0.21146287, 'vf_loss': 0.10003593, 'vf_explained_var': 0.96430093, 'kl': 0.017856902, 'entropy': 552.54504, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,649\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10333293, 'policy_loss': -0.21515663, 'vf_loss': 0.09640828, 'vf_explained_var': 0.96559006, 'kl': 0.022837674, 'entropy': 552.609, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,660\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10756419, 'policy_loss': -0.21624629, 'vf_loss': 0.09129974, 'vf_explained_var': 0.96718425, 'kl': 0.025751645, 'entropy': 552.6348, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,671\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.110925935, 'policy_loss': -0.2169513, 'vf_loss': 0.08758599, 'vf_explained_var': 0.9679725, 'kl': 0.027317584, 'entropy': 552.6327, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,683\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.115623884, 'policy_loss': -0.21722563, 'vf_loss': 0.082832575, 'vf_explained_var': 0.9696891, 'kl': 0.027806208, 'entropy': 552.6197, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,694\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11977156, 'policy_loss': -0.21755552, 'vf_loss': 0.07929284, 'vf_explained_var': 0.9713556, 'kl': 0.027394256, 'entropy': 552.6064, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,705\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12204381, 'policy_loss': -0.2176633, 'vf_loss': 0.07742407, 'vf_explained_var': 0.97194725, 'kl': 0.026956193, 'entropy': 552.5995, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,716\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11719323, 'policy_loss': -0.2177393, 'vf_loss': 0.08303763, 'vf_explained_var': 0.96983504, 'kl': 0.025938414, 'entropy': 552.59625, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,728\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12613648, 'policy_loss': -0.21783997, 'vf_loss': 0.07510934, 'vf_explained_var': 0.97301435, 'kl': 0.02458395, 'entropy': 552.5984, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,740\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1318957, 'policy_loss': -0.21789317, 'vf_loss': 0.07037433, 'vf_explained_var': 0.97426814, 'kl': 0.023145378, 'entropy': 552.606, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,751\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12805554, 'policy_loss': -0.21792366, 'vf_loss': 0.074874215, 'vf_explained_var': 0.9729762, 'kl': 0.022213167, 'entropy': 552.61456, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,769\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13177152, 'policy_loss': -0.21796839, 'vf_loss': 0.071980305, 'vf_explained_var': 0.9737654, 'kl': 0.021061562, 'entropy': 552.62054, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,784\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13396811, 'policy_loss': -0.21800359, 'vf_loss': 0.07060974, 'vf_explained_var': 0.97415614, 'kl': 0.019889956, 'entropy': 552.6239, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,796\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13503428, 'policy_loss': -0.21801662, 'vf_loss': 0.070259504, 'vf_explained_var': 0.97447985, 'kl': 0.01884863, 'entropy': 552.6279, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,807\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13627733, 'policy_loss': -0.2178932, 'vf_loss': 0.06960162, 'vf_explained_var': 0.974555, 'kl': 0.01779891, 'entropy': 552.63165, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,818\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1385528, 'policy_loss': -0.21804643, 'vf_loss': 0.0680658, 'vf_explained_var': 0.975262, 'kl': 0.016930094, 'entropy': 552.6336, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,828\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14026858, 'policy_loss': -0.21805756, 'vf_loss': 0.06693431, 'vf_explained_var': 0.97562885, 'kl': 0.016080964, 'entropy': 552.63385, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,838\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1412208, 'policy_loss': -0.21806954, 'vf_loss': 0.06658181, 'vf_explained_var': 0.975802, 'kl': 0.015210275, 'entropy': 552.6347, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,849\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14379281, 'policy_loss': -0.2180516, 'vf_loss': 0.064497, 'vf_explained_var': 0.9762831, 'kl': 0.014461898, 'entropy': 552.63257, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,860\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14237678, 'policy_loss': -0.2180844, 'vf_loss': 0.06639545, 'vf_explained_var': 0.9761054, 'kl': 0.013795783, 'entropy': 552.63495, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,873\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14595234, 'policy_loss': -0.21809717, 'vf_loss': 0.063267924, 'vf_explained_var': 0.9765451, 'kl': 0.013150956, 'entropy': 552.637, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,889\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14470078, 'policy_loss': -0.21808755, 'vf_loss': 0.06492594, 'vf_explained_var': 0.97672063, 'kl': 0.012534599, 'entropy': 552.63574, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,904\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14703402, 'policy_loss': -0.21810876, 'vf_loss': 0.0629726, 'vf_explained_var': 0.97723675, 'kl': 0.012003179, 'entropy': 552.6312, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,917\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14827697, 'policy_loss': -0.21811114, 'vf_loss': 0.06204811, 'vf_explained_var': 0.9771773, 'kl': 0.01153488, 'entropy': 552.6265, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,929\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1482747, 'policy_loss': -0.21810488, 'vf_loss': 0.06234665, 'vf_explained_var': 0.97728986, 'kl': 0.011086731, 'entropy': 552.62396, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,940\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15020868, 'policy_loss': -0.2181043, 'vf_loss': 0.060699746, 'vf_explained_var': 0.9775693, 'kl': 0.010660547, 'entropy': 552.6254, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 12:59:58,951\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1506834, 'policy_loss': -0.21810955, 'vf_loss': 0.06049637, 'vf_explained_var': 0.97784346, 'kl': 0.010266342, 'entropy': 552.63214, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_12-59-58\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.063958879657779\n",
      "  episode_reward_mean: 2.7608530867136527\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 165\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6321411132812\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01026634220033884\n",
      "        model: {}\n",
      "        policy_loss: -0.21810954809188843\n",
      "        total_loss: -0.15068340301513672\n",
      "        vf_explained_var: 0.9778434634208679\n",
      "        vf_loss: 0.06049637123942375\n",
      "    num_steps_sampled: 16500\n",
      "    num_steps_trained: 16500\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 35.524137931034474\n",
      "    ram_util_percent: 65.09827586206897\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1184426606828509\n",
      "    mean_env_wait_ms: 405.8835038415971\n",
      "    mean_inference_ms: 1.0394817166974197\n",
      "    mean_raw_obs_processing_ms: 1.7031796161308324\n",
      "  time_since_restore: 1370.7332966327667\n",
      "  time_this_iter_s: 37.29065203666687\n",
      "  time_total_s: 1370.7332966327667\n",
      "  timers:\n",
      "    learn_throughput: 1406.249\n",
      "    learn_time_ms: 355.556\n",
      "    load_throughput: 91539.116\n",
      "    load_time_ms: 5.462\n",
      "    sample_throughput: 13.012\n",
      "    sample_time_ms: 38426.815\n",
      "    update_time_ms: 2.948\n",
      "  timestamp: 1604404798\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16500\n",
      "  training_iteration: 33\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 13:00:03,529\tWARNING util.py:139 -- The `process_trial` operation took 3.73838210105896 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:00:03,508\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 13:00:04,280\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7497663497924805 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         1370.73</td><td style=\"text-align: right;\">16500</td><td style=\"text-align: right;\"> 2.76085</td><td style=\"text-align: right;\">             7.06396</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,614\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,614\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,614\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,614\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,614\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,614\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,614\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,614\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,614\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,614\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,614\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,614\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,616\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,629\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.087987326, 'policy_loss': -0.0048315357, 'vf_loss': 0.09178555, 'vf_explained_var': 0.97047395, 'kl': 0.0015308204, 'entropy': 552.61554, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,641\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.046219405, 'policy_loss': -0.12981838, 'vf_loss': 0.076664954, 'vf_explained_var': 0.9744086, 'kl': 0.010272622, 'entropy': 552.58044, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,653\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.091706, 'policy_loss': -0.17536521, 'vf_loss': 0.0694347, 'vf_explained_var': 0.9768374, 'kl': 0.021073349, 'entropy': 552.55585, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,664\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.104850866, 'policy_loss': -0.19314285, 'vf_loss': 0.06856591, 'vf_explained_var': 0.97706145, 'kl': 0.029223815, 'entropy': 552.55963, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,679\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.111452796, 'policy_loss': -0.19966, 'vf_loss': 0.06415385, 'vf_explained_var': 0.9783229, 'kl': 0.03563462, 'entropy': 552.60345, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,694\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1136416, 'policy_loss': -0.20333584, 'vf_loss': 0.064877935, 'vf_explained_var': 0.97829026, 'kl': 0.03676488, 'entropy': 552.6353, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,708\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1232157, 'policy_loss': -0.204868, 'vf_loss': 0.057735234, 'vf_explained_var': 0.98052263, 'kl': 0.035432693, 'entropy': 552.64777, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,721\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1287192, 'policy_loss': -0.2054391, 'vf_loss': 0.05462986, 'vf_explained_var': 0.98148507, 'kl': 0.032725994, 'entropy': 552.6268, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,736\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1322208, 'policy_loss': -0.20602356, 'vf_loss': 0.05280863, 'vf_explained_var': 0.9822809, 'kl': 0.03110239, 'entropy': 552.5987, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,750\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1322785, 'policy_loss': -0.20635653, 'vf_loss': 0.053381126, 'vf_explained_var': 0.9822629, 'kl': 0.03066206, 'entropy': 552.59204, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,763\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13710254, 'policy_loss': -0.20627403, 'vf_loss': 0.050337587, 'vf_explained_var': 0.9831608, 'kl': 0.027902065, 'entropy': 552.61316, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,776\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14118913, 'policy_loss': -0.20642214, 'vf_loss': 0.04810415, 'vf_explained_var': 0.9838197, 'kl': 0.025376072, 'entropy': 552.6436, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,789\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13985458, 'policy_loss': -0.20656215, 'vf_loss': 0.050572023, 'vf_explained_var': 0.9834609, 'kl': 0.023904512, 'entropy': 552.66034, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,800\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14544515, 'policy_loss': -0.20667696, 'vf_loss': 0.04600203, 'vf_explained_var': 0.984576, 'kl': 0.022562651, 'entropy': 552.6617, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,812\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14707418, 'policy_loss': -0.20671324, 'vf_loss': 0.045047697, 'vf_explained_var': 0.9847543, 'kl': 0.021616831, 'entropy': 552.6516, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,823\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14783114, 'policy_loss': -0.20675702, 'vf_loss': 0.04522367, 'vf_explained_var': 0.98479605, 'kl': 0.020299606, 'entropy': 552.6396, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,835\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15229498, 'policy_loss': -0.2067907, 'vf_loss': 0.041727353, 'vf_explained_var': 0.9859905, 'kl': 0.018916119, 'entropy': 552.6292, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,846\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1520139, 'policy_loss': -0.20678103, 'vf_loss': 0.04274742, 'vf_explained_var': 0.9856131, 'kl': 0.017806998, 'entropy': 552.6203, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,859\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15409058, 'policy_loss': -0.20677583, 'vf_loss': 0.041379444, 'vf_explained_var': 0.98608476, 'kl': 0.016749332, 'entropy': 552.6121, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,871\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15513737, 'policy_loss': -0.20681326, 'vf_loss': 0.040933747, 'vf_explained_var': 0.98621696, 'kl': 0.01591427, 'entropy': 552.6092, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,885\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15595384, 'policy_loss': -0.20678782, 'vf_loss': 0.040633727, 'vf_explained_var': 0.9863179, 'kl': 0.015111486, 'entropy': 552.61395, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,899\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1577811, 'policy_loss': -0.20682244, 'vf_loss': 0.039368927, 'vf_explained_var': 0.98678964, 'kl': 0.014329497, 'entropy': 552.6202, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,913\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15963188, 'policy_loss': -0.20683463, 'vf_loss': 0.038047735, 'vf_explained_var': 0.98722416, 'kl': 0.013562963, 'entropy': 552.62067, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,925\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16060247, 'policy_loss': -0.20684016, 'vf_loss': 0.0375399, 'vf_explained_var': 0.98735434, 'kl': 0.012885634, 'entropy': 552.6178, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,938\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16084623, 'policy_loss': -0.20682313, 'vf_loss': 0.03764443, 'vf_explained_var': 0.98728675, 'kl': 0.012344401, 'entropy': 552.6186, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,949\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16145484, 'policy_loss': -0.20683908, 'vf_loss': 0.03742871, 'vf_explained_var': 0.98733383, 'kl': 0.011786007, 'entropy': 552.6188, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,960\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16218877, 'policy_loss': -0.20684941, 'vf_loss': 0.037121944, 'vf_explained_var': 0.98748356, 'kl': 0.011168445, 'entropy': 552.6169, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,973\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16453445, 'policy_loss': -0.20686193, 'vf_loss': 0.035189386, 'vf_explained_var': 0.98817664, 'kl': 0.010574947, 'entropy': 552.6138, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,984\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1631306, 'policy_loss': -0.20686044, 'vf_loss': 0.03691401, 'vf_explained_var': 0.98763275, 'kl': 0.010097517, 'entropy': 552.61066, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:00:41,996\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16520737, 'policy_loss': -0.20686121, 'vf_loss': 0.035129573, 'vf_explained_var': 0.9881771, 'kl': 0.0096656075, 'entropy': 552.6096, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_13-00-42\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.104304871784551\n",
      "  episode_reward_mean: 2.7690745081999153\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 170\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.609619140625\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00966560747474432\n",
      "        model: {}\n",
      "        policy_loss: -0.206861212849617\n",
      "        total_loss: -0.1652073711156845\n",
      "        vf_explained_var: 0.9881771206855774\n",
      "        vf_loss: 0.035129573196172714\n",
      "    num_steps_sampled: 17000\n",
      "    num_steps_trained: 17000\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.754999999999995\n",
      "    ram_util_percent: 68.67833333333333\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11801786014894912\n",
      "    mean_env_wait_ms: 404.39581905692626\n",
      "    mean_inference_ms: 1.0351983482758376\n",
      "    mean_raw_obs_processing_ms: 1.698016045788365\n",
      "  time_since_restore: 1409.2303285598755\n",
      "  time_this_iter_s: 38.497031927108765\n",
      "  time_total_s: 1409.2303285598755\n",
      "  timers:\n",
      "    learn_throughput: 1404.198\n",
      "    learn_time_ms: 356.075\n",
      "    load_throughput: 102015.45\n",
      "    load_time_ms: 4.901\n",
      "    sample_throughput: 12.989\n",
      "    sample_time_ms: 38493.253\n",
      "    update_time_ms: 2.942\n",
      "  timestamp: 1604404842\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17000\n",
      "  training_iteration: 34\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 13:00:46,228\tWARNING util.py:139 -- The `process_trial` operation took 3.6002821922302246 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 13:00:46,966\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7369849681854248 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         1409.23</td><td style=\"text-align: right;\">17000</td><td style=\"text-align: right;\"> 2.76907</td><td style=\"text-align: right;\">              7.1043</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:01:03,777\tINFO sampler.py:800 -- Preprocessed obs: np.ndarray((389,), dtype=float64, min=7.1, max=2446.01, mean=118.404)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:01:03,777\tINFO sampler.py:805 -- Filtered obs: np.ndarray((389,), dtype=float64, min=7.1, max=2446.01, mean=118.404)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:01:03,777\tINFO sampler.py:1223 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'info': {},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'obs': np.ndarray((389,), dtype=float64, min=7.1, max=2446.01, mean=118.404),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_action': np.ndarray((389,), dtype=float32, min=-2.64, max=2.896, mean=0.066),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_reward': 0.08175873116548382,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:01:03,778\tINFO tf_run_builder.py:87 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:01:03,779\tINFO sampler.py:1269 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': ( np.ndarray((1, 389), dtype=float32, min=-2.775, max=2.738, mean=-0.016),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       { 'action_dist_inputs': np.ndarray((1, 778), dtype=float32, min=-0.057, max=0.057, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-560.627, max=-560.627, mean=-560.627),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=3.876, max=3.876, mean=3.876)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:01:04,157\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=7.1, max=2446.01, mean=118.275)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:01:04,157\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:01:23,326\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.239, max=0.301, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-606.652, max=-505.607, mean=-552.045),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.142, max=3.833, mean=0.004),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-0.819, max=1.744, mean=-0.119),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=770349637.0, max=770349637.0, mean=770349637.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4849.152, mean=124.308),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.896),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.142, max=3.833, mean=0.004),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.181, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.181, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=34.0, max=34.0, mean=34.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.013, max=4.363, mean=2.601),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=0.042, max=4.735, mean=2.72)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:01:23,494\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.239, max=0.301, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-606.652, max=-505.607, mean=-552.045),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.142, max=3.833, mean=0.004),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-0.819, max=1.744, mean=-0.119),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=770349637.0, max=770349637.0, mean=770349637.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4849.152, mean=124.308),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.896),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.142, max=3.833, mean=0.004),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.181, mean=0.067),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.181, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=34.0, max=34.0, mean=34.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.013, max=4.363, mean=2.601),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=0.042, max=4.735, mean=2.72)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,335\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,346\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.076894306, 'policy_loss': -0.015047112, 'vf_loss': 0.09094115, 'vf_explained_var': 0.9664123, 'kl': 0.0014818726, 'entropy': 552.6391, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,357\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.04350172, 'policy_loss': -0.13635737, 'vf_loss': 0.08563741, 'vf_explained_var': 0.96827054, 'kl': 0.010693676, 'entropy': 552.6075, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,368\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10320424, 'policy_loss': -0.19455689, 'vf_loss': 0.07756736, 'vf_explained_var': 0.9713435, 'kl': 0.020422662, 'entropy': 552.6107, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,379\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.113357045, 'policy_loss': -0.20685233, 'vf_loss': 0.07679698, 'vf_explained_var': 0.9715231, 'kl': 0.024738232, 'entropy': 552.70874, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,390\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11722231, 'policy_loss': -0.21035723, 'vf_loss': 0.0736661, 'vf_explained_var': 0.9730719, 'kl': 0.028842688, 'entropy': 552.73553, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,402\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12078091, 'policy_loss': -0.21266699, 'vf_loss': 0.07216213, 'vf_explained_var': 0.9735897, 'kl': 0.029220656, 'entropy': 552.6605, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,412\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12549973, 'policy_loss': -0.21419375, 'vf_loss': 0.06911736, 'vf_explained_var': 0.97479814, 'kl': 0.02900247, 'entropy': 552.5695, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,424\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.124766104, 'policy_loss': -0.21455137, 'vf_loss': 0.07047159, 'vf_explained_var': 0.97398263, 'kl': 0.028612845, 'entropy': 552.51685, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,435\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12911896, 'policy_loss': -0.21490933, 'vf_loss': 0.0669942, 'vf_explained_var': 0.9753023, 'kl': 0.027846182, 'entropy': 552.5023, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,447\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13050866, 'policy_loss': -0.21490586, 'vf_loss': 0.06594422, 'vf_explained_var': 0.97575134, 'kl': 0.027337745, 'entropy': 552.5164, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,459\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13199344, 'policy_loss': -0.21504538, 'vf_loss': 0.06518392, 'vf_explained_var': 0.9760849, 'kl': 0.026471118, 'entropy': 552.5446, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,472\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13552995, 'policy_loss': -0.2152514, 'vf_loss': 0.06271093, 'vf_explained_var': 0.9771429, 'kl': 0.025200754, 'entropy': 552.58203, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,484\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13687484, 'policy_loss': -0.21527024, 'vf_loss': 0.06194601, 'vf_explained_var': 0.97731894, 'kl': 0.024369454, 'entropy': 552.616, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,498\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13980132, 'policy_loss': -0.21531196, 'vf_loss': 0.059902083, 'vf_explained_var': 0.97800785, 'kl': 0.023123791, 'entropy': 552.63983, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,512\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14036012, 'policy_loss': -0.21541522, 'vf_loss': 0.060598437, 'vf_explained_var': 0.97787005, 'kl': 0.02141731, 'entropy': 552.64813, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,527\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14324993, 'policy_loss': -0.21543543, 'vf_loss': 0.058630228, 'vf_explained_var': 0.97848606, 'kl': 0.020081878, 'entropy': 552.64166, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,541\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1444838, 'policy_loss': -0.21539615, 'vf_loss': 0.05783562, 'vf_explained_var': 0.9788467, 'kl': 0.01937292, 'entropy': 552.6244, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,554\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1525501, 'policy_loss': -0.21550453, 'vf_loss': 0.05050991, 'vf_explained_var': 0.9813273, 'kl': 0.01843634, 'entropy': 552.61084, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,567\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15339187, 'policy_loss': -0.21554387, 'vf_loss': 0.050293654, 'vf_explained_var': 0.98157406, 'kl': 0.017567901, 'entropy': 552.60736, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,585\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15274622, 'policy_loss': -0.2155792, 'vf_loss': 0.05153398, 'vf_explained_var': 0.9810954, 'kl': 0.016739286, 'entropy': 552.6104, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,603\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14881247, 'policy_loss': -0.21559095, 'vf_loss': 0.056047153, 'vf_explained_var': 0.97930115, 'kl': 0.015898256, 'entropy': 552.6107, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,618\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15416329, 'policy_loss': -0.21555217, 'vf_loss': 0.051249232, 'vf_explained_var': 0.98125654, 'kl': 0.015021701, 'entropy': 552.60693, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,634\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15420431, 'policy_loss': -0.21559101, 'vf_loss': 0.05168466, 'vf_explained_var': 0.9810877, 'kl': 0.014373377, 'entropy': 552.6014, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,649\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14572553, 'policy_loss': -0.21558817, 'vf_loss': 0.060484543, 'vf_explained_var': 0.9778984, 'kl': 0.013893445, 'entropy': 552.6007, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,664\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14761469, 'policy_loss': -0.21558988, 'vf_loss': 0.058989972, 'vf_explained_var': 0.9783904, 'kl': 0.013311413, 'entropy': 552.6076, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,679\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14739203, 'policy_loss': -0.2155927, 'vf_loss': 0.05959628, 'vf_explained_var': 0.9783489, 'kl': 0.012747246, 'entropy': 552.6181, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,693\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14797892, 'policy_loss': -0.21560387, 'vf_loss': 0.059358474, 'vf_explained_var': 0.97816116, 'kl': 0.012246616, 'entropy': 552.6264, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,705\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1479783, 'policy_loss': -0.21555483, 'vf_loss': 0.059605967, 'vf_explained_var': 0.97806233, 'kl': 0.011808253, 'entropy': 552.6258, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,719\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1490592, 'policy_loss': -0.21558143, 'vf_loss': 0.05853337, 'vf_explained_var': 0.9786253, 'kl': 0.011835348, 'entropy': 552.6185, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:01:24,733\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1497739, 'policy_loss': -0.21553332, 'vf_loss': 0.057681326, 'vf_explained_var': 0.9788838, 'kl': 0.011967535, 'entropy': 552.61896, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_13-01-24\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.104304871784551\n",
      "  episode_reward_mean: 2.7734479658973754\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 175\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6189575195312\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011967535130679607\n",
      "        model: {}\n",
      "        policy_loss: -0.2155333161354065\n",
      "        total_loss: -0.14977389574050903\n",
      "        vf_explained_var: 0.9788838028907776\n",
      "        vf_loss: 0.05768132582306862\n",
      "    num_steps_sampled: 17500\n",
      "    num_steps_trained: 17500\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.41967213114754\n",
      "    ram_util_percent: 69.70819672131148\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11766139999665531\n",
      "    mean_env_wait_ms: 403.1420105498959\n",
      "    mean_inference_ms: 1.031554694874543\n",
      "    mean_raw_obs_processing_ms: 1.6939829872795853\n",
      "  time_since_restore: 1447.7677426338196\n",
      "  time_this_iter_s: 38.53741407394409\n",
      "  time_total_s: 1447.7677426338196\n",
      "  timers:\n",
      "    learn_throughput: 1393.68\n",
      "    learn_time_ms: 358.762\n",
      "    load_throughput: 172269.072\n",
      "    load_time_ms: 2.902\n",
      "    sample_throughput: 13.101\n",
      "    sample_time_ms: 38165.726\n",
      "    update_time_ms: 2.507\n",
      "  timestamp: 1604404884\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17500\n",
      "  training_iteration: 35\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 13:01:29,775\tWARNING util.py:139 -- The `process_trial` operation took 4.135854005813599 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:01:29,748\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 13:01:30,823\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 1.0467100143432617 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         1447.77</td><td style=\"text-align: right;\">17500</td><td style=\"text-align: right;\"> 2.77345</td><td style=\"text-align: right;\">              7.1043</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:14,946\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-4.264, max=4.272, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.056, max=0.179, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.032),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.215, max=0.299, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-591.818, max=-510.195, mean=-554.048),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.264, max=4.272, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-11.039, max=7.257, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.032),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.264, max=4.272, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.056, max=0.179, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.382, max=4.293, mean=0.788),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.406, max=4.621, mean=0.786)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:14,947\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:14,949\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:14,962\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.014571701, 'policy_loss': -0.04406509, 'vf_loss': 0.05720292, 'vf_explained_var': 0.97915864, 'kl': 0.0021242534, 'entropy': 552.62164, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:14,974\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10362216, 'policy_loss': -0.16022661, 'vf_loss': 0.04728636, 'vf_explained_var': 0.9828182, 'kl': 0.013804617, 'entropy': 552.58344, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:14,986\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13425983, 'policy_loss': -0.1995302, 'vf_loss': 0.047576774, 'vf_explained_var': 0.98311526, 'kl': 0.02621276, 'entropy': 552.5522, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:14,999\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14613385, 'policy_loss': -0.21139888, 'vf_loss': 0.04591791, 'vf_explained_var': 0.984111, 'kl': 0.028662393, 'entropy': 552.57007, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,011\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1525843, 'policy_loss': -0.21566616, 'vf_loss': 0.04402994, 'vf_explained_var': 0.98452085, 'kl': 0.028225062, 'entropy': 552.61035, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,025\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15821192, 'policy_loss': -0.21733622, 'vf_loss': 0.04121585, 'vf_explained_var': 0.98561645, 'kl': 0.026531048, 'entropy': 552.65656, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,037\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15835977, 'policy_loss': -0.21788551, 'vf_loss': 0.042032663, 'vf_explained_var': 0.98493093, 'kl': 0.025915647, 'entropy': 552.68207, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,050\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16465682, 'policy_loss': -0.21893476, 'vf_loss': 0.037258867, 'vf_explained_var': 0.986602, 'kl': 0.025213419, 'entropy': 552.6821, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,062\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16570343, 'policy_loss': -0.2193764, 'vf_loss': 0.037279334, 'vf_explained_var': 0.98635626, 'kl': 0.024286859, 'entropy': 552.6723, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,080\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16907804, 'policy_loss': -0.21941149, 'vf_loss': 0.034512617, 'vf_explained_var': 0.98762065, 'kl': 0.023438292, 'entropy': 552.6688, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,091\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1679043, 'policy_loss': -0.2195812, 'vf_loss': 0.036548346, 'vf_explained_var': 0.98697704, 'kl': 0.02241269, 'entropy': 552.6713, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,103\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17044973, 'policy_loss': -0.21970117, 'vf_loss': 0.034784976, 'vf_explained_var': 0.9872365, 'kl': 0.021431804, 'entropy': 552.67816, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,114\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17264791, 'policy_loss': -0.21988447, 'vf_loss': 0.033619802, 'vf_explained_var': 0.9877879, 'kl': 0.020172924, 'entropy': 552.6883, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,125\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17433067, 'policy_loss': -0.21999176, 'vf_loss': 0.032881316, 'vf_explained_var': 0.9881373, 'kl': 0.01893296, 'entropy': 552.68915, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,137\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17621128, 'policy_loss': -0.22007458, 'vf_loss': 0.031815335, 'vf_explained_var': 0.9884946, 'kl': 0.017848814, 'entropy': 552.67816, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,149\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17734806, 'policy_loss': -0.22012848, 'vf_loss': 0.03148834, 'vf_explained_var': 0.98863524, 'kl': 0.016729018, 'entropy': 552.6642, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,161\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17830896, 'policy_loss': -0.22016068, 'vf_loss': 0.031133631, 'vf_explained_var': 0.98869497, 'kl': 0.015878608, 'entropy': 552.6573, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,173\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.17900765, 'policy_loss': -0.22016855, 'vf_loss': 0.031017689, 'vf_explained_var': 0.98860043, 'kl': 0.015026961, 'entropy': 552.6567, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,185\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18087254, 'policy_loss': -0.22017121, 'vf_loss': 0.029743187, 'vf_explained_var': 0.98912007, 'kl': 0.014156268, 'entropy': 552.6593, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,198\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18213242, 'policy_loss': -0.22020797, 'vf_loss': 0.029048303, 'vf_explained_var': 0.9894884, 'kl': 0.013373676, 'entropy': 552.6617, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,211\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18260019, 'policy_loss': -0.22020239, 'vf_loss': 0.029028771, 'vf_explained_var': 0.98955035, 'kl': 0.012701371, 'entropy': 552.6584, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,224\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18408598, 'policy_loss': -0.2201634, 'vf_loss': 0.027968414, 'vf_explained_var': 0.98986155, 'kl': 0.012013339, 'entropy': 552.65826, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,236\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18507999, 'policy_loss': -0.22019999, 'vf_loss': 0.027394915, 'vf_explained_var': 0.99002904, 'kl': 0.011444527, 'entropy': 552.6601, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,250\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18482177, 'policy_loss': -0.22020854, 'vf_loss': 0.027893422, 'vf_explained_var': 0.98980594, 'kl': 0.011101294, 'entropy': 552.663, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,263\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18577649, 'policy_loss': -0.22023706, 'vf_loss': 0.027304687, 'vf_explained_var': 0.9901112, 'kl': 0.0106012905, 'entropy': 552.6606, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,276\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18609162, 'policy_loss': -0.22018845, 'vf_loss': 0.02721841, 'vf_explained_var': 0.99016994, 'kl': 0.010190259, 'entropy': 552.6518, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,289\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18562786, 'policy_loss': -0.22025843, 'vf_loss': 0.028079031, 'vf_explained_var': 0.9898724, 'kl': 0.009705984, 'entropy': 552.64246, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,302\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18636005, 'policy_loss': -0.22025639, 'vf_loss': 0.02758354, 'vf_explained_var': 0.99003774, 'kl': 0.009352276, 'entropy': 552.6372, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,315\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1862802, 'policy_loss': -0.22026338, 'vf_loss': 0.027906248, 'vf_explained_var': 0.9898388, 'kl': 0.009002854, 'entropy': 552.63477, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:15,328\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.18819185, 'policy_loss': -0.22000806, 'vf_loss': 0.02600587, 'vf_explained_var': 0.9905427, 'kl': 0.008607898, 'entropy': 552.6387, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_13-02-15\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.104304871784551\n",
      "  episode_reward_mean: 2.7685754504131825\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 180\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.638671875\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008607897907495499\n",
      "        model: {}\n",
      "        policy_loss: -0.22000806033611298\n",
      "        total_loss: -0.18819184601306915\n",
      "        vf_explained_var: 0.9905427098274231\n",
      "        vf_loss: 0.02600586973130703\n",
      "    num_steps_sampled: 18000\n",
      "    num_steps_trained: 18000\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.00704225352113\n",
      "    ram_util_percent: 75.15211267605635\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1173769201177166\n",
      "    mean_env_wait_ms: 402.1555580932189\n",
      "    mean_inference_ms: 1.028618778432108\n",
      "    mean_raw_obs_processing_ms: 1.690220159075155\n",
      "  time_since_restore: 1493.3616955280304\n",
      "  time_this_iter_s: 45.593952894210815\n",
      "  time_total_s: 1493.3616955280304\n",
      "  timers:\n",
      "    learn_throughput: 1377.069\n",
      "    learn_time_ms: 363.09\n",
      "    load_throughput: 139293.818\n",
      "    load_time_ms: 3.59\n",
      "    sample_throughput: 12.866\n",
      "    sample_time_ms: 38861.721\n",
      "    update_time_ms: 2.614\n",
      "  timestamp: 1604404935\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 18000\n",
      "  training_iteration: 36\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 13:02:20,354\tWARNING util.py:139 -- The `process_trial` operation took 4.069758892059326 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 13:02:21,397\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 1.0415680408477783 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 8.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         1493.36</td><td style=\"text-align: right;\">18000</td><td style=\"text-align: right;\"> 2.76858</td><td style=\"text-align: right;\">              7.1043</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-564.248, max=-564.248, mean=-564.248),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=3.79, max=3.79, mean=3.79)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:02:30,253\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=8.58, max=2315.05, mean=125.348)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:02:30,253\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:02:57,236\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.216, max=0.288, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-582.745, max=-523.22, mean=-554.034),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.24, max=3.869, mean=0.009),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-0.432, max=1.578, mean=0.14),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=558207987.0, max=558207987.0, mean=558207987.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4580.023, mean=124.677),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.345),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.24, max=3.869, mean=0.009),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.181, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.181, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=36.0, max=36.0, mean=36.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.016, max=4.473, mean=2.659),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=-0.158, max=4.468, mean=2.519)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:02:57,372\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.216, max=0.288, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-582.745, max=-523.22, mean=-554.034),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.24, max=3.869, mean=0.009),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-0.432, max=1.578, mean=0.14),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=558207987.0, max=558207987.0, mean=558207987.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4580.023, mean=124.677),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.345),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.24, max=3.869, mean=0.009),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.181, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.181, mean=0.069),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=36.0, max=36.0, mean=36.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.016, max=4.473, mean=2.659),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=-0.158, max=4.468, mean=2.519)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,963\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,963\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,964\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,964\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,964\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,964\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,964\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,964\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,964\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,964\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,964\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,964\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,966\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,983\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.100455195, 'policy_loss': 0.010241221, 'vf_loss': 0.08949081, 'vf_explained_var': 0.9690416, 'kl': 0.0010713316, 'entropy': 552.6568, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:57,996\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.014778326, 'policy_loss': -0.105219126, 'vf_loss': 0.08223277, 'vf_explained_var': 0.9708769, 'kl': 0.012160029, 'entropy': 552.68945, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,008\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.056608584, 'policy_loss': -0.14939149, 'vf_loss': 0.076368235, 'vf_explained_var': 0.97281855, 'kl': 0.024318026, 'entropy': 552.69135, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,020\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06792429, 'policy_loss': -0.16215952, 'vf_loss': 0.073378146, 'vf_explained_var': 0.97387916, 'kl': 0.03089939, 'entropy': 552.65106, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,031\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07795081, 'policy_loss': -0.16924012, 'vf_loss': 0.069711186, 'vf_explained_var': 0.9751696, 'kl': 0.031967554, 'entropy': 552.66064, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,042\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.083425075, 'policy_loss': -0.17226852, 'vf_loss': 0.06707358, 'vf_explained_var': 0.9759477, 'kl': 0.03225166, 'entropy': 552.6608, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,053\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08495275, 'policy_loss': -0.17345072, 'vf_loss': 0.0666761, 'vf_explained_var': 0.9763015, 'kl': 0.032328695, 'entropy': 552.6209, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,064\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09102618, 'policy_loss': -0.17471008, 'vf_loss': 0.061998814, 'vf_explained_var': 0.9778905, 'kl': 0.032126043, 'entropy': 552.55475, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,077\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09228173, 'policy_loss': -0.17533545, 'vf_loss': 0.061763633, 'vf_explained_var': 0.97812766, 'kl': 0.031540856, 'entropy': 552.51575, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,089\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09569051, 'policy_loss': -0.17561483, 'vf_loss': 0.05964439, 'vf_explained_var': 0.9786243, 'kl': 0.03004436, 'entropy': 552.5253, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,100\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.099120565, 'policy_loss': -0.17572401, 'vf_loss': 0.057376157, 'vf_explained_var': 0.9795185, 'kl': 0.028484887, 'entropy': 552.5549, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,111\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09993494, 'policy_loss': -0.17581446, 'vf_loss': 0.05739135, 'vf_explained_var': 0.97952604, 'kl': 0.027389906, 'entropy': 552.5756, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,123\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1033991, 'policy_loss': -0.17582686, 'vf_loss': 0.055292744, 'vf_explained_var': 0.98017526, 'kl': 0.025385207, 'entropy': 552.5769, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,135\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.104815274, 'policy_loss': -0.17583795, 'vf_loss': 0.055049602, 'vf_explained_var': 0.9802323, 'kl': 0.023663824, 'entropy': 552.5693, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,146\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10528084, 'policy_loss': -0.1758076, 'vf_loss': 0.055423167, 'vf_explained_var': 0.98021436, 'kl': 0.02237573, 'entropy': 552.56793, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,157\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10780847, 'policy_loss': -0.17581443, 'vf_loss': 0.053525776, 'vf_explained_var': 0.98082525, 'kl': 0.021452151, 'entropy': 552.5768, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,168\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11001486, 'policy_loss': -0.17590107, 'vf_loss': 0.05222358, 'vf_explained_var': 0.98136806, 'kl': 0.0202409, 'entropy': 552.58954, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,179\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.111774854, 'policy_loss': -0.17593355, 'vf_loss': 0.051361363, 'vf_explained_var': 0.9815655, 'kl': 0.018959025, 'entropy': 552.59436, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,190\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1135071, 'policy_loss': -0.1759866, 'vf_loss': 0.050451715, 'vf_explained_var': 0.9818705, 'kl': 0.017818948, 'entropy': 552.5932, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,201\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11512339, 'policy_loss': -0.17592518, 'vf_loss': 0.04940793, 'vf_explained_var': 0.98237175, 'kl': 0.016879817, 'entropy': 552.594, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,213\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11680431, 'policy_loss': -0.17593487, 'vf_loss': 0.04836352, 'vf_explained_var': 0.98264426, 'kl': 0.015951153, 'entropy': 552.5971, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,226\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.116660394, 'policy_loss': -0.17593817, 'vf_loss': 0.049003597, 'vf_explained_var': 0.98247916, 'kl': 0.015220959, 'entropy': 552.6024, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,241\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11867276, 'policy_loss': -0.17592342, 'vf_loss': 0.04741239, 'vf_explained_var': 0.9830296, 'kl': 0.014575229, 'entropy': 552.6068, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,254\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11951816, 'policy_loss': -0.17597723, 'vf_loss': 0.047001217, 'vf_explained_var': 0.9832294, 'kl': 0.014011602, 'entropy': 552.6188, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,267\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.118946135, 'policy_loss': -0.17598699, 'vf_loss': 0.047947332, 'vf_explained_var': 0.9828086, 'kl': 0.013471889, 'entropy': 552.6276, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,280\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11940071, 'policy_loss': -0.17602451, 'vf_loss': 0.047851905, 'vf_explained_var': 0.98289967, 'kl': 0.012995395, 'entropy': 552.62775, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,292\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12058663, 'policy_loss': -0.17602713, 'vf_loss': 0.04699875, 'vf_explained_var': 0.98327523, 'kl': 0.012506291, 'entropy': 552.62683, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,304\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12106911, 'policy_loss': -0.1759646, 'vf_loss': 0.046696108, 'vf_explained_var': 0.9832721, 'kl': 0.012147219, 'entropy': 552.6269, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,315\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12220523, 'policy_loss': -0.17573668, 'vf_loss': 0.045419935, 'vf_explained_var': 0.98372215, 'kl': 0.012017056, 'entropy': 552.624, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:02:58,326\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.122656316, 'policy_loss': -0.1759487, 'vf_loss': 0.045405556, 'vf_explained_var': 0.98382664, 'kl': 0.011684214, 'entropy': 552.6267, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_13-02-58\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.104304871784551\n",
      "  episode_reward_mean: 2.769047959518598\n",
      "  episode_reward_min: -2.278187355476516\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 185\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.626708984375\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011684213764965534\n",
      "        model: {}\n",
      "        policy_loss: -0.17594869434833527\n",
      "        total_loss: -0.12265631556510925\n",
      "        vf_explained_var: 0.9838266372680664\n",
      "        vf_loss: 0.0454055555164814\n",
      "    num_steps_sampled: 18500\n",
      "    num_steps_trained: 18500\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.169999999999995\n",
      "    ram_util_percent: 52.64833333333333\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11708260171096278\n",
      "    mean_env_wait_ms: 401.1303769675643\n",
      "    mean_inference_ms: 1.0256769966271926\n",
      "    mean_raw_obs_processing_ms: 1.6856436766617002\n",
      "  time_since_restore: 1531.3663876056671\n",
      "  time_this_iter_s: 38.00469207763672\n",
      "  time_total_s: 1531.3663876056671\n",
      "  timers:\n",
      "    learn_throughput: 1373.168\n",
      "    learn_time_ms: 364.121\n",
      "    load_throughput: 145931.472\n",
      "    load_time_ms: 3.426\n",
      "    sample_throughput: 12.911\n",
      "    sample_time_ms: 38726.444\n",
      "    update_time_ms: 2.618\n",
      "  timestamp: 1604404978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 18500\n",
      "  training_iteration: 37\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 13:03:02,253\tWARNING util.py:139 -- The `process_trial` operation took 3.3079607486724854 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:03:02,235\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 13:03:02,960\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7056980133056641 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 8.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         1531.37</td><td style=\"text-align: right;\">18500</td><td style=\"text-align: right;\"> 2.76905</td><td style=\"text-align: right;\">              7.1043</td><td style=\"text-align: right;\">            -2.27819</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,238\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,250\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.08441689, 'policy_loss': 0.0025866728, 'vf_loss': 0.08085657, 'vf_explained_var': 0.97207516, 'kl': 0.0014424516, 'entropy': 552.60126, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,261\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.04556494, 'policy_loss': -0.12275485, 'vf_loss': 0.0694985, 'vf_explained_var': 0.9745547, 'kl': 0.011394683, 'entropy': 552.6802, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,271\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08339846, 'policy_loss': -0.1627164, 'vf_loss': 0.06351466, 'vf_explained_var': 0.9765933, 'kl': 0.02341226, 'entropy': 552.71826, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,281\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.091597535, 'policy_loss': -0.17531343, 'vf_loss': 0.06624942, 'vf_explained_var': 0.97597075, 'kl': 0.025876256, 'entropy': 552.6253, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,292\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.100606464, 'policy_loss': -0.18110813, 'vf_loss': 0.061230067, 'vf_explained_var': 0.9777384, 'kl': 0.02855052, 'entropy': 552.564, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,303\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10710108, 'policy_loss': -0.18404944, 'vf_loss': 0.05744755, 'vf_explained_var': 0.9791569, 'kl': 0.028890124, 'entropy': 552.5923, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,313\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11039781, 'policy_loss': -0.1849594, 'vf_loss': 0.053865165, 'vf_explained_var': 0.9802006, 'kl': 0.030661367, 'entropy': 552.63696, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,324\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.113030575, 'policy_loss': -0.18533818, 'vf_loss': 0.051971126, 'vf_explained_var': 0.9807093, 'kl': 0.030128144, 'entropy': 552.6455, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,334\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1131876, 'policy_loss': -0.18566348, 'vf_loss': 0.05334733, 'vf_explained_var': 0.9803178, 'kl': 0.028338611, 'entropy': 552.6367, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,345\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.117325366, 'policy_loss': -0.18594737, 'vf_loss': 0.049986776, 'vf_explained_var': 0.9815474, 'kl': 0.02760776, 'entropy': 552.6377, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,356\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11831274, 'policy_loss': -0.18599774, 'vf_loss': 0.049661964, 'vf_explained_var': 0.98159933, 'kl': 0.026700804, 'entropy': 552.65533, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,367\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12082585, 'policy_loss': -0.18615206, 'vf_loss': 0.04831646, 'vf_explained_var': 0.982152, 'kl': 0.02519965, 'entropy': 552.6673, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,378\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12080556, 'policy_loss': -0.1862092, 'vf_loss': 0.04911982, 'vf_explained_var': 0.98191595, 'kl': 0.024124207, 'entropy': 552.6613, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,389\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.123095505, 'policy_loss': -0.18618767, 'vf_loss': 0.047906518, 'vf_explained_var': 0.9824396, 'kl': 0.02249726, 'entropy': 552.63654, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,399\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12508816, 'policy_loss': -0.18619514, 'vf_loss': 0.046897423, 'vf_explained_var': 0.9826846, 'kl': 0.021051163, 'entropy': 552.6113, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,410\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12587418, 'policy_loss': -0.18628812, 'vf_loss': 0.046803582, 'vf_explained_var': 0.98285556, 'kl': 0.020163445, 'entropy': 552.60077, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,421\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12777446, 'policy_loss': -0.1863156, 'vf_loss': 0.045552906, 'vf_explained_var': 0.9831259, 'kl': 0.019241845, 'entropy': 552.6038, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,432\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12802492, 'policy_loss': -0.18634109, 'vf_loss': 0.0458765, 'vf_explained_var': 0.98312443, 'kl': 0.01842915, 'entropy': 552.611, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,443\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13006169, 'policy_loss': -0.18636139, 'vf_loss': 0.044447917, 'vf_explained_var': 0.9836445, 'kl': 0.017558223, 'entropy': 552.6129, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,454\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13012077, 'policy_loss': -0.18637651, 'vf_loss': 0.044939656, 'vf_explained_var': 0.9834259, 'kl': 0.01676455, 'entropy': 552.6125, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,467\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13104044, 'policy_loss': -0.18637057, 'vf_loss': 0.044463392, 'vf_explained_var': 0.98360825, 'kl': 0.016098864, 'entropy': 552.61316, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,479\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13174503, 'policy_loss': -0.18642025, 'vf_loss': 0.044249248, 'vf_explained_var': 0.98372525, 'kl': 0.015445859, 'entropy': 552.61993, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,490\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13252237, 'policy_loss': -0.18640709, 'vf_loss': 0.04390913, 'vf_explained_var': 0.9838743, 'kl': 0.014778633, 'entropy': 552.6268, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,502\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1334634, 'policy_loss': -0.18643801, 'vf_loss': 0.0434366, 'vf_explained_var': 0.98408335, 'kl': 0.014130361, 'entropy': 552.62787, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,515\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13381802, 'policy_loss': -0.1864541, 'vf_loss': 0.043675315, 'vf_explained_var': 0.98401165, 'kl': 0.013275221, 'entropy': 552.6224, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,525\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13486288, 'policy_loss': -0.1863934, 'vf_loss': 0.043058008, 'vf_explained_var': 0.9840897, 'kl': 0.012551834, 'entropy': 552.6163, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,537\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13603754, 'policy_loss': -0.18633516, 'vf_loss': 0.042319607, 'vf_explained_var': 0.9844265, 'kl': 0.011819261, 'entropy': 552.61456, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,549\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13691817, 'policy_loss': -0.1862572, 'vf_loss': 0.04182671, 'vf_explained_var': 0.9847095, 'kl': 0.011129372, 'entropy': 552.62085, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,561\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13762215, 'policy_loss': -0.18628456, 'vf_loss': 0.041569304, 'vf_explained_var': 0.9845969, 'kl': 0.010508315, 'entropy': 552.6385, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:03:38,572\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13774313, 'policy_loss': -0.18639098, 'vf_loss': 0.042013388, 'vf_explained_var': 0.98451847, 'kl': 0.009828825, 'entropy': 552.6507, 'entropy_coeff': 0.0, 'model': {}}\n",
      "2020-11-03 13:03:40,256\tWARNING util.py:139 -- The `fetch_result` operation took 0.8581409454345703 seconds to complete, which may be a performance bottleneck.\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_13-03-38\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.104304871784551\n",
      "  episode_reward_mean: 2.772344702403509\n",
      "  episode_reward_min: -2.1941117521451647\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 190\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6506958007812\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009828824549913406\n",
      "        model: {}\n",
      "        policy_loss: -0.1863909810781479\n",
      "        total_loss: -0.13774313032627106\n",
      "        vf_explained_var: 0.9845184683799744\n",
      "        vf_loss: 0.04201338812708855\n",
      "    num_steps_sampled: 19000\n",
      "    num_steps_trained: 19000\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.10877192982456\n",
      "    ram_util_percent: 55.11052631578947\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1168148974795177\n",
      "    mean_env_wait_ms: 400.1740601812011\n",
      "    mean_inference_ms: 1.0229996083672808\n",
      "    mean_raw_obs_processing_ms: 1.681512438389567\n",
      "  time_since_restore: 1567.7172055244446\n",
      "  time_this_iter_s: 36.350817918777466\n",
      "  time_total_s: 1567.7172055244446\n",
      "  timers:\n",
      "    learn_throughput: 1373.855\n",
      "    learn_time_ms: 363.939\n",
      "    load_throughput: 151625.829\n",
      "    load_time_ms: 3.298\n",
      "    sample_throughput: 12.995\n",
      "    sample_time_ms: 38477.529\n",
      "    update_time_ms: 2.398\n",
      "  timestamp: 1604405018\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19000\n",
      "  training_iteration: 38\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 13:03:43,236\tWARNING util.py:139 -- The `process_trial` operation took 3.8381941318511963 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 13:03:43,921\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.6843240261077881 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 9.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         1567.72</td><td style=\"text-align: right;\">19000</td><td style=\"text-align: right;\"> 2.77234</td><td style=\"text-align: right;\">              7.1043</td><td style=\"text-align: right;\">            -2.19411</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "action_logp': np.ndarray((100,), dtype=float32, min=-598.283, max=-515.793, mean=-550.224),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-5.246, max=4.567, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-0.556, max=3.006, mean=0.192),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=1758557346.0, max=1758557346.0, mean=1758557346.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4804.063, mean=124.889),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.557),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-5.246, max=4.567, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.185, mean=0.071),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.185, mean=0.071),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=38.0, max=38.0, mean=38.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.021, max=4.611, mean=2.761),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=-0.093, max=4.516, mean=2.57)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:04:18,652\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.229, max=0.283, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-598.283, max=-515.793, mean=-550.224),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-5.246, max=4.567, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-0.556, max=3.006, mean=0.192),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=1758557346.0, max=1758557346.0, mean=1758557346.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4804.063, mean=124.889),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=150.557),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-5.246, max=4.567, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.185, mean=0.071),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.185, mean=0.071),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=38.0, max=38.0, mean=38.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.021, max=4.611, mean=2.761),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=-0.093, max=4.516, mean=2.57)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,269\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-5.246, max=4.664, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.053, max=0.185, mean=0.029),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.269),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.229, max=0.283, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-608.674, max=-515.335, mean=-551.836),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-5.246, max=4.664, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-7.068, max=9.355, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=130.269),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-5.246, max=4.664, mean=-0.002),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.053, max=0.185, mean=0.029),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.25, max=4.611, mean=0.849),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.437, max=4.516, mean=0.818)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,270\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,270\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,282\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.10835397, 'policy_loss': 0.006551391, 'vf_loss': 0.100980334, 'vf_explained_var': 0.96560764, 'kl': 0.0012181596, 'entropy': 552.7102, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,293\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.037512764, 'policy_loss': -0.13316937, 'vf_loss': 0.08798387, 'vf_explained_var': 0.970042, 'kl': 0.011367013, 'entropy': 552.69794, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,305\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08423082, 'policy_loss': -0.18040879, 'vf_loss': 0.080910385, 'vf_explained_var': 0.97227865, 'kl': 0.022618642, 'entropy': 552.664, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,317\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10172629, 'policy_loss': -0.19504845, 'vf_loss': 0.074448556, 'vf_explained_var': 0.9745207, 'kl': 0.027960898, 'entropy': 552.6552, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,327\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.110808425, 'policy_loss': -0.19904828, 'vf_loss': 0.0680452, 'vf_explained_var': 0.9767101, 'kl': 0.029917978, 'entropy': 552.6465, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,338\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11803162, 'policy_loss': -0.20092435, 'vf_loss': 0.0631096, 'vf_explained_var': 0.9785573, 'kl': 0.029308341, 'entropy': 552.6152, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,350\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11954967, 'policy_loss': -0.20169155, 'vf_loss': 0.062165152, 'vf_explained_var': 0.9788132, 'kl': 0.02959515, 'entropy': 552.5811, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,361\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.123416506, 'policy_loss': -0.20243835, 'vf_loss': 0.05893078, 'vf_explained_var': 0.97977775, 'kl': 0.029764563, 'entropy': 552.5706, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,372\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12734194, 'policy_loss': -0.20273383, 'vf_loss': 0.055896062, 'vf_explained_var': 0.9808302, 'kl': 0.02888269, 'entropy': 552.58136, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,383\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13165888, 'policy_loss': -0.20293583, 'vf_loss': 0.052549627, 'vf_explained_var': 0.982065, 'kl': 0.02774421, 'entropy': 552.5869, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,394\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1341307, 'policy_loss': -0.20307918, 'vf_loss': 0.051001053, 'vf_explained_var': 0.98251754, 'kl': 0.026588783, 'entropy': 552.5881, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,406\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13677968, 'policy_loss': -0.20321773, 'vf_loss': 0.049283553, 'vf_explained_var': 0.9831982, 'kl': 0.02541407, 'entropy': 552.58435, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,418\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14002572, 'policy_loss': -0.20325927, 'vf_loss': 0.04681213, 'vf_explained_var': 0.9840024, 'kl': 0.02432806, 'entropy': 552.5868, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,430\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1416159, 'policy_loss': -0.20334667, 'vf_loss': 0.046312813, 'vf_explained_var': 0.9840634, 'kl': 0.022841422, 'entropy': 552.6015, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,441\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14237045, 'policy_loss': -0.20336199, 'vf_loss': 0.046612233, 'vf_explained_var': 0.98394054, 'kl': 0.021302687, 'entropy': 552.62616, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,453\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14536302, 'policy_loss': -0.20347218, 'vf_loss': 0.04453345, 'vf_explained_var': 0.9847422, 'kl': 0.020112144, 'entropy': 552.6457, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,465\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14661501, 'policy_loss': -0.20348889, 'vf_loss': 0.04392171, 'vf_explained_var': 0.98495024, 'kl': 0.019188378, 'entropy': 552.6565, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,477\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14879578, 'policy_loss': -0.20349742, 'vf_loss': 0.042339563, 'vf_explained_var': 0.9854586, 'kl': 0.018314166, 'entropy': 552.66156, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,490\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15135667, 'policy_loss': -0.20353442, 'vf_loss': 0.040542766, 'vf_explained_var': 0.98609066, 'kl': 0.017236995, 'entropy': 552.66864, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,504\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15172519, 'policy_loss': -0.20354195, 'vf_loss': 0.04099453, 'vf_explained_var': 0.98591703, 'kl': 0.016032958, 'entropy': 552.67413, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,518\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15352829, 'policy_loss': -0.20355807, 'vf_loss': 0.039850708, 'vf_explained_var': 0.9863878, 'kl': 0.015080075, 'entropy': 552.67487, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,531\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15535372, 'policy_loss': -0.20356782, 'vf_loss': 0.038527828, 'vf_explained_var': 0.98679113, 'kl': 0.014350045, 'entropy': 552.67334, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,543\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15613662, 'policy_loss': -0.20357342, 'vf_loss': 0.03823307, 'vf_explained_var': 0.98687506, 'kl': 0.013635154, 'entropy': 552.6724, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,561\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15691428, 'policy_loss': -0.20357956, 'vf_loss': 0.037931785, 'vf_explained_var': 0.9869426, 'kl': 0.01293847, 'entropy': 552.6742, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,581\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15812494, 'policy_loss': -0.20358121, 'vf_loss': 0.037128296, 'vf_explained_var': 0.9872516, 'kl': 0.012337753, 'entropy': 552.679, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,601\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1597204, 'policy_loss': -0.20358942, 'vf_loss': 0.035893884, 'vf_explained_var': 0.98768836, 'kl': 0.011815015, 'entropy': 552.6832, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,618\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1595579, 'policy_loss': -0.20357692, 'vf_loss': 0.036408093, 'vf_explained_var': 0.98751134, 'kl': 0.011275395, 'entropy': 552.6855, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,632\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16071868, 'policy_loss': -0.20356034, 'vf_loss': 0.035559375, 'vf_explained_var': 0.9877713, 'kl': 0.010788566, 'entropy': 552.69025, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,645\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16052954, 'policy_loss': -0.2035805, 'vf_loss': 0.03600779, 'vf_explained_var': 0.98763996, 'kl': 0.010434299, 'entropy': 552.6949, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:04:19,656\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.16157593, 'policy_loss': -0.20357037, 'vf_loss': 0.035203807, 'vf_explained_var': 0.9879703, 'kl': 0.010060225, 'entropy': 552.69116, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_13-04-19\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.149332531282339\n",
      "  episode_reward_mean: 2.768042835307459\n",
      "  episode_reward_min: -2.1941117521451647\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 195\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.691162109375\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010060224682092667\n",
      "        model: {}\n",
      "        policy_loss: -0.20357036590576172\n",
      "        total_loss: -0.16157592833042145\n",
      "        vf_explained_var: 0.9879702925682068\n",
      "        vf_loss: 0.035203807055950165\n",
      "    num_steps_sampled: 19500\n",
      "    num_steps_trained: 19500\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 35.1051724137931\n",
      "    ram_util_percent: 64.96034482758621\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11656243505295577\n",
      "    mean_env_wait_ms: 399.30682729926536\n",
      "    mean_inference_ms: 1.0205214065879336\n",
      "    mean_raw_obs_processing_ms: 1.6778958473747443\n",
      "  time_since_restore: 1604.1666858196259\n",
      "  time_this_iter_s: 36.449480295181274\n",
      "  time_total_s: 1604.1666858196259\n",
      "  timers:\n",
      "    learn_throughput: 1369.985\n",
      "    learn_time_ms: 364.968\n",
      "    load_throughput: 142586.773\n",
      "    load_time_ms: 3.507\n",
      "    sample_throughput: 13.094\n",
      "    sample_time_ms: 38186.432\n",
      "    update_time_ms: 2.403\n",
      "  timestamp: 1604405059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19500\n",
      "  training_iteration: 39\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 13:04:24,314\tWARNING util.py:139 -- The `process_trial` operation took 3.4048330783843994 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:04:24,293\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 13:04:25,088\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.773068904876709 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         1604.17</td><td style=\"text-align: right;\">19500</td><td style=\"text-align: right;\"> 2.76804</td><td style=\"text-align: right;\">             7.14933</td><td style=\"text-align: right;\">            -2.19411</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,594\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,595\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,595\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(389, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,595\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,595\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,595\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,595\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,595\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,595\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 778) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,595\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/fc_out/bias:0' shape=(778,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,595\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,595\tINFO tf_policy.py:622 -- Optimizing variable <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,597\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,609\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.122367404, 'policy_loss': 0.034751695, 'vf_loss': 0.086903654, 'vf_explained_var': 0.97189, 'kl': 0.0010548783, 'entropy': 552.7061, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,621\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.005832588, 'policy_loss': -0.091710955, 'vf_loss': 0.077445954, 'vf_explained_var': 0.97392756, 'kl': 0.012492464, 'entropy': 552.7381, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,632\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.030313134, 'policy_loss': -0.121134095, 'vf_loss': 0.07498318, 'vf_explained_var': 0.9748621, 'kl': 0.02346339, 'entropy': 552.7375, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,643\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.046176676, 'policy_loss': -0.1368036, 'vf_loss': 0.07351171, 'vf_explained_var': 0.975267, 'kl': 0.025355881, 'entropy': 552.7127, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,654\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.052122783, 'policy_loss': -0.14077425, 'vf_loss': 0.070918016, 'vf_explained_var': 0.9761165, 'kl': 0.026271803, 'entropy': 552.6835, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,665\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.053802636, 'policy_loss': -0.14298679, 'vf_loss': 0.07080043, 'vf_explained_var': 0.9762249, 'kl': 0.027235111, 'entropy': 552.6517, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,676\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.05371229, 'policy_loss': -0.14356701, 'vf_loss': 0.07116906, 'vf_explained_var': 0.9761462, 'kl': 0.027682438, 'entropy': 552.63153, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,687\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.055932578, 'policy_loss': -0.14411972, 'vf_loss': 0.06927406, 'vf_explained_var': 0.97670144, 'kl': 0.028019378, 'entropy': 552.622, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,698\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.054713145, 'policy_loss': -0.14447516, 'vf_loss': 0.07104129, 'vf_explained_var': 0.9761481, 'kl': 0.027734404, 'entropy': 552.62616, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,709\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.058924805, 'policy_loss': -0.14486939, 'vf_loss': 0.06818098, 'vf_explained_var': 0.9772441, 'kl': 0.026316464, 'entropy': 552.6352, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,720\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.05935519, 'policy_loss': -0.14495176, 'vf_loss': 0.068908356, 'vf_explained_var': 0.9769463, 'kl': 0.024723282, 'entropy': 552.6377, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,732\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06276578, 'policy_loss': -0.14504953, 'vf_loss': 0.06664928, 'vf_explained_var': 0.9776388, 'kl': 0.023162158, 'entropy': 552.6453, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,743\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06505932, 'policy_loss': -0.14523818, 'vf_loss': 0.06503571, 'vf_explained_var': 0.9782216, 'kl': 0.022434277, 'entropy': 552.6552, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,755\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.064017355, 'policy_loss': -0.14531286, 'vf_loss': 0.06665373, 'vf_explained_var': 0.977741, 'kl': 0.02169151, 'entropy': 552.6552, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,766\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.068059735, 'policy_loss': -0.14532046, 'vf_loss': 0.063447386, 'vf_explained_var': 0.97878677, 'kl': 0.020464225, 'entropy': 552.6447, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,779\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06884704, 'policy_loss': -0.14531292, 'vf_loss': 0.06329277, 'vf_explained_var': 0.97882944, 'kl': 0.019515716, 'entropy': 552.63574, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,790\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.071468405, 'policy_loss': -0.14534615, 'vf_loss': 0.061315846, 'vf_explained_var': 0.97951937, 'kl': 0.018610183, 'entropy': 552.638, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,802\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07284562, 'policy_loss': -0.14525126, 'vf_loss': 0.060448915, 'vf_explained_var': 0.97979516, 'kl': 0.017713672, 'entropy': 552.64703, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,813\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.074172966, 'policy_loss': -0.14535707, 'vf_loss': 0.059807062, 'vf_explained_var': 0.98004, 'kl': 0.01685487, 'entropy': 552.6513, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,825\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0817237, 'policy_loss': -0.14539373, 'vf_loss': 0.05277723, 'vf_explained_var': 0.9823722, 'kl': 0.016137483, 'entropy': 552.6544, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,836\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07321023, 'policy_loss': -0.14540344, 'vf_loss': 0.061777744, 'vf_explained_var': 0.9794887, 'kl': 0.015430301, 'entropy': 552.65936, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,849\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07449177, 'policy_loss': -0.14541064, 'vf_loss': 0.060976908, 'vf_explained_var': 0.97973245, 'kl': 0.014728828, 'entropy': 552.66644, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,862\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07709603, 'policy_loss': -0.1454091, 'vf_loss': 0.058772918, 'vf_explained_var': 0.98053545, 'kl': 0.014133577, 'entropy': 552.67194, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,875\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07727605, 'policy_loss': -0.14531954, 'vf_loss': 0.05889192, 'vf_explained_var': 0.9805231, 'kl': 0.013557881, 'entropy': 552.6733, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,889\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07772889, 'policy_loss': -0.14538392, 'vf_loss': 0.05878319, 'vf_explained_var': 0.9805196, 'kl': 0.01314348, 'entropy': 552.6721, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,901\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.078197666, 'policy_loss': -0.14538153, 'vf_loss': 0.058459144, 'vf_explained_var': 0.9806244, 'kl': 0.012925501, 'entropy': 552.6744, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,913\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07924528, 'policy_loss': -0.14543015, 'vf_loss': 0.05766179, 'vf_explained_var': 0.98083407, 'kl': 0.012626781, 'entropy': 552.6735, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,925\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07991805, 'policy_loss': -0.14540477, 'vf_loss': 0.05725855, 'vf_explained_var': 0.9809944, 'kl': 0.01218988, 'entropy': 552.66846, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,938\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.080120005, 'policy_loss': -0.14543831, 'vf_loss': 0.057339292, 'vf_explained_var': 0.9809484, 'kl': 0.011820779, 'entropy': 552.6681, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:04,950\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0806234, 'policy_loss': -0.14543688, 'vf_loss': 0.05704659, 'vf_explained_var': 0.9810591, 'kl': 0.011506513, 'entropy': 552.6716, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_13-05-04\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.149332531282339\n",
      "  episode_reward_mean: 2.761602532170424\n",
      "  episode_reward_min: -2.1941117521451647\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 200\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6715698242188\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011506512761116028\n",
      "        model: {}\n",
      "        policy_loss: -0.14543688297271729\n",
      "        total_loss: -0.08062340319156647\n",
      "        vf_explained_var: 0.9810590744018555\n",
      "        vf_loss: 0.05704658851027489\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.639062499999994\n",
      "    ram_util_percent: 60.89687500000001\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11633707395737536\n",
      "    mean_env_wait_ms: 398.54539233343417\n",
      "    mean_inference_ms: 1.01828726119398\n",
      "    mean_raw_obs_processing_ms: 1.6748392026913428\n",
      "  time_since_restore: 1644.8345310688019\n",
      "  time_this_iter_s: 40.667845249176025\n",
      "  time_total_s: 1644.8345310688019\n",
      "  timers:\n",
      "    learn_throughput: 1374.017\n",
      "    learn_time_ms: 363.897\n",
      "    load_throughput: 151178.777\n",
      "    load_time_ms: 3.307\n",
      "    sample_throughput: 13.004\n",
      "    sample_time_ms: 38448.986\n",
      "    update_time_ms: 2.419\n",
      "  timestamp: 1604405104\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 40\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 13:05:09,247\tWARNING util.py:139 -- The `process_trial` operation took 3.662106990814209 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 13:05:10,074\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.8264849185943604 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         1644.83</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">  2.7616</td><td style=\"text-align: right;\">             7.14933</td><td style=\"text-align: right;\">            -2.19411</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:05:24,437\tINFO sampler.py:800 -- Preprocessed obs: np.ndarray((389,), dtype=float64, min=7.5, max=4374.054, mean=132.413)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:05:24,437\tINFO sampler.py:805 -- Filtered obs: np.ndarray((389,), dtype=float64, min=7.5, max=4374.054, mean=132.413)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:05:24,438\tINFO sampler.py:1223 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'info': {},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'obs': np.ndarray((389,), dtype=float64, min=7.5, max=4374.054, mean=132.413),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_action': np.ndarray((389,), dtype=float32, min=-2.619, max=2.966, mean=0.026),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_reward': 0.050103056324159456,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:05:24,438\tINFO tf_run_builder.py:87 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:05:24,439\tINFO sampler.py:1269 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': ( np.ndarray((1, 389), dtype=float32, min=-3.417, max=2.881, mean=0.062),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       { 'action_dist_inputs': np.ndarray((1, 778), dtype=float32, min=-0.06, max=0.082, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-549.655, max=-549.655, mean=-549.655),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=3.941, max=3.941, mean=3.941)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:05:24,843\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=7.5, max=2450.0, mean=125.262)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:05:24,843\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:05:50,741\tINFO sample_batch_builder.py:211 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.258, max=0.285, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((100,), dtype=float32, min=-579.739, max=-517.785, mean=-552.294),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'actions': np.ndarray((100, 389), dtype=float32, min=-4.514, max=4.125, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'advantages': np.ndarray((100,), dtype=float32, min=-0.886, max=2.45, mean=-0.114),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'eps_id': np.ndarray((100,), dtype=int64, min=525598509.0, max=525598509.0, mean=525598509.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4527.066, mean=124.083),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.751),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.514, max=4.125, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.182, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.182, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'unroll_id': np.ndarray((100,), dtype=int64, min=40.0, max=40.0, mean=40.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'value_targets': np.ndarray((100,), dtype=float32, min=0.013, max=4.394, mean=2.617),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((100,), dtype=float32, min=-0.012, max=4.786, mean=2.731)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:05:50,920\tINFO rollout_worker.py:611 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((100, 778), dtype=float32, min=-0.258, max=0.285, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_logp': np.ndarray((100,), dtype=float32, min=-579.739, max=-517.785, mean=-552.294),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'action_prob': np.ndarray((100,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'actions': np.ndarray((100, 389), dtype=float32, min=-4.514, max=4.125, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'advantages': np.ndarray((100,), dtype=float32, min=-0.886, max=2.45, mean=-0.114),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=525598509.0, max=525598509.0, mean=525598509.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'new_obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=4527.066, mean=124.083),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'obs': np.ndarray((100, 389), dtype=float32, min=6.71, max=1000000.0, mean=149.751),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_actions': np.ndarray((100, 389), dtype=float32, min=-4.514, max=4.125, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.182, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=-0.0, max=0.182, mean=0.068),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=99.0, mean=49.5),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=40.0, max=40.0, mean=40.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'value_targets': np.ndarray((100,), dtype=float32, min=0.013, max=4.394, mean=2.617),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m             'vf_preds': np.ndarray((100,), dtype=float32, min=-0.012, max=4.786, mean=2.731)},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,614\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,636\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.05545872, 'policy_loss': -0.025937915, 'vf_loss': 0.07973308, 'vf_explained_var': 0.9719874, 'kl': 0.0024645242, 'entropy': 552.67053, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,648\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.05604041, 'policy_loss': -0.13939403, 'vf_loss': 0.07292428, 'vf_explained_var': 0.97440594, 'kl': 0.015450873, 'entropy': 552.70953, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,661\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11109754, 'policy_loss': -0.19435503, 'vf_loss': 0.06863574, 'vf_explained_var': 0.9761346, 'kl': 0.02166188, 'entropy': 552.6248, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,674\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12192913, 'policy_loss': -0.20741332, 'vf_loss': 0.06729313, 'vf_explained_var': 0.97660035, 'kl': 0.026949694, 'entropy': 552.571, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,766\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12583646, 'policy_loss': -0.21238859, 'vf_loss': 0.06677196, 'vf_explained_var': 0.976885, 'kl': 0.029303977, 'entropy': 552.585, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,779\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.12915821, 'policy_loss': -0.21383758, 'vf_loss': 0.0644864, 'vf_explained_var': 0.977613, 'kl': 0.029915566, 'entropy': 552.5661, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,792\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13160594, 'policy_loss': -0.2148052, 'vf_loss': 0.062822156, 'vf_explained_var': 0.9782612, 'kl': 0.030188335, 'entropy': 552.5321, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,804\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13410518, 'policy_loss': -0.2151577, 'vf_loss': 0.06110838, 'vf_explained_var': 0.9786816, 'kl': 0.029546881, 'entropy': 552.51984, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,817\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1358545, 'policy_loss': -0.2154292, 'vf_loss': 0.06036215, 'vf_explained_var': 0.9790049, 'kl': 0.028463056, 'entropy': 552.53564, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,830\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.13925137, 'policy_loss': -0.21565588, 'vf_loss': 0.058071937, 'vf_explained_var': 0.9797557, 'kl': 0.027159363, 'entropy': 552.5691, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,842\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14088334, 'policy_loss': -0.21556409, 'vf_loss': 0.057102267, 'vf_explained_var': 0.9801011, 'kl': 0.026042184, 'entropy': 552.5999, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,855\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14195602, 'policy_loss': -0.21594174, 'vf_loss': 0.05674478, 'vf_explained_var': 0.98007107, 'kl': 0.025542146, 'entropy': 552.63135, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,868\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14403182, 'policy_loss': -0.21606143, 'vf_loss': 0.05518918, 'vf_explained_var': 0.9807226, 'kl': 0.02494876, 'entropy': 552.642, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,882\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14362276, 'policy_loss': -0.2159419, 'vf_loss': 0.056263287, 'vf_explained_var': 0.9803998, 'kl': 0.023786455, 'entropy': 552.6323, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,894\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14465584, 'policy_loss': -0.21614413, 'vf_loss': 0.056199823, 'vf_explained_var': 0.98032874, 'kl': 0.022649555, 'entropy': 552.6203, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,906\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14659208, 'policy_loss': -0.21618676, 'vf_loss': 0.055059314, 'vf_explained_var': 0.9807258, 'kl': 0.021533912, 'entropy': 552.6067, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,919\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14810248, 'policy_loss': -0.21618794, 'vf_loss': 0.054263715, 'vf_explained_var': 0.98101, 'kl': 0.020476654, 'entropy': 552.59906, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,931\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.14904837, 'policy_loss': -0.21625648, 'vf_loss': 0.054216396, 'vf_explained_var': 0.9810541, 'kl': 0.019246958, 'entropy': 552.59155, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,943\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15070327, 'policy_loss': -0.21631293, 'vf_loss': 0.05341631, 'vf_explained_var': 0.9815073, 'kl': 0.018064247, 'entropy': 552.5888, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,955\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15185052, 'policy_loss': -0.21633784, 'vf_loss': 0.0530905, 'vf_explained_var': 0.9813948, 'kl': 0.01688419, 'entropy': 552.5959, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,970\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15327014, 'policy_loss': -0.21631128, 'vf_loss': 0.052504737, 'vf_explained_var': 0.98179954, 'kl': 0.015609491, 'entropy': 552.6076, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:51,986\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15404263, 'policy_loss': -0.21625511, 'vf_loss': 0.052260533, 'vf_explained_var': 0.9818657, 'kl': 0.014743614, 'entropy': 552.61633, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:52,002\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15527932, 'policy_loss': -0.21637522, 'vf_loss': 0.051672082, 'vf_explained_var': 0.98208976, 'kl': 0.013961202, 'entropy': 552.6205, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:52,017\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15572803, 'policy_loss': -0.21639235, 'vf_loss': 0.05174656, 'vf_explained_var': 0.98197347, 'kl': 0.0132115185, 'entropy': 552.6255, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:52,032\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15676303, 'policy_loss': -0.21640544, 'vf_loss': 0.051019847, 'vf_explained_var': 0.98220205, 'kl': 0.012774139, 'entropy': 552.6297, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:52,044\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15700422, 'policy_loss': -0.21641992, 'vf_loss': 0.05106568, 'vf_explained_var': 0.98219615, 'kl': 0.012370405, 'entropy': 552.6307, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:52,057\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15805684, 'policy_loss': -0.2164319, 'vf_loss': 0.050401982, 'vf_explained_var': 0.9824056, 'kl': 0.011811948, 'entropy': 552.6303, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:52,070\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15812723, 'policy_loss': -0.21643919, 'vf_loss': 0.05065001, 'vf_explained_var': 0.9823429, 'kl': 0.011351039, 'entropy': 552.6279, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:52,082\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.15832673, 'policy_loss': -0.21644317, 'vf_loss': 0.050776064, 'vf_explained_var': 0.9823046, 'kl': 0.010874641, 'entropy': 552.6274, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:05:52,096\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.159075, 'policy_loss': -0.21643777, 'vf_loss': 0.05029769, 'vf_explained_var': 0.98252565, 'kl': 0.0104668075, 'entropy': 552.6259, 'entropy_coeff': 0.0, 'model': {}}\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_13-05-52\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.149332531282339\n",
      "  episode_reward_mean: 2.76697474001275\n",
      "  episode_reward_min: -2.1941117521451647\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 205\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6259155273438\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010466807521879673\n",
      "        model: {}\n",
      "        policy_loss: -0.21643777191638947\n",
      "        total_loss: -0.15907500684261322\n",
      "        vf_explained_var: 0.982525646686554\n",
      "        vf_loss: 0.05029768869280815\n",
      "    num_steps_sampled: 20500\n",
      "    num_steps_trained: 20500\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.30746268656717\n",
      "    ram_util_percent: 69.20597014925374\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11614592496409745\n",
      "    mean_env_wait_ms: 397.87990153994156\n",
      "    mean_inference_ms: 1.0164017732016468\n",
      "    mean_raw_obs_processing_ms: 1.6723300227690583\n",
      "  time_since_restore: 1687.7309231758118\n",
      "  time_this_iter_s: 42.89639210700989\n",
      "  time_total_s: 1687.7309231758118\n",
      "  timers:\n",
      "    learn_throughput: 1323.666\n",
      "    learn_time_ms: 377.739\n",
      "    load_throughput: 113878.484\n",
      "    load_time_ms: 4.391\n",
      "    sample_throughput: 12.843\n",
      "    sample_time_ms: 38931.417\n",
      "    update_time_ms: 2.944\n",
      "  timestamp: 1604405152\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20500\n",
      "  training_iteration: 41\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 13:05:57,114\tWARNING util.py:139 -- The `process_trial` operation took 3.8982880115509033 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:05:57,092\tINFO rollout_worker.py:577 -- Generating sample batch of size 100\n",
      "2020-11-03 13:05:58,010\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.8945081233978271 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         1687.73</td><td style=\"text-align: right;\">20500</td><td style=\"text-align: right;\"> 2.76697</td><td style=\"text-align: right;\">             7.14933</td><td style=\"text-align: right;\">            -2.19411</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:39,914\tINFO multi_gpu_impl.py:143 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m { 'inputs': [ np.ndarray((500, 389), dtype=float32, min=-4.526, max=4.418, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.061, max=0.186, mean=0.029),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=129.845),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 778), dtype=float32, min=-0.264, max=0.237, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-603.086, max=-514.737, mean=-553.375),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.526, max=4.418, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-9.508, max=7.902, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=1.66, max=1000000.0, mean=129.845),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500, 389), dtype=float32, min=-4.526, max=4.418, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-0.061, max=0.186, mean=0.029),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.466, max=4.658, mean=0.844),\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m               np.ndarray((500,), dtype=float32, min=-1.494, max=4.523, mean=0.78)],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_dist_inputs:0' shape=(?, 778) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_action:0' shape=(?, 389) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:39,914\tINFO multi_gpu_impl.py:188 -- Divided 500 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:39,915\tDEBUG train_ops.py:201 -- == sgd epochs for default_policy ==\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:39,928\tDEBUG train_ops.py:213 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 0.14058082, 'policy_loss': 0.028537124, 'vf_loss': 0.11090604, 'vf_explained_var': 0.9635021, 'kl': 0.0016854139, 'entropy': 552.661, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:39,941\tDEBUG train_ops.py:213 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.0073366812, 'policy_loss': -0.10589536, 'vf_loss': 0.09155812, 'vf_explained_var': 0.9689837, 'kl': 0.010371215, 'entropy': 552.6701, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:39,953\tDEBUG train_ops.py:213 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.05671982, 'policy_loss': -0.15934815, 'vf_loss': 0.088772595, 'vf_explained_var': 0.969526, 'kl': 0.020527016, 'entropy': 552.75433, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:39,966\tDEBUG train_ops.py:213 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.06593293, 'policy_loss': -0.1698484, 'vf_loss': 0.08621151, 'vf_explained_var': 0.9703416, 'kl': 0.026228102, 'entropy': 552.84064, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:39,979\tDEBUG train_ops.py:213 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.076317854, 'policy_loss': -0.17534524, 'vf_loss': 0.07936346, 'vf_explained_var': 0.97268057, 'kl': 0.029131753, 'entropy': 552.8295, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:39,991\tDEBUG train_ops.py:213 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.07828649, 'policy_loss': -0.17751074, 'vf_loss': 0.07828482, 'vf_explained_var': 0.9733657, 'kl': 0.031021366, 'entropy': 552.7598, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,003\tDEBUG train_ops.py:213 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.078196935, 'policy_loss': -0.17855357, 'vf_loss': 0.07964819, 'vf_explained_var': 0.97308034, 'kl': 0.030679194, 'entropy': 552.71674, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,015\tDEBUG train_ops.py:213 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.083090715, 'policy_loss': -0.1788374, 'vf_loss': 0.075819544, 'vf_explained_var': 0.973926, 'kl': 0.029521668, 'entropy': 552.71173, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,028\tDEBUG train_ops.py:213 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08406764, 'policy_loss': -0.1795078, 'vf_loss': 0.07559482, 'vf_explained_var': 0.9741022, 'kl': 0.02940053, 'entropy': 552.6999, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,040\tDEBUG train_ops.py:213 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.08943308, 'policy_loss': -0.17973869, 'vf_loss': 0.07141123, 'vf_explained_var': 0.97539115, 'kl': 0.027991673, 'entropy': 552.68024, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,053\tDEBUG train_ops.py:213 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.092393376, 'policy_loss': -0.17984207, 'vf_loss': 0.069681235, 'vf_explained_var': 0.9761062, 'kl': 0.02632218, 'entropy': 552.6728, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,065\tDEBUG train_ops.py:213 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.09192119, 'policy_loss': -0.17990579, 'vf_loss': 0.07108838, 'vf_explained_var': 0.9755988, 'kl': 0.025031412, 'entropy': 552.67773, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,076\tDEBUG train_ops.py:213 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.095924765, 'policy_loss': -0.17999494, 'vf_loss': 0.068095624, 'vf_explained_var': 0.9765119, 'kl': 0.023665989, 'entropy': 552.6884, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,089\tDEBUG train_ops.py:213 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.095512085, 'policy_loss': -0.17999656, 'vf_loss': 0.06944778, 'vf_explained_var': 0.9760637, 'kl': 0.022276605, 'entropy': 552.6922, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,101\tDEBUG train_ops.py:213 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10000944, 'policy_loss': -0.18009764, 'vf_loss': 0.06595994, 'vf_explained_var': 0.9772007, 'kl': 0.020930761, 'entropy': 552.6906, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,113\tDEBUG train_ops.py:213 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10092121, 'policy_loss': -0.18014066, 'vf_loss': 0.06579228, 'vf_explained_var': 0.9772863, 'kl': 0.019892072, 'entropy': 552.691, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,126\tDEBUG train_ops.py:213 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.100418456, 'policy_loss': -0.1801691, 'vf_loss': 0.06702157, 'vf_explained_var': 0.97693366, 'kl': 0.018857902, 'entropy': 552.6995, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,139\tDEBUG train_ops.py:213 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1028982, 'policy_loss': -0.18018627, 'vf_loss': 0.0652635, 'vf_explained_var': 0.97745943, 'kl': 0.017814176, 'entropy': 552.7084, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,152\tDEBUG train_ops.py:213 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.103612125, 'policy_loss': -0.18020464, 'vf_loss': 0.065300286, 'vf_explained_var': 0.97741914, 'kl': 0.01672925, 'entropy': 552.70734, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,165\tDEBUG train_ops.py:213 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.106480084, 'policy_loss': -0.1802196, 'vf_loss': 0.06310207, 'vf_explained_var': 0.97814137, 'kl': 0.01575918, 'entropy': 552.6995, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,176\tDEBUG train_ops.py:213 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10750862, 'policy_loss': -0.18022041, 'vf_loss': 0.06262826, 'vf_explained_var': 0.9783065, 'kl': 0.014938552, 'entropy': 552.69305, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,190\tDEBUG train_ops.py:213 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10766391, 'policy_loss': -0.18021996, 'vf_loss': 0.06302318, 'vf_explained_var': 0.9782279, 'kl': 0.01412277, 'entropy': 552.69586, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,205\tDEBUG train_ops.py:213 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.10857291, 'policy_loss': -0.18023509, 'vf_loss': 0.062613465, 'vf_explained_var': 0.978317, 'kl': 0.013405503, 'entropy': 552.69434, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,223\tDEBUG train_ops.py:213 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.1099427, 'policy_loss': -0.18021655, 'vf_loss': 0.061614055, 'vf_explained_var': 0.97865754, 'kl': 0.012829322, 'entropy': 552.69366, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,239\tDEBUG train_ops.py:213 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.110800095, 'policy_loss': -0.18017991, 'vf_loss': 0.06109856, 'vf_explained_var': 0.9788098, 'kl': 0.012268529, 'entropy': 552.6935, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,254\tDEBUG train_ops.py:213 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11145238, 'policy_loss': -0.18023558, 'vf_loss': 0.060811374, 'vf_explained_var': 0.9788999, 'kl': 0.011810124, 'entropy': 552.6931, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,267\tDEBUG train_ops.py:213 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11219273, 'policy_loss': -0.1802562, 'vf_loss': 0.060386628, 'vf_explained_var': 0.97901994, 'kl': 0.011373104, 'entropy': 552.6956, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,281\tDEBUG train_ops.py:213 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.113164835, 'policy_loss': -0.18025811, 'vf_loss': 0.05970691, 'vf_explained_var': 0.97925586, 'kl': 0.010942777, 'entropy': 552.69586, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,297\tDEBUG train_ops.py:213 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11266837, 'policy_loss': -0.18026948, 'vf_loss': 0.06049356, 'vf_explained_var': 0.97897035, 'kl': 0.010529704, 'entropy': 552.69385, 'entropy_coeff': 0.0, 'model': {}}\n",
      "\u001b[2m\u001b[36m(pid=29360)\u001b[0m 2020-11-03 13:06:40,312\tDEBUG train_ops.py:213 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': -0.11318923, 'policy_loss': -0.18022203, 'vf_loss': 0.060195897, 'vf_explained_var': 0.97910863, 'kl': 0.01012875, 'entropy': 552.69, 'entropy_coeff': 0.0, 'model': {}}\n",
      "2020-11-03 13:06:42,136\tWARNING util.py:139 -- The `fetch_result` operation took 0.9033200740814209 seconds to complete, which may be a performance bottleneck.\n",
      "Result for PPO_TradingEnv_82736_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_13-06-40\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 7.255894858585511\n",
      "  episode_reward_mean: 2.7702858145889615\n",
      "  episode_reward_min: -2.1941117521451647\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 210\n",
      "  experiment_id: bebcb644bcdd4399926383db021c2428\n",
      "  experiment_tag: '0'\n",
      "  hostname: Pavols-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 552.6900024414062\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010128749534487724\n",
      "        model: {}\n",
      "        policy_loss: -0.1802220344543457\n",
      "        total_loss: -0.1131892278790474\n",
      "        vf_explained_var: 0.9791086316108704\n",
      "        vf_loss: 0.06019589677453041\n",
      "    num_steps_sampled: 21000\n",
      "    num_steps_trained: 21000\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.0.100\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.51194029850747\n",
      "    ram_util_percent: 67.76268656716417\n",
      "  pid: 29360\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11598107598783935\n",
      "    mean_env_wait_ms: 397.314643765674\n",
      "    mean_inference_ms: 1.0148006632728233\n",
      "    mean_raw_obs_processing_ms: 1.6703943228878242\n",
      "  time_since_restore: 1730.964891910553\n",
      "  time_this_iter_s: 43.23396873474121\n",
      "  time_total_s: 1730.964891910553\n",
      "  timers:\n",
      "    learn_throughput: 1304.748\n",
      "    learn_time_ms: 383.216\n",
      "    load_throughput: 105685.114\n",
      "    load_time_ms: 4.731\n",
      "    sample_throughput: 12.706\n",
      "    sample_time_ms: 39351.946\n",
      "    update_time_ms: 3.069\n",
      "  timestamp: 1604405200\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 21000\n",
      "  training_iteration: 42\n",
      "  trial_id: '82736_00000'\n",
      "  \n",
      "2020-11-03 13:06:45,582\tWARNING util.py:139 -- The `process_trial` operation took 4.348597049713135 seconds to complete, which may be a performance bottleneck.\n",
      "2020-11-03 13:06:46,358\tWARNING util.py:139 -- The `experiment_checkpoint` operation took 0.7760128974914551 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 9.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6/16 CPUs, 0/0 GPUs, 0.0/5.71 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: /Users/Palo/Documents/Programming/Quant/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_TradingEnv_82736_00000</td><td>RUNNING </td><td>192.168.0.100:29360</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         1730.96</td><td style=\"text-align: right;\">21000</td><td style=\"text-align: right;\"> 2.77029</td><td style=\"text-align: right;\">             7.25589</td><td style=\"text-align: right;\">            -2.19411</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:06:57,094\tINFO sampler.py:800 -- Preprocessed obs: np.ndarray((389,), dtype=float64, min=8.02, max=2401.28, mean=124.043)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:06:57,095\tINFO sampler.py:805 -- Filtered obs: np.ndarray((389,), dtype=float64, min=8.02, max=2401.28, mean=124.043)\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:06:57,095\tINFO sampler.py:1223 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'info': {},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'obs': np.ndarray((389,), dtype=float64, min=8.02, max=2401.28, mean=124.043),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_action': np.ndarray((389,), dtype=float32, min=-3.056, max=2.895, mean=-0.063),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'prev_reward': 0.07229796272835198,\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:06:57,095\tINFO tf_run_builder.py:87 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:06:57,097\tINFO sampler.py:1269 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m { 'default_policy': ( np.ndarray((1, 389), dtype=float32, min=-2.736, max=4.474, mean=-0.083),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                       { 'action_dist_inputs': np.ndarray((1, 778), dtype=float32, min=-0.063, max=0.064, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-520.767, max=-520.767, mean=-520.767),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=4.224, max=4.224, mean=4.224)})}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:06:57,551\tINFO sampler.py:553 -- Raw obs from env: { 0: { 'agent0': np.ndarray((389,), dtype=float64, min=8.02, max=2401.28, mean=124.245)}}\n",
      "\u001b[2m\u001b[36m(pid=29361)\u001b[0m 2020-11-03 13:06:57,552\tINFO sampler.py:554 -- Info return from env: {0: {'agent0': {}}}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-19894637945e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#trainer = ppo.PPOTrainer(config=config, env=TradingEnv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPPOTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"training_iteration\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ray_results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \"\"\"\n",
      "\u001b[0;32m~/anaconda3/envs/quant/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, loggers, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/quant/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/quant/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;31m# TODO(ujvl): Consider combining get_next_available_trial and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_restoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial_restore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/quant/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/quant/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout)\u001b[0m\n\u001b[1;32m   1556\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1558\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1559\u001b[0m         )\n\u001b[1;32m   1560\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ray.rllib.agents.ppo as ppo\n",
    "import ray.rllib.models.catalog as catalog\n",
    "import ray.tune as tune\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config[\"num_gpus\"] = 0\n",
    "config[\"num_workers\"] = 5\n",
    "config[\"rollout_fragment_length\"] = 100\n",
    "config[\"train_batch_size\"] = 500\n",
    "#config[\"framework\"] = \"torch\"\n",
    "config[\"env_config\"] = env_config\n",
    "config[\"log_level\"] = \"DEBUG\"\n",
    "config[\"env\"] = TradingEnv\n",
    "\n",
    "model_config = catalog.MODEL_DEFAULTS.copy()\n",
    "model_config[\"use_lstm\"] = True\n",
    "model_config[\"max_seq_len\"] = 100\n",
    "\n",
    "#trainer = ppo.PPOTrainer(config=config, env=TradingEnv)\n",
    "tune.run(ppo.PPOTrainer, stop={\"training_iteration\": 100}, config=config, local_dir='ray_results')\n",
    "\n",
    "\"\"\"\n",
    "# Can optionally call trainer.restore(path) to load a checkpoint.\n",
    "\n",
    "for i in range(1000):\n",
    "    # Perform one iteration of training the policy with PPO\n",
    "    result = trainer.train()\n",
    "    print(pretty_print(result))\n",
    "    \n",
    "    checkpoint = trainer.save()\n",
    "    print(\"checkpoint saved at\", checkpoint)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}