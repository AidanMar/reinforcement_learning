{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import typing\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-25 16:53:45,770\tINFO services.py:1092 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2020-11-25 16:53:45,778\tWARNING services.py:1560 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.17.0.2',\n",
       " 'raylet_ip_address': '172.17.0.2',\n",
       " 'redis_address': '172.17.0.2:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-11-25_16-53-45_209894_5481/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-11-25_16-53-45_209894_5481/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-11-25_16-53-45_209894_5481',\n",
       " 'metrics_export_port': 39217,\n",
       " 'node_id': 'b5c1ed06be1f98cc2000a6846a081da7bd93719a'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "# Start up Ray. This must be done before we instantiate any RL agents.\n",
    "ray.init(num_cpus=10, ignore_reinit_error=True, log_to_driver=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(\n",
    "    price_source: str, \n",
    "    tickers: typing.List[str],\n",
    "    start: datetime, \n",
    "    end: datetime, \n",
    "    features: typing.List[str],\n",
    "):\n",
    "    \"\"\"Returned price data to use in gym environment\"\"\"\n",
    "    # Load data\n",
    "    # Each dataframe will have columns date and a collection of fields\n",
    "    # TODO: DataLoader from mongoDB\n",
    "    # Raw price from DB, forward impute on the trading days for missing date\n",
    "    # calculate the features (log return, volatility)\n",
    "    if price_source in [\"csvdata\"]:\n",
    "        feature_df = []\n",
    "        for t in tickers:\n",
    "            df1 = pd.read_csv(\"csvdata/{}.csv\".format(t))\n",
    "            df1['datetime'] = pd.to_datetime(df1['datetime'])\n",
    "            df1 = df1[(df1['datetime']>=start) & (df1['datetime']<=end)]\n",
    "            df1.set_index(\"datetime\",inplace=True)\n",
    "            selected_features = ['return','tcost'] + features\n",
    "            feature_df.append(df1[selected_features])\n",
    "            ref_df_columns = df1[selected_features].columns\n",
    "\n",
    "    # assume all the price_df are aligned and cleaned in the DataLoader\n",
    "    merged_df = pd.concat(feature_df, axis=1, join=\"outer\")\n",
    "    # Imputer missing values with zeros \n",
    "    price_tensor = merged_df['return'].fillna(0.0).values\n",
    "    tcost = merged_df['tcost'].fillna(0.0).values\n",
    "\n",
    "    return {\n",
    "        \"dates\": merged_df.index,\n",
    "        \"fields\": ref_df_columns,\n",
    "        \"data\": merged_df.fillna(0.0).values,\n",
    "        \"pricedata\": price_tensor,\n",
    "        \"tcost\": tcost,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.36998991e-02,  4.25369008e-05,  1.09934270e-02,\n",
       "        -9.14812793e-01, -2.61064489e-01, -3.01849936e-02,\n",
       "         1.03231135e-04,  1.16465557e-02, -1.10048552e+00,\n",
       "         5.96949184e-01],\n",
       "       [-5.94984959e-03,  4.27953952e-05,  1.09991806e-02,\n",
       "        -9.10788716e-01, -2.70376218e-01, -5.12061786e-03,\n",
       "         1.03745202e-04,  1.16723407e-02, -9.95452223e-01,\n",
       "         4.23777969e-01],\n",
       "       [-3.36369023e-02,  4.42928644e-05,  1.30807177e-02,\n",
       "        -9.16682320e-01, -2.54900342e-01, -3.36202334e-02,\n",
       "         0.00000000e+00,  1.37192261e-02, -9.68839072e-01,\n",
       "        -4.24718444e-02],\n",
       "       [-1.49229482e-02,  4.49216118e-05,  1.31754036e-02,\n",
       "        -7.10326792e-01, -5.75516042e-01, -2.49435926e-02,\n",
       "         0.00000000e+00,  1.45399702e-02, -7.26873145e-01,\n",
       "        -6.77999658e-01],\n",
       "       [ 4.29173814e-02,  4.30496362e-05,  1.66156842e-02,\n",
       "         3.64864054e-01,  7.49281745e-01,  5.01088321e-02,\n",
       "         1.04701078e-04,  1.85963149e-02,  4.85487538e-01,\n",
       "         1.00154483e+00],\n",
       "       [-2.83321867e-03,  4.31685733e-05,  1.66096621e-02,\n",
       "         3.97455884e-01,  7.71150320e-01, -1.03600456e-03,\n",
       "         1.04788850e-04,  1.85902709e-02,  5.00760488e-01,\n",
       "         1.01652457e+00],\n",
       "       [ 1.38321429e-02,  4.25731193e-05,  1.67197778e-02,\n",
       "         3.83285096e-01,  6.79796060e-01,  1.84858246e-02,\n",
       "         1.02848915e-04,  1.90479506e-02,  4.14326683e-01,\n",
       "         6.36670606e-01],\n",
       "       [-1.24574586e-02,  4.31053063e-05,  1.68749185e-02,\n",
       "         4.77305606e-01,  6.20829768e-01, -1.57944420e-02,\n",
       "         1.04525975e-04,  1.90924952e-02,  5.89737350e-01,\n",
       "         7.52217559e-01],\n",
       "       [-1.81948624e-02,  4.38962293e-05,  1.69719556e-02,\n",
       "         4.73712400e-01,  5.68503491e-01, -1.92043281e-02,\n",
       "         0.00000000e+00,  1.93833946e-02,  7.09832439e-01,\n",
       "         7.12169398e-01],\n",
       "       [ 5.24473794e-04,  4.38769690e-05,  1.69286653e-02,\n",
       "         5.03839482e-01,  6.22996147e-01,  3.15641285e-03,\n",
       "         1.06145844e-04,  1.93252157e-02,  6.05525569e-01,\n",
       "         6.52081021e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data('csvdata',['SPY','QQQ',], datetime(2010, 5, 4), datetime(2020, 12, 31), [\"volatility_20\", \"skewness_20\", \"kurtosis_20\"] ) ['data'][:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from empyrical import max_drawdown, alpha_beta, sharpe_ratio, annual_return\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "class Equitydaily(gym.Env):\n",
    "\n",
    "    def __init__(self,env_config):\n",
    "        \n",
    "        self.tickers = env_config['tickers']\n",
    "        self.lookback = env_config['lookback']\n",
    "        self.random_start = env_config['random_start']\n",
    "        self.trading_days = env_config['trading_days'] # Number of days the algorithm runs before resetting\n",
    "        # Load price data, to be replaced by DataLoader class\n",
    "        raw_data = load_data(env_config['pricing_source'],env_config['tickers'],env_config['start'],env_config['end'],env_config['features'])\n",
    "        # Set the trading dates, features and price data \n",
    "        self.dates = raw_data['dates']\n",
    "        self.fields = raw_data['fields']\n",
    "        self.pricedata = raw_data['pricedata']\n",
    "        self.featuredata = raw_data['data']\n",
    "        self.tcostdata = raw_data['tcost']\n",
    "        # Set up historical actions and rewards \n",
    "        self.n_assets = len(self.tickers) + 1\n",
    "        self.n_metrics = 2 \n",
    "        self.n_assets_fields = len(self.fields)\n",
    "        self.n_features = self.n_assets_fields * len(self.tickers) + self.n_assets + self.n_metrics # reward function\n",
    "        #self.n_features = self.n_assets_fields * len(self.tickers)\n",
    "        \n",
    "        # Set up action and observation space\n",
    "        # The last asset is cash \n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(self.tickers)+1,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf,\n",
    "                                            shape=(self.lookback,self.n_features,1), dtype=np.float32)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        # Trade every 10 days \n",
    "        # Normalise action space \n",
    "        if (self.index - self.start_index) % 10 == 0:\n",
    "            normalised_action = action / np.sum(np.abs(action))\n",
    "            self.actions = normalised_action\n",
    "        \n",
    "        done = False\n",
    "        # Rebalance portfolio at close using return of the next date\n",
    "        next_day_log_return = self.pricedata[self.index,:]\n",
    "        # transaction cost \n",
    "        transaction_cost = self.transaction_cost(self.actions,self.position_series[-1])\n",
    "        \n",
    "        # Rebalancing \n",
    "        self.position_series = np.append(self.position_series, [self.actions], axis=0)\n",
    "        # Portfolio return \n",
    "        today_portfolio_return = np.sum(self.actions[:-1] * next_day_log_return) + np.sum(transaction_cost)\n",
    "        self.log_return_series = np.append(self.log_return_series, [today_portfolio_return], axis=0)\n",
    "        \n",
    "        \n",
    "        # Calculate reward \n",
    "        # Need to cast log_return in pd series to use the functions in empyrical \n",
    "        recent_series = pd.Series(self.log_return_series)[-100:]\n",
    "        #print(recent_series)\n",
    "        rolling_volatility = np.std(recent_series)\n",
    "        self.metric = today_portfolio_return / rolling_volatility \n",
    "        reward = self.metric\n",
    "        self.metric_series = np.append(self.metric_series, [self.metric], axis=0)\n",
    "        \n",
    "        # Check if the end of backtest\n",
    "        if self.trading_days is None:\n",
    "            done = self.index >= self.pricedata.shape[0]-2\n",
    "        else:\n",
    "            done = (self.index - self.start_index) >= self.trading_days\n",
    "            \n",
    "        # Prepare observation for next day\n",
    "        self.index += 1\n",
    "        self.observation = self.get_observation()\n",
    "            \n",
    "        return self.observation, reward, done, {}\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        self.log_return_series = np.zeros(shape=self.lookback)\n",
    "        self.metric_series = np.zeros(shape=self.lookback)\n",
    "        self.position_series = np.zeros(shape=(self.lookback,self.n_assets))\n",
    "        self.metric = 0           \n",
    "        if self.random_start:\n",
    "            num_days = len(self.dates)      \n",
    "            self.start_index = np.random.randint(self.lookback, num_days - self.trading_days)\n",
    "            self.index = self.start_index\n",
    "        else:\n",
    "            self.start_index = self.lookback\n",
    "            self.index = self.lookback\n",
    "        self.actions = np.zeros(shape=self.n_assets)\n",
    "        self.observation = self.get_observation()\n",
    "        return self.observation\n",
    "    \n",
    "    def get_observation(self):\n",
    "        # Can use simple moving average data here \n",
    "        last_lookback_day = self.index - self.start_index\n",
    "        price_lookback = self.featuredata[last_lookback_day:last_lookback_day + self.lookback,:]\n",
    "        metrics = np.vstack((self.log_return_series[last_lookback_day:last_lookback_day + self.lookback], \n",
    "                             self.metric_series[last_lookback_day:last_lookback_day + self.lookback])).transpose()\n",
    "        positions = self.position_series[last_lookback_day:last_lookback_day + self.lookback]\n",
    "        scaler = StandardScaler()\n",
    "        price_lookback = scaler.fit_transform(price_lookback)\n",
    "        observation = np.concatenate((price_lookback, metrics, positions), axis=1)\n",
    "        return observation.reshape((observation.shape[0], observation.shape[1], 1))\n",
    "    \n",
    "    # 0.05% and spread to model t-cost for institutional portfolios \n",
    "    def transaction_cost(self, new_action, old_action):\n",
    "        turnover = np.abs(new_action - old_action) \n",
    "        fees = 0.9995 - self.tcostdata[self.index,:]\n",
    "        fees = np.array(list(fees) + [0.9995])\n",
    "        tcost = turnover * np.log(fees)\n",
    "        return tcost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'pricing_source':'csvdata', 'tickers':['BRK','TLT','QQQ','GLD',], \n",
    "          'lookback':150, 'start':'2008-01-02', 'end':'2018-12-31', 'features':[\"volatility_20\", \"skewness_20\", \"kurtosis_20\"], 'random_start': True, 'trading_days':600}\n",
    "EQ_env = Equitydaily(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 27, 1), 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EQ_env.observation.shape, EQ_env.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.05037815259212\n"
     ]
    }
   ],
   "source": [
    "EQ_env.reset()\n",
    "_, rw, _, _ = EQ_env.step([ 0.4612986,  -0.3883527,  -0.45688114, -0.06747285, -0.1717046])\n",
    "print(rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.92373966],\n",
       "        [ 0.45358441],\n",
       "        [ 1.39746521],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.8800406 ],\n",
       "        [ 1.02384958],\n",
       "        [ 1.20435439],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.08883363],\n",
       "        [ 0.60212631],\n",
       "        [ 1.16747142],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.50895053],\n",
       "        [ 0.0082069 ],\n",
       "        [ 1.10279178],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-1.75118278],\n",
       "        [ 2.36244607],\n",
       "        [ 1.36376658],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.12167133],\n",
       "        [ 1.58185624],\n",
       "        [ 1.35427596],\n",
       "        ...,\n",
       "        [-0.29558014],\n",
       "        [-0.04365169],\n",
       "        [-0.11108462]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EQ_env.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = EQ_env.reset()\n",
    "done = False\n",
    "reward_list = []\n",
    "cum_reward = 0\n",
    "actions = list()\n",
    "\n",
    "while not done:\n",
    "    #action = agent.compute_action(state)\n",
    "    action = np.array([1,0,0,0,0])\n",
    "    state, reward, done, future_price = EQ_env.step(action)\n",
    "    cum_reward += reward\n",
    "    actions.append(action)\n",
    "    reward_list.append(reward)\n",
    "\n",
    "pd.Series(reward_list).cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/envs/quant/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 5\n",
    "config[\"num_envs_per_worker\"] = 1\n",
    "config[\"rollout_fragment_length\"] = 20\n",
    "config[\"train_batch_size\"] = 1200\n",
    "config[\"batch_mode\"] = \"complete_episodes\"\n",
    "config['num_sgd_iter'] = 20\n",
    "config['sgd_minibatch_size'] = 200\n",
    "config['model']['dim'] = 200\n",
    "config['model']['conv_filters'] = [[32, [5, 1], 5], [32, [5, 1], 5], [4, [5, 1], 5]]\n",
    "config['num_cpus_per_worker'] = 2  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "config['env_config'] = {'pricing_source':'csvdata', \"tickers\": [\"BRK_A\", \"GE_\",\"GOLD_\", \"AAPL_\",\"GS_\",\"T_\",],\n",
    "          'lookback':200, 'start':'1995-01-02', 'end':'2018-12-31', 'features':[\"return_volatility_20\", \"return_skewness_20\", \"return_kurtosis_20\"],\n",
    "          'random_start': True, 'trading_days': 600}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if agents can be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = PPOTrainer(config, Equitydaily)\n",
    "best_reward = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(300)):\n",
    "    result = agent.train()\n",
    "    if result['episode_reward_mean'] > best_reward + 10:\n",
    "        path = agent.save('sampleagent')\n",
    "        print(path)\n",
    "        best_reward = result['episode_reward_mean']\n",
    "        print(best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-24 18:16:19,141\tINFO trainable.py:482 -- Restored on 192.168.0.101 from checkpoint: sampleagent/checkpoint_1/checkpoint-1\n",
      "2020-11-24 18:16:19,142\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 24.549320936203003, '_episodes_total': 9}\n"
     ]
    }
   ],
   "source": [
    "agent.restore('sampleagent/checkpoint_1/checkpoint-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleagent/checkpoint_2/checkpoint-2\n",
      "-18.499785088445154\n",
      "sampleagent/checkpoint_3/checkpoint-3\n",
      "-16.556459086976048\n",
      "sampleagent/checkpoint_4/checkpoint-4\n",
      "-14.630928403378638\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    result = agent.train()\n",
    "    if result['episode_reward_mean'] > best_reward + 1:\n",
    "        path = agent.save('sampleagent')\n",
    "        print(path)\n",
    "        best_reward = result['episode_reward_mean']\n",
    "        print(best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episode_reward_max': 52.77934555607334,\n",
       " 'episode_reward_min': -86.04378430659364,\n",
       " 'episode_reward_mean': -18.523488700115685,\n",
       " 'episode_len_mean': 601.0,\n",
       " 'episodes_this_iter': 9,\n",
       " 'policy_reward_min': {},\n",
       " 'policy_reward_max': {},\n",
       " 'policy_reward_mean': {},\n",
       " 'custom_metrics': {},\n",
       " 'hist_stats': {'episode_reward': [-45.6825668696604,\n",
       "   -10.03960208396772,\n",
       "   -86.04378430659364,\n",
       "   -17.20824320402023,\n",
       "   9.652539580057784,\n",
       "   -31.748727861143124,\n",
       "   -46.54041751196004,\n",
       "   -73.66879208983079,\n",
       "   -47.84958915896191,\n",
       "   -63.55823822770892,\n",
       "   -14.381210230459878,\n",
       "   -2.019125434167244,\n",
       "   -21.15038879249259,\n",
       "   -50.66122997210185,\n",
       "   -51.34743964490648,\n",
       "   9.509088603245639,\n",
       "   -39.49717156868493,\n",
       "   -39.158988309216575,\n",
       "   -6.857061755878346,\n",
       "   52.77934555607334,\n",
       "   -42.36841265278894,\n",
       "   -33.95732898670692,\n",
       "   35.229035199981965,\n",
       "   -84.7391826807767,\n",
       "   1.2101442723187028,\n",
       "   -13.324725917295487,\n",
       "   -33.97551246279332,\n",
       "   -13.822189658401095,\n",
       "   16.611751221895165,\n",
       "   -52.65329252650407,\n",
       "   8.873974529577376,\n",
       "   -25.62587588102242,\n",
       "   -36.02832254919572,\n",
       "   8.721919388772468,\n",
       "   -46.00308343815432,\n",
       "   38.6993245293719,\n",
       "   12.781451950995663,\n",
       "   -34.82709280331788,\n",
       "   -59.09195613142421,\n",
       "   -4.565612405982268,\n",
       "   0.12071444574522805,\n",
       "   -14.88139261284083,\n",
       "   31.370610428057113,\n",
       "   -16.61518236870877,\n",
       "   -10.829870245642317,\n",
       "   -20.30676271772501,\n",
       "   -44.65692102060569,\n",
       "   -31.853626972199123,\n",
       "   -29.789199258218414,\n",
       "   -26.110634208944038,\n",
       "   1.8132573073631992,\n",
       "   31.683301103043327,\n",
       "   29.544203125980772,\n",
       "   27.317131620403774,\n",
       "   -11.03267872016328,\n",
       "   -35.87237385557684,\n",
       "   -22.96376515733498,\n",
       "   7.507059756839339,\n",
       "   -16.280279132790653,\n",
       "   -11.475589190356144,\n",
       "   -33.84438714982256,\n",
       "   -58.7024644407639,\n",
       "   23.20565144079971],\n",
       "  'episode_lengths': [601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601]},\n",
       " 'sampler_perf': {'mean_env_wait_ms': 0.9942217810868244,\n",
       "  'mean_raw_obs_processing_ms': 0.18674279250673886,\n",
       "  'mean_inference_ms': 0.6311225609268525,\n",
       "  'mean_action_processing_ms': 0.07442045425743668},\n",
       " 'off_policy_estimator': {},\n",
       " 'num_healthy_workers': 1,\n",
       " 'timesteps_total': 32454,\n",
       " 'timers': {'sample_time_ms': 10463.033,\n",
       "  'sample_throughput': 516.963,\n",
       "  'load_time_ms': 286.016,\n",
       "  'load_throughput': 18911.524,\n",
       "  'learn_time_ms': 11276.592,\n",
       "  'learn_throughput': 479.666,\n",
       "  'update_time_ms': 2.517},\n",
       " 'info': {'learner': {'default_policy': {'cur_kl_coeff': 0.00937500037252903,\n",
       "    'cur_lr': 4.999999873689376e-05,\n",
       "    'total_loss': 49.262215,\n",
       "    'policy_loss': -0.018855443,\n",
       "    'vf_loss': 49.281033,\n",
       "    'vf_explained_var': -0.0014109038,\n",
       "    'kl': 0.0036750787,\n",
       "    'entropy': 10.056853,\n",
       "    'entropy_coeff': 0.0,\n",
       "    'model': {}}},\n",
       "  'num_steps_sampled': 32454,\n",
       "  'num_steps_trained': 32454},\n",
       " 'done': False,\n",
       " 'episodes_total': 54,\n",
       " 'training_iteration': 6,\n",
       " 'experiment_id': 'ef7c90146df249558e21c43df610d138',\n",
       " 'date': '2020-11-24_18-18-12',\n",
       " 'timestamp': 1606238292,\n",
       " 'time_this_iter_s': 21.24334979057312,\n",
       " 'time_total_s': 134.85556650161743,\n",
       " 'pid': 20930,\n",
       " 'hostname': 'Pavols-MacBook-Pro.local',\n",
       " 'node_ip': '192.168.0.101',\n",
       " 'config': {'num_workers': 1,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'rollout_fragment_length': 20,\n",
       "  'batch_mode': 'complete_episodes',\n",
       "  'num_gpus': 0,\n",
       "  'train_batch_size': 5000,\n",
       "  'model': {'fcnet_hiddens': [256, 256],\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'conv_filters': [[32, [5, 1], 5], [32, [5, 1], 5], [4, [5, 1], 5]],\n",
       "   'conv_activation': 'relu',\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': True,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action_reward': False,\n",
       "   '_time_major': False,\n",
       "   'framestack': True,\n",
       "   'dim': 200,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None},\n",
       "  'optimizer': {},\n",
       "  'gamma': 0.99,\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env_config': {'pricing_source': 'csvdata',\n",
       "   'tickers': ['BRK_A', 'GE_', 'GOLD_', 'AAPL_', 'GS_', 'T_'],\n",
       "   'lookback': 200,\n",
       "   'start': '1995-01-02',\n",
       "   'end': '2018-12-31',\n",
       "   'features': ['return_volatility_20',\n",
       "    'return_skewness_20',\n",
       "    'return_kurtosis_20'],\n",
       "   'random_start': True,\n",
       "   'trading_days': 600},\n",
       "  'env': 'Equitydaily',\n",
       "  'normalize_actions': False,\n",
       "  'clip_rewards': None,\n",
       "  'clip_actions': True,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'lr': 5e-05,\n",
       "  'monitor': False,\n",
       "  'log_level': 'WARN',\n",
       "  'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'framework': 'tf',\n",
       "  'eager_tracing': False,\n",
       "  'no_eager_on_workers': False,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_num_episodes': 10,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'sample_async': False,\n",
       "  '_use_trajectory_view_api': False,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'compress_observations': False,\n",
       "  'collect_metrics_timeout': 180,\n",
       "  'metrics_smoothing_episodes': 100,\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'min_iter_time_s': 0,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'seed': None,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_cpus_per_worker': 2,\n",
       "  'num_gpus_per_worker': 0,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'memory': 0,\n",
       "  'object_store_memory': 0,\n",
       "  'memory_per_worker': 0,\n",
       "  'object_store_memory_per_worker': 0,\n",
       "  'input': 'sampler',\n",
       "  'input_evaluation': ['is', 'wis'],\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'multiagent': {'policies': {},\n",
       "   'policy_mapping_fn': None,\n",
       "   'policies_to_train': None,\n",
       "   'observation_fn': None,\n",
       "   'replay_mode': 'independent'},\n",
       "  'logger_config': None,\n",
       "  'replay_sequence_length': 1,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 1.0,\n",
       "  'kl_coeff': 0.2,\n",
       "  'sgd_minibatch_size': 200,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 20,\n",
       "  'lr_schedule': None,\n",
       "  'vf_share_layers': False,\n",
       "  'vf_loss_coeff': 1.0,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.3,\n",
       "  'vf_clip_param': 10.0,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.01,\n",
       "  'simple_optimizer': False,\n",
       "  '_fake_gpus': False},\n",
       " 'time_since_restore': 110.30624556541443,\n",
       " 'timesteps_since_restore': 0,\n",
       " 'iterations_since_restore': 5,\n",
       " 'perf': {'cpu_util_percent': 34.0, 'ram_util_percent': 73.68333333333335}}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.sac import SACTrainer, DEFAULT_CONFIG\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 1\n",
    "config[\"num_envs_per_worker\"] = 1\n",
    "\n",
    "config[\"rollout_fragment_length\"] = 10\n",
    "config[\"train_batch_size\"] = 50\n",
    "config[\"timesteps_per_iteration\"] = 10\n",
    "config[\"buffer_size\"] = 10000\n",
    "\n",
    "config[\"Q_model\"][\"fcnet_hiddens\"] = [10, 10]\n",
    "config[\"policy_model\"][\"fcnet_hiddens\"] = [10, 10]\n",
    "config[\"num_cpus_per_worker\"] = 2 \n",
    "config[\"env_config\"] = {\n",
    "    \"pricing_source\": \"csvdata\",\n",
    "    \"tickers\": [\"QQQ\", \"EEM\", \"TLT\", \"SHY\", \"GLD\", \"SLV\"],\n",
    "    \"lookback\": 1,\n",
    "    \"start\": \"2007-01-02\",\n",
    "    \"end\": \"2015-12-31\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train agent \n",
    "agent = SACTrainer(config, Equitydaily)\n",
    "best_reward = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    result = agent.train()\n",
    "    if result['episode_reward_mean'] > best_reward + 0.01:\n",
    "        path = agent.save('sampleagent')\n",
    "        print(path)\n",
    "        best_reward = result['episode_reward_mean']\n",
    "    print(result['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6042\n",
      "2010\n",
      "2020-11-24 18:19:14,974\tWARNING util.py:39 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "agent = PPOTrainer(config, Equitydaily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6042\n",
      "1190\n"
     ]
    }
   ],
   "source": [
    "env = Equitydaily(config['env_config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoint_1087/checkpoint-1087.tune_metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-d66c41531741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoint_1087/checkpoint-1087'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/quant/lib/python3.7/site-packages/ray/tune/trainable.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mThis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mrestores\u001b[0m \u001b[0madditional\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0msaved\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \"\"\"\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".tune_metadata\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"experiment_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoint_1087/checkpoint-1087.tune_metadata'"
     ]
    }
   ],
   "source": [
    "agent.restore('checkpoint_1087/checkpoint-1087')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "done = False\n",
    "reward_list = []\n",
    "cum_reward = 0\n",
    "actions = list()\n",
    "\n",
    "while not done:\n",
    "    #action = agent.compute_action(state)\n",
    "    action = np.array([0,0,0,0,0,0,1])\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    cum_reward += reward\n",
    "    actions.append(action)\n",
    "    reward_list.append(reward)\n",
    "\n",
    "pd.Series(env.log_return_series).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(reward_list).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run environment for RNN environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Equitydaily({'pricing_source':'Alpaca_Equity_daily', 'tickers':['SPY','QQQ'], 'lookback':50, 'start':'2018-01-02', 'end':'2020-12-31'})\n",
    "\n",
    "state = env.reset()\n",
    "done = False\n",
    "cum_reward = 0 \n",
    "actions = list()\n",
    "\n",
    "rnn_state = agent.get_policy().get_initial_state()\n",
    "\n",
    "while not done:\n",
    "    action, rnn_state, _ = agent.compute_action(state,rnn_state)\n",
    "    #action = np.array([1,-1])\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    cum_reward += reward\n",
    "    actions.append(actions)\n",
    "\n",
    "pd.Series(env.log_return_series).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_drawdown(pd.Series(env.log_return_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_return(pd.Series(env.log_return_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Equitydaily_v1(gym.Env):\n",
    "\n",
    "    def __init__(self,env_config):\n",
    "        \n",
    "        self.tickers = env_config['tickers']\n",
    "        self.lookback = env_config['lookback']\n",
    "        # Load price data, to be replaced by DataLoader class\n",
    "        raw_data = load_data(env_config['pricing_source'],env_config['tickers'],env_config['start'],env_config['end'])\n",
    "        # Set the trading dates, features and price data \n",
    "        self.dates = raw_data['dates']\n",
    "        self.fields = raw_data['fields']\n",
    "        self.pricedata = raw_data['pricedata']\n",
    "        self.featuredata = raw_data['data']\n",
    "        self.tcostdata = raw_data['tcost']\n",
    "        # Set up historical actions and rewards \n",
    "        self.n_assets = len(self.tickers) + 1\n",
    "        self.n_metrics = 2 \n",
    "        self.n_assets_fields = len(self.fields)\n",
    "        self.n_features = self.n_assets_fields * len(self.tickers) + self.n_assets + self.n_metrics # reward function\n",
    "        \n",
    "        # Set up action and observation space\n",
    "        # The last asset is cash \n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(self.tickers)+1,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf,\n",
    "                                            shape=(self.lookback,self.n_features), dtype=np.float32)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        ## Normalise action space \n",
    "        normalised_action = action / np.sum(np.abs(action))\n",
    "        \n",
    "        done = False\n",
    "        # Rebalance portfolio at close using return of the next date\n",
    "        next_day_log_return = self.pricedata[self.index,:]\n",
    "        # transaction cost \n",
    "        transaction_cost = self.transaction_cost(normalised_action,self.position_series[-1])\n",
    "        \n",
    "        # Rebalancing \n",
    "        self.position_series = np.append(self.position_series, [normalised_action], axis=0)\n",
    "        # Portfolio return \n",
    "        today_portfolio_return = np.sum(normalised_action[:-1] * next_day_log_return) + np.sum(transaction_cost)\n",
    "        self.log_return_series = np.append(self.log_return_series, [today_portfolio_return], axis=0)\n",
    "        \n",
    "        \n",
    "        # Calculate reward \n",
    "        # Need to cast log_return in pd series to use the functions in empyrical \n",
    "        live_days = self.index - self.lookback\n",
    "        burnin = 250\n",
    "        recent_series = pd.Series(self.log_return_series)[-100:]\n",
    "        whole_series = pd.Series(self.log_return_series)\n",
    "        if live_days > burnin: \n",
    "            self.metric = annual_return(whole_series) + 0.5* max_drawdown(whole_series)\n",
    "        else:\n",
    "            self.metric = annual_return(whole_series) + 0.5* max_drawdown(whole_series) *live_days / burnin\n",
    "        reward = self.metric - self.metric_series[-1]\n",
    "        #reward = self.metric\n",
    "        self.metric_series = np.append(self.metric_series, [self.metric], axis=0)\n",
    "        \n",
    "        # Check if the end of backtest\n",
    "        if self.index >= self.pricedata.shape[0]-2:\n",
    "            done = True\n",
    "            \n",
    "        # Prepare observation for next day\n",
    "        self.index += 1\n",
    "        self.observation = self.get_observation()\n",
    "            \n",
    "        return self.observation, reward, done, {'current_price':next_day_log_return}\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        self.log_return_series = np.zeros(shape=self.lookback)\n",
    "        self.metric_series = np.zeros(shape=self.lookback)\n",
    "        self.position_series = np.zeros(shape=(self.lookback,self.n_assets))\n",
    "        self.metric = 0                    \n",
    "        self.index = self.lookback\n",
    "        self.observation = self.get_observation()\n",
    "        return self.observation\n",
    "    \n",
    "    def get_observation(self):\n",
    "        # Can use simple moving average data here \n",
    "        price_lookback = self.featuredata[self.index-self.lookback:self.index,:]\n",
    "        metrics = np.vstack((self.log_return_series[self.index-self.lookback:self.index], \n",
    "                             self.metric_series[self.index-self.lookback:self.index])).transpose()\n",
    "        positions = self.position_series[self.index-self.lookback:self.index]\n",
    "        observation = np.concatenate((price_lookback, metrics, positions), axis=1)\n",
    "        return observation \n",
    "    \n",
    "    # 0.05% and spread to model t-cost for institutional portfolios \n",
    "    def transaction_cost(self,new_action,old_action,):\n",
    "        turnover = np.abs(new_action - old_action) \n",
    "        fees = 0.9995 - self.tcostdata[self.index,:]\n",
    "        tcost = turnover * np.log(fees)\n",
    "        return tcost "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
