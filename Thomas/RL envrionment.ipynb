{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import typing\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-22 09:32:15,267\tERROR worker.py:643 -- Calling ray.init() again after it has already been called.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "# Start up Ray. This must be done before we instantiate any RL agents.\n",
    "ray.init(num_cpus=10, ignore_reinit_error=True, log_to_driver=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(\n",
    "    price_source: str, \n",
    "    tickers: typing.List[str],\n",
    "    start: datetime, \n",
    "    end: datetime, \n",
    "    features: typing.List[str],\n",
    "):\n",
    "    \"\"\"Returned price data to use in gym environment\"\"\"\n",
    "    # Load data\n",
    "    # Each dataframe will have columns date and a collection of fields\n",
    "    # TODO: DataLoader from mongoDB\n",
    "    # Raw price from DB, forward impute on the trading days for missing date\n",
    "    # calculate the features (log return, volatility)\n",
    "    if price_source in [\"csvdata\"]:\n",
    "        feature_df = []\n",
    "        for t in tickers:\n",
    "            df1 = pd.read_csv(\"csvdata/{}.csv\".format(t))\n",
    "            df1['datetime'] = pd.to_datetime(df1['datetime'])\n",
    "            df1 = df1[(df1['datetime']>=start) & (df1['datetime']<=end)]\n",
    "            df1.set_index(\"datetime\",inplace=True)\n",
    "            selected_features = ['return','tcost'] + features\n",
    "            feature_df.append(df1[selected_features])\n",
    "            ref_df_columns = df1[selected_features].columns\n",
    "\n",
    "    # assume all the price_df are aligned and cleaned in the DataLoader\n",
    "    merged_df = pd.concat(feature_df, axis=1, join=\"outer\")\n",
    "    # Imputer missing values with zeros \n",
    "    price_tensor = merged_df['return'].fillna(0.0).values\n",
    "    tcost = merged_df['tcost'].fillna(0.0).values\n",
    "\n",
    "    return {\n",
    "        \"dates\": merged_df.index,\n",
    "        \"fields\": ref_df_columns,\n",
    "        \"data\": merged_df.fillna(0.0).values,\n",
    "        \"pricedata\": price_tensor,\n",
    "        \"tcost\": tcost,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.36998991e-02,  4.25369008e-05,  1.09934270e-02,\n",
       "        -9.14812793e-01, -2.61064489e-01, -3.01849936e-02,\n",
       "         1.03231135e-04,  1.16465557e-02, -1.10048552e+00,\n",
       "         5.96949184e-01],\n",
       "       [-5.94984959e-03,  4.27953952e-05,  1.09991806e-02,\n",
       "        -9.10788716e-01, -2.70376218e-01, -5.12061786e-03,\n",
       "         1.03745202e-04,  1.16723407e-02, -9.95452223e-01,\n",
       "         4.23777969e-01],\n",
       "       [-3.36369023e-02,  4.42928644e-05,  1.30807177e-02,\n",
       "        -9.16682320e-01, -2.54900342e-01, -3.36202334e-02,\n",
       "         0.00000000e+00,  1.37192261e-02, -9.68839072e-01,\n",
       "        -4.24718444e-02],\n",
       "       [-1.49229482e-02,  4.49216118e-05,  1.31754036e-02,\n",
       "        -7.10326792e-01, -5.75516042e-01, -2.49435926e-02,\n",
       "         0.00000000e+00,  1.45399702e-02, -7.26873145e-01,\n",
       "        -6.77999658e-01],\n",
       "       [ 4.29173814e-02,  4.30496362e-05,  1.66156842e-02,\n",
       "         3.64864054e-01,  7.49281745e-01,  5.01088321e-02,\n",
       "         1.04701078e-04,  1.85963149e-02,  4.85487538e-01,\n",
       "         1.00154483e+00],\n",
       "       [-2.83321867e-03,  4.31685733e-05,  1.66096621e-02,\n",
       "         3.97455884e-01,  7.71150320e-01, -1.03600456e-03,\n",
       "         1.04788850e-04,  1.85902709e-02,  5.00760488e-01,\n",
       "         1.01652457e+00],\n",
       "       [ 1.38321429e-02,  4.25731193e-05,  1.67197778e-02,\n",
       "         3.83285096e-01,  6.79796060e-01,  1.84858246e-02,\n",
       "         1.02848915e-04,  1.90479506e-02,  4.14326683e-01,\n",
       "         6.36670606e-01],\n",
       "       [-1.24574586e-02,  4.31053063e-05,  1.68749185e-02,\n",
       "         4.77305606e-01,  6.20829768e-01, -1.57944420e-02,\n",
       "         1.04525975e-04,  1.90924952e-02,  5.89737350e-01,\n",
       "         7.52217559e-01],\n",
       "       [-1.81948624e-02,  4.38962293e-05,  1.69719556e-02,\n",
       "         4.73712400e-01,  5.68503491e-01, -1.92043281e-02,\n",
       "         0.00000000e+00,  1.93833946e-02,  7.09832439e-01,\n",
       "         7.12169398e-01],\n",
       "       [ 5.24473794e-04,  4.38769690e-05,  1.69286653e-02,\n",
       "         5.03839482e-01,  6.22996147e-01,  3.15641285e-03,\n",
       "         1.06145844e-04,  1.93252157e-02,  6.05525569e-01,\n",
       "         6.52081021e-01]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data('csvdata',['SPY','QQQ',], datetime(2010, 5, 4), datetime(2020, 12, 31), [\"volatility_20\", \"skewness_20\", \"kurtosis_20\"] ) ['data'][:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from empyrical import max_drawdown, alpha_beta, sharpe_ratio, annual_return\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "class Equitydaily(gym.Env):\n",
    "\n",
    "    def __init__(self,env_config):\n",
    "        \n",
    "        self.tickers = env_config['tickers']\n",
    "        self.lookback = env_config['lookback']\n",
    "        # Load price data, to be replaced by DataLoader class\n",
    "        raw_data = load_data(env_config['pricing_source'],env_config['tickers'],env_config['start'],env_config['end'],env_config['features'])\n",
    "        # Set the trading dates, features and price data \n",
    "        self.dates = raw_data['dates']\n",
    "        self.fields = raw_data['fields']\n",
    "        self.pricedata = raw_data['pricedata']\n",
    "        self.featuredata = raw_data['data']\n",
    "        self.tcostdata = raw_data['tcost']\n",
    "        # Set up historical actions and rewards \n",
    "        self.n_assets = len(self.tickers) + 1\n",
    "        self.n_metrics = 2 \n",
    "        self.n_assets_fields = len(self.fields)\n",
    "        self.n_features = self.n_assets_fields * len(self.tickers) + self.n_assets + self.n_metrics # reward function\n",
    "        #self.n_features = self.n_assets_fields * len(self.tickers)\n",
    "        \n",
    "        # Set up action and observation space\n",
    "        # The last asset is cash \n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(self.tickers)+1,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf,\n",
    "                                            shape=(self.lookback,self.n_features,1), dtype=np.float32)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        # Trade every 10 days \n",
    "        # Normalise action space \n",
    "        if self.index % 10 == 0:\n",
    "            normalised_action = action / np.sum(np.abs(action))\n",
    "            self.actions = normalised_action\n",
    "        \n",
    "        done = False\n",
    "        # Rebalance portfolio at close using return of the next date\n",
    "        next_day_log_return = self.pricedata[self.index,:]\n",
    "        # transaction cost \n",
    "        transaction_cost = self.transaction_cost(self.actions,self.position_series[-1])\n",
    "        \n",
    "        # Rebalancing \n",
    "        self.position_series = np.append(self.position_series, [self.actions], axis=0)\n",
    "        # Portfolio return \n",
    "        today_portfolio_return = np.sum(self.actions[:-1] * next_day_log_return) + np.sum(transaction_cost)\n",
    "        self.log_return_series = np.append(self.log_return_series, [today_portfolio_return], axis=0)\n",
    "        \n",
    "        \n",
    "        # Calculate reward \n",
    "        # Need to cast log_return in pd series to use the functions in empyrical \n",
    "        recent_series = pd.Series(self.log_return_series)[-100:]\n",
    "        rolling_volatility = np.std(recent_series)\n",
    "        self.metric = today_portfolio_return / rolling_volatility \n",
    "        reward = self.metric\n",
    "        self.metric_series = np.append(self.metric_series, [self.metric], axis=0)\n",
    "        \n",
    "        # Check if the end of backtest\n",
    "        if self.index >= self.pricedata.shape[0]-2:\n",
    "            done = True\n",
    "            \n",
    "        # Prepare observation for next day\n",
    "        self.index += 1\n",
    "        self.observation = self.get_observation()\n",
    "            \n",
    "        return self.observation, reward, done, {}\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        self.log_return_series = np.zeros(shape=self.lookback)\n",
    "        self.metric_series = np.zeros(shape=self.lookback)\n",
    "        self.position_series = np.zeros(shape=(self.lookback,self.n_assets))\n",
    "        self.metric = 0                    \n",
    "        self.index = self.lookback\n",
    "        self.actions = np.zeros(shape=self.n_assets)\n",
    "        self.observation = self.get_observation()\n",
    "        return self.observation\n",
    "    \n",
    "    def get_observation(self):\n",
    "        # Can use simple moving average data here \n",
    "        price_lookback = self.featuredata[self.index-self.lookback:self.index,:]\n",
    "        metrics = np.vstack((self.log_return_series[self.index-self.lookback:self.index], \n",
    "                             self.metric_series[self.index-self.lookback:self.index])).transpose()\n",
    "        positions = self.position_series[self.index-self.lookback:self.index]\n",
    "        scaler = StandardScaler()\n",
    "        price_lookback = scaler.fit_transform(price_lookback)\n",
    "        observation = np.concatenate((price_lookback, metrics, positions), axis=1)\n",
    "        return observation.reshape((observation.shape[0], observation.shape[1], 1))\n",
    "    \n",
    "    # 0.05% and spread to model t-cost for institutional portfolios \n",
    "    def transaction_cost(self, new_action, old_action,):\n",
    "        turnover = np.abs(new_action - old_action) \n",
    "        fees = 0.9995 - self.tcostdata[self.index,:]\n",
    "        fees = np.array(list(fees) + [0.9995])\n",
    "        tcost = turnover * np.log(fees)\n",
    "        return tcost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'pricing_source':'csvdata', 'tickers':['BRK','TLT','QQQ','GLD',], \n",
    "          'lookback':10, 'start':'2008-01-02', 'end':'2018-12-31', 'features':[\"volatility_20\", \"skewness_20\", \"kurtosis_20\"]}\n",
    "EQ_env = Equitydaily(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 27, 1), 20)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EQ_env.observation.shape, EQ_env.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.46623792],\n",
       "        [-0.53317207],\n",
       "        [-0.6065899 ],\n",
       "        [-1.90618101],\n",
       "        [ 2.16042431],\n",
       "        [ 1.52550903],\n",
       "        [-0.87140677],\n",
       "        [ 1.31492554],\n",
       "        [ 1.26956813],\n",
       "        [-1.38604284],\n",
       "        [-0.1689315 ],\n",
       "        [ 0.67833654],\n",
       "        [-2.42229207],\n",
       "        [ 0.69360279],\n",
       "        [-1.00745854],\n",
       "        [ 1.55595835],\n",
       "        [-0.34534522],\n",
       "        [ 0.60420498],\n",
       "        [-0.71944688],\n",
       "        [-0.43106563],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-1.06752807],\n",
       "        [-0.69607796],\n",
       "        [ 0.34712032],\n",
       "        [-0.98516115],\n",
       "        [-0.08524695],\n",
       "        [-0.62235964],\n",
       "        [ 1.32476134],\n",
       "        [ 1.31857015],\n",
       "        [ 1.33850772],\n",
       "        [-1.35020668],\n",
       "        [-1.59973366],\n",
       "        [ 0.73023773],\n",
       "        [-0.21286845],\n",
       "        [-1.69979899],\n",
       "        [ 1.299592  ],\n",
       "        [-0.10455638],\n",
       "        [ 0.74862153],\n",
       "        [ 0.08162681],\n",
       "        [-0.00885458],\n",
       "        [ 0.13058068],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.30618024],\n",
       "        [-0.24455047],\n",
       "        [-0.55871233],\n",
       "        [-0.59642075],\n",
       "        [ 0.5371135 ],\n",
       "        [ 0.14870816],\n",
       "        [ 0.87501141],\n",
       "        [ 0.92193918],\n",
       "        [ 0.77652767],\n",
       "        [-1.18622536],\n",
       "        [ 0.39531322],\n",
       "        [-0.50376217],\n",
       "        [-0.74180448],\n",
       "        [-1.59853223],\n",
       "        [ 1.93159224],\n",
       "        [-0.5871292 ],\n",
       "        [-0.89601903],\n",
       "        [-0.48856689],\n",
       "        [-0.20480558],\n",
       "        [ 0.79950034],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.40058506],\n",
       "        [-0.57846469],\n",
       "        [-0.73172071],\n",
       "        [-0.48297451],\n",
       "        [ 0.77659638],\n",
       "        [-0.62193942],\n",
       "        [-0.43653978],\n",
       "        [ 0.65287589],\n",
       "        [ 0.52078536],\n",
       "        [-0.61473354],\n",
       "        [-0.774275  ],\n",
       "        [ 0.7646505 ],\n",
       "        [-0.57869645],\n",
       "        [-0.695726  ],\n",
       "        [ 0.87175167],\n",
       "        [ 1.21393194],\n",
       "        [ 0.69572567],\n",
       "        [ 1.17241839],\n",
       "        [-0.23790593],\n",
       "        [-0.40257262],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.91943767],\n",
       "        [-0.44902993],\n",
       "        [-0.05393865],\n",
       "        [ 0.19118696],\n",
       "        [-0.60184773],\n",
       "        [-0.19267167],\n",
       "        [ 1.74840942],\n",
       "        [ 0.15704135],\n",
       "        [ 0.18155537],\n",
       "        [ 0.31779053],\n",
       "        [ 1.79978498],\n",
       "        [-1.7467722 ],\n",
       "        [ 0.23060917],\n",
       "        [-0.19781087],\n",
       "        [ 0.12074076],\n",
       "        [-0.48404075],\n",
       "        [-0.37804062],\n",
       "        [ 0.44285183],\n",
       "        [-0.49911394],\n",
       "        [ 0.40673124],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 1.09689362],\n",
       "        [-0.25920278],\n",
       "        [ 0.34750631],\n",
       "        [ 0.20341686],\n",
       "        [-1.05653186],\n",
       "        [-1.27441419],\n",
       "        [ 0.44831558],\n",
       "        [ 0.14867796],\n",
       "        [ 0.17827985],\n",
       "        [ 0.34137607],\n",
       "        [-0.34127214],\n",
       "        [ 0.76222498],\n",
       "        [ 0.35129897],\n",
       "        [ 0.69930732],\n",
       "        [-0.32031755],\n",
       "        [ 1.19761783],\n",
       "        [-0.41485745],\n",
       "        [ 1.25288291],\n",
       "        [-0.32783632],\n",
       "        [-0.0544529 ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.27963608],\n",
       "        [-0.4850496 ],\n",
       "        [ 0.39355487],\n",
       "        [ 0.5562369 ],\n",
       "        [-1.2135276 ],\n",
       "        [ 0.06020898],\n",
       "        [-0.87252032],\n",
       "        [-0.89626073],\n",
       "        [-0.32837886],\n",
       "        [ 0.42565328],\n",
       "        [ 1.59276081],\n",
       "        [-1.74781031],\n",
       "        [ 0.48015162],\n",
       "        [-0.1795249 ],\n",
       "        [-0.06976448],\n",
       "        [ 0.39026817],\n",
       "        [-1.47739738],\n",
       "        [-0.6120611 ],\n",
       "        [-1.37262309],\n",
       "        [ 1.80448616],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.13156142],\n",
       "        [ 2.85240116],\n",
       "        [-1.08420971],\n",
       "        [ 0.41188162],\n",
       "        [ 0.65328383],\n",
       "        [ 1.10416509],\n",
       "        [-0.01614491],\n",
       "        [-1.07096102],\n",
       "        [-1.1570427 ],\n",
       "        [ 0.9181413 ],\n",
       "        [-0.86495253],\n",
       "        [ 0.77554401],\n",
       "        [ 0.92424023],\n",
       "        [ 0.78847832],\n",
       "        [-0.844473  ],\n",
       "        [-1.44785055],\n",
       "        [ 0.12633854],\n",
       "        [ 0.78560628],\n",
       "        [-0.36951766],\n",
       "        [ 0.85484455],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.71990439],\n",
       "        [ 0.44071987],\n",
       "        [-0.65661718],\n",
       "        [ 0.65243202],\n",
       "        [-0.15441227],\n",
       "        [-1.47505945],\n",
       "        [-1.31233626],\n",
       "        [-1.36284837],\n",
       "        [-0.9731258 ],\n",
       "        [ 1.17251358],\n",
       "        [ 0.06745409],\n",
       "        [ 0.79111309],\n",
       "        [ 0.95752173],\n",
       "        [ 1.02389832],\n",
       "        [-0.93421576],\n",
       "        [-1.27257595],\n",
       "        [ 2.31882714],\n",
       "        [-1.69674821],\n",
       "        [ 1.79145326],\n",
       "        [-1.48140483],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 2.3930071 ],\n",
       "        [-0.04757352],\n",
       "        [ 2.60360697],\n",
       "        [ 1.95558304],\n",
       "        [-1.01585161],\n",
       "        [ 1.3478531 ],\n",
       "        [-0.88754972],\n",
       "        [-1.18395997],\n",
       "        [-1.80667674],\n",
       "        [ 1.36173365],\n",
       "        [-0.10614827],\n",
       "        [-0.50376217],\n",
       "        [ 1.01183975],\n",
       "        [ 1.16610623],\n",
       "        [-1.04744733],\n",
       "        [-0.46162345],\n",
       "        [-0.37785317],\n",
       "        [-1.54221499],\n",
       "        [ 1.94865072],\n",
       "        [-1.62664699],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EQ_env.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7faf1c6ddc70>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = EQ_env.reset()\n",
    "done = False\n",
    "reward_list = []\n",
    "cum_reward = 0\n",
    "actions = list()\n",
    "\n",
    "while not done:\n",
    "    #action = agent.compute_action(state)\n",
    "    action = np.array([1,0,0,0,0])\n",
    "    state, reward, done, future_price = EQ_env.step(action)\n",
    "    cum_reward += reward\n",
    "    actions.append(action)\n",
    "    reward_list.append(reward)\n",
    "\n",
    "pd.Series(reward_list).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 1\n",
    "config[\"num_envs_per_worker\"] = 1\n",
    "config[\"rollout_fragment_length\"] = 20\n",
    "config[\"train_batch_size\"] = 5000\n",
    "config[\"batch_mode\"] = \"complete_episodes\"\n",
    "config['num_sgd_iter'] = 20\n",
    "config['sgd_minibatch_size'] = 200\n",
    "config['model']['dim'] = 200\n",
    "config['model']['conv_filters'] = [[32, [5, 1], 5], [32, [5, 1], 5], [4, [5, 1], 5]]\n",
    "config['num_cpus_per_worker'] = 2  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "config['env_config'] = {'pricing_source':'csvdata', \"tickers\": [\"BRK_A\", \"GE_\",\"GOLD_\", \"AAPL_\",\"GS_\",\"T_\",],\n",
    "          'lookback':200, 'start':'1995-01-02', 'end':'2018-12-31', 'features':[\"return_volatility_20\", \"return_skewness_20\", \"return_kurtosis_20\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_workers': 1,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'rollout_fragment_length': 20,\n",
       " 'batch_mode': 'complete_episodes',\n",
       " 'num_gpus': 0,\n",
       " 'train_batch_size': 5000,\n",
       " 'model': {'fcnet_hiddens': [256, 256],\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'conv_filters': [[32, [5, 1], 5], [32, [5, 1], 5], [4, [5, 1], 5]],\n",
       "  'conv_activation': 'relu',\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': True,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action_reward': False,\n",
       "  '_time_major': False,\n",
       "  'framestack': True,\n",
       "  'dim': 200,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None},\n",
       " 'optimizer': {},\n",
       " 'gamma': 0.99,\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env_config': {'pricing_source': 'csvdata',\n",
       "  'tickers': ['BRK_A', 'GE_', 'GOLD_', 'AAPL_', 'GS_', 'T_'],\n",
       "  'lookback': 200,\n",
       "  'start': '1995-01-02',\n",
       "  'end': '2018-12-31',\n",
       "  'features': ['return_volatility_20',\n",
       "   'return_skewness_20',\n",
       "   'return_kurtosis_20']},\n",
       " 'env': None,\n",
       " 'normalize_actions': False,\n",
       " 'clip_rewards': None,\n",
       " 'clip_actions': True,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'lr': 5e-05,\n",
       " 'monitor': False,\n",
       " 'log_level': 'WARN',\n",
       " 'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'framework': 'tf',\n",
       " 'eager_tracing': False,\n",
       " 'no_eager_on_workers': False,\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_num_episodes': 10,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config': {},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'sample_async': False,\n",
       " '_use_trajectory_view_api': False,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'compress_observations': False,\n",
       " 'collect_metrics_timeout': 180,\n",
       " 'metrics_smoothing_episodes': 100,\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'min_iter_time_s': 0,\n",
       " 'timesteps_per_iteration': 0,\n",
       " 'seed': None,\n",
       " 'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_cpus_per_worker': 2,\n",
       " 'num_gpus_per_worker': 0,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'memory': 0,\n",
       " 'object_store_memory': 0,\n",
       " 'memory_per_worker': 0,\n",
       " 'object_store_memory_per_worker': 0,\n",
       " 'input': 'sampler',\n",
       " 'input_evaluation': ['is', 'wis'],\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'multiagent': {'policies': {},\n",
       "  'policy_mapping_fn': None,\n",
       "  'policies_to_train': None,\n",
       "  'observation_fn': None,\n",
       "  'replay_mode': 'independent'},\n",
       " 'logger_config': None,\n",
       " 'replay_sequence_length': 1,\n",
       " 'use_critic': True,\n",
       " 'use_gae': True,\n",
       " 'lambda': 1.0,\n",
       " 'kl_coeff': 0.2,\n",
       " 'sgd_minibatch_size': 200,\n",
       " 'shuffle_sequences': True,\n",
       " 'num_sgd_iter': 20,\n",
       " 'lr_schedule': None,\n",
       " 'vf_share_layers': False,\n",
       " 'vf_loss_coeff': 1.0,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.3,\n",
       " 'vf_clip_param': 10.0,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.01,\n",
       " 'simple_optimizer': False,\n",
       " '_fake_gpus': False}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if agents can be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-22 10:17:18,772\tWARNING util.py:39 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "agent = PPOTrainer(config, Equitydaily)\n",
    "best_reward = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleagent/checkpoint_1/checkpoint-1\n",
      "-169.59557785100353\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    result = agent.train()\n",
    "    if result['episode_reward_mean'] > best_reward + 10:\n",
    "        path = agent.save('sampleagent')\n",
    "        print(path)\n",
    "        best_reward = result['episode_reward_mean']\n",
    "        print(best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.restore('sampleagent/checkpoint_1/checkpoint-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleagent/checkpoint_4/checkpoint-4\n",
      "-535.9323429076005\n",
      "sampleagent/checkpoint_5/checkpoint-5\n",
      "-526.1276376951023\n",
      "sampleagent/checkpoint_7/checkpoint-7\n",
      "-522.2019039406775\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    result = agent.train()\n",
    "    if result['episode_reward_mean'] > best_reward + 1:\n",
    "        path = agent.save('sampleagent')\n",
    "        print(path)\n",
    "        best_reward = result['episode_reward_mean']\n",
    "        print(best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episode_reward_max': -415.02074011362794,\n",
       " 'episode_reward_min': -633.5108483329875,\n",
       " 'episode_reward_mean': -522.2019039406775,\n",
       " 'episode_len_mean': 2627.0,\n",
       " 'episodes_this_iter': 2,\n",
       " 'policy_reward_min': {},\n",
       " 'policy_reward_max': {},\n",
       " 'policy_reward_mean': {},\n",
       " 'custom_metrics': {},\n",
       " 'hist_stats': {'episode_reward': [-539.1598334863469,\n",
       "   -469.06551439816803,\n",
       "   -562.9823075709035,\n",
       "   -523.5588877487897,\n",
       "   -570.4579153419675,\n",
       "   -549.8358615276551,\n",
       "   -633.5108483329875,\n",
       "   -415.02074011362794,\n",
       "   -460.29247088179636,\n",
       "   -571.7997117430767,\n",
       "   -502.9626815458952,\n",
       "   -470.85495214432393,\n",
       "   -480.83164749398276,\n",
       "   -560.4932828399646],\n",
       "  'episode_lengths': [2627,\n",
       "   2627,\n",
       "   2627,\n",
       "   2627,\n",
       "   2627,\n",
       "   2627,\n",
       "   2627,\n",
       "   2627,\n",
       "   2627,\n",
       "   2627,\n",
       "   2627,\n",
       "   2627,\n",
       "   2627,\n",
       "   2627]},\n",
       " 'sampler_perf': {'mean_env_wait_ms': 0.9928205776032585,\n",
       "  'mean_raw_obs_processing_ms': 0.09451218710168378,\n",
       "  'mean_inference_ms': 0.8205471140632769,\n",
       "  'mean_action_processing_ms': 0.08131409539686671},\n",
       " 'off_policy_estimator': {},\n",
       " 'num_healthy_workers': 1,\n",
       " 'timesteps_total': 36778,\n",
       " 'timers': {'sample_time_ms': 10442.3,\n",
       "  'sample_throughput': 503.146,\n",
       "  'load_time_ms': 54.26,\n",
       "  'load_throughput': 96830.171,\n",
       "  'learn_time_ms': 3356.799,\n",
       "  'learn_throughput': 1565.181,\n",
       "  'update_time_ms': 3.186},\n",
       " 'info': {'learner': {'default_policy': {'cur_kl_coeff': 0.01875000074505806,\n",
       "    'cur_lr': 4.999999873689376e-05,\n",
       "    'total_loss': 79.2426,\n",
       "    'policy_loss': -0.0148372855,\n",
       "    'vf_loss': 79.257355,\n",
       "    'vf_explained_var': -0.060537085,\n",
       "    'kl': 0.00481694,\n",
       "    'entropy': 7.091626,\n",
       "    'entropy_coeff': 0.0,\n",
       "    'model': {}}},\n",
       "  'num_steps_sampled': 36778,\n",
       "  'num_steps_trained': 36778},\n",
       " 'done': False,\n",
       " 'episodes_total': 14,\n",
       " 'training_iteration': 7,\n",
       " 'experiment_id': '3b5659148ebb4319ac2a426d9eee9432',\n",
       " 'date': '2020-11-15_22-32-51',\n",
       " 'timestamp': 1605479571,\n",
       " 'time_this_iter_s': 13.18719220161438,\n",
       " 'time_total_s': 97.1631236076355,\n",
       " 'pid': 171989,\n",
       " 'hostname': 'laplace',\n",
       " 'node_ip': '155.198.195.98',\n",
       " 'config': {'num_workers': 1,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'rollout_fragment_length': 20,\n",
       "  'batch_mode': 'complete_episodes',\n",
       "  'num_gpus': 0,\n",
       "  'train_batch_size': 5000,\n",
       "  'model': {'fcnet_hiddens': [256, 256],\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'conv_filters': [[16, [10, 1], 5], [16, [5, 1], 10]],\n",
       "   'conv_activation': 'relu',\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': True,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action_reward': False,\n",
       "   '_time_major': False,\n",
       "   'framestack': True,\n",
       "   'dim': 50,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None},\n",
       "  'optimizer': {},\n",
       "  'gamma': 0.99,\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env_config': {'pricing_source': 'csvdata',\n",
       "   'tickers': ['BRK', 'TLT', 'QQQ', 'GLD'],\n",
       "   'lookback': 50,\n",
       "   'start': '2008-01-02',\n",
       "   'end': '2018-12-31',\n",
       "   'features': ['volatility_20', 'skewness_20', 'kurtosis_20']},\n",
       "  'env': 'Equitydaily',\n",
       "  'normalize_actions': False,\n",
       "  'clip_rewards': None,\n",
       "  'clip_actions': True,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'lr': 5e-05,\n",
       "  'monitor': False,\n",
       "  'log_level': 'WARN',\n",
       "  'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'framework': 'tf',\n",
       "  'eager_tracing': False,\n",
       "  'no_eager_on_workers': False,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_num_episodes': 10,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'sample_async': False,\n",
       "  '_use_trajectory_view_api': False,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'compress_observations': False,\n",
       "  'collect_metrics_timeout': 180,\n",
       "  'metrics_smoothing_episodes': 100,\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'min_iter_time_s': 0,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'seed': None,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_cpus_per_worker': 2,\n",
       "  'num_gpus_per_worker': 0,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'memory': 0,\n",
       "  'object_store_memory': 0,\n",
       "  'memory_per_worker': 0,\n",
       "  'object_store_memory_per_worker': 0,\n",
       "  'input': 'sampler',\n",
       "  'input_evaluation': ['is', 'wis'],\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'multiagent': {'policies': {},\n",
       "   'policy_mapping_fn': None,\n",
       "   'policies_to_train': None,\n",
       "   'observation_fn': None,\n",
       "   'replay_mode': 'independent'},\n",
       "  'logger_config': None,\n",
       "  'replay_sequence_length': 1,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 1.0,\n",
       "  'kl_coeff': 0.2,\n",
       "  'sgd_minibatch_size': 200,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 20,\n",
       "  'lr_schedule': None,\n",
       "  'vf_share_layers': False,\n",
       "  'vf_loss_coeff': 1.0,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.3,\n",
       "  'vf_clip_param': 10.0,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.01,\n",
       "  'simple_optimizer': False,\n",
       "  '_fake_gpus': False},\n",
       " 'time_since_restore': 97.1631236076355,\n",
       " 'timesteps_since_restore': 0,\n",
       " 'iterations_since_restore': 7,\n",
       " 'perf': {'cpu_util_percent': 3.1526315789473682, 'ram_util_percent': 42.9}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.sac import SACTrainer, DEFAULT_CONFIG\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 1\n",
    "config[\"num_envs_per_worker\"] = 1\n",
    "\n",
    "config[\"rollout_fragment_length\"] = 10\n",
    "config[\"train_batch_size\"] = 50\n",
    "config[\"timesteps_per_iteration\"] = 10\n",
    "config[\"buffer_size\"] = 10000\n",
    "\n",
    "config[\"Q_model\"][\"fcnet_hiddens\"] = [10, 10]\n",
    "config[\"policy_model\"][\"fcnet_hiddens\"] = [10, 10]\n",
    "config[\"num_cpus_per_worker\"] = 2 \n",
    "config[\"env_config\"] = {\n",
    "    \"pricing_source\": \"csvdata\",\n",
    "    \"tickers\": [\"QQQ\", \"EEM\", \"TLT\", \"SHY\", \"GLD\", \"SLV\"],\n",
    "    \"lookback\": 1,\n",
    "    \"start\": \"2007-01-02\",\n",
    "    \"end\": \"2015-12-31\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train agent \n",
    "agent = SACTrainer(config, Equitydaily)\n",
    "best_reward = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    result = agent.train()\n",
    "    if result['episode_reward_mean'] > best_reward + 0.01:\n",
    "        path = agent.save('sampleagent')\n",
    "        print(path)\n",
    "        best_reward = result['episode_reward_mean']\n",
    "    print(result['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = PPOTrainer(config, Equitydaily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Equitydaily({'pricing_source':'Alpaca_Equity_daily', 'tickers':['SPY','QQQ','SHY','GLD','TLT','EEM'], 'lookback':50, 'start':'2011-01-02', 'end':'2020-12-31'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.restore('checkpoint_1087/checkpoint-1087')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "done = False\n",
    "reward_list = []\n",
    "cum_reward = 0\n",
    "actions = list()\n",
    "\n",
    "while not done:\n",
    "    #action = agent.compute_action(state)\n",
    "    action = np.array([0,0,0,0,0,0,1])\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    cum_reward += reward\n",
    "    actions.append(action)\n",
    "    reward_list.append(reward)\n",
    "\n",
    "pd.Series(env.log_return_series).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(reward_list).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run environment for RNN environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Equitydaily({'pricing_source':'Alpaca_Equity_daily', 'tickers':['SPY','QQQ'], 'lookback':50, 'start':'2018-01-02', 'end':'2020-12-31'})\n",
    "\n",
    "state = env.reset()\n",
    "done = False\n",
    "cum_reward = 0 \n",
    "actions = list()\n",
    "\n",
    "rnn_state = agent.get_policy().get_initial_state()\n",
    "\n",
    "while not done:\n",
    "    action, rnn_state, _ = agent.compute_action(state,rnn_state)\n",
    "    #action = np.array([1,-1])\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    cum_reward += reward\n",
    "    actions.append(actions)\n",
    "\n",
    "pd.Series(env.log_return_series).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_drawdown(pd.Series(env.log_return_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_return(pd.Series(env.log_return_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Equitydaily_v1(gym.Env):\n",
    "\n",
    "    def __init__(self,env_config):\n",
    "        \n",
    "        self.tickers = env_config['tickers']\n",
    "        self.lookback = env_config['lookback']\n",
    "        # Load price data, to be replaced by DataLoader class\n",
    "        raw_data = load_data(env_config['pricing_source'],env_config['tickers'],env_config['start'],env_config['end'])\n",
    "        # Set the trading dates, features and price data \n",
    "        self.dates = raw_data['dates']\n",
    "        self.fields = raw_data['fields']\n",
    "        self.pricedata = raw_data['pricedata']\n",
    "        self.featuredata = raw_data['data']\n",
    "        self.tcostdata = raw_data['tcost']\n",
    "        # Set up historical actions and rewards \n",
    "        self.n_assets = len(self.tickers) + 1\n",
    "        self.n_metrics = 2 \n",
    "        self.n_assets_fields = len(self.fields)\n",
    "        self.n_features = self.n_assets_fields * len(self.tickers) + self.n_assets + self.n_metrics # reward function\n",
    "        \n",
    "        # Set up action and observation space\n",
    "        # The last asset is cash \n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(self.tickers)+1,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf,\n",
    "                                            shape=(self.lookback,self.n_features), dtype=np.float32)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        ## Normalise action space \n",
    "        normalised_action = action / np.sum(np.abs(action))\n",
    "        \n",
    "        done = False\n",
    "        # Rebalance portfolio at close using return of the next date\n",
    "        next_day_log_return = self.pricedata[self.index,:]\n",
    "        # transaction cost \n",
    "        transaction_cost = self.transaction_cost(normalised_action,self.position_series[-1])\n",
    "        \n",
    "        # Rebalancing \n",
    "        self.position_series = np.append(self.position_series, [normalised_action], axis=0)\n",
    "        # Portfolio return \n",
    "        today_portfolio_return = np.sum(normalised_action[:-1] * next_day_log_return) + np.sum(transaction_cost)\n",
    "        self.log_return_series = np.append(self.log_return_series, [today_portfolio_return], axis=0)\n",
    "        \n",
    "        \n",
    "        # Calculate reward \n",
    "        # Need to cast log_return in pd series to use the functions in empyrical \n",
    "        live_days = self.index - self.lookback\n",
    "        burnin = 250\n",
    "        recent_series = pd.Series(self.log_return_series)[-100:]\n",
    "        whole_series = pd.Series(self.log_return_series)\n",
    "        if live_days > burnin: \n",
    "            self.metric = annual_return(whole_series) + 0.5* max_drawdown(whole_series)\n",
    "        else:\n",
    "            self.metric = annual_return(whole_series) + 0.5* max_drawdown(whole_series) *live_days / burnin\n",
    "        reward = self.metric - self.metric_series[-1]\n",
    "        #reward = self.metric\n",
    "        self.metric_series = np.append(self.metric_series, [self.metric], axis=0)\n",
    "        \n",
    "        # Check if the end of backtest\n",
    "        if self.index >= self.pricedata.shape[0]-2:\n",
    "            done = True\n",
    "            \n",
    "        # Prepare observation for next day\n",
    "        self.index += 1\n",
    "        self.observation = self.get_observation()\n",
    "            \n",
    "        return self.observation, reward, done, {'current_price':next_day_log_return}\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        self.log_return_series = np.zeros(shape=self.lookback)\n",
    "        self.metric_series = np.zeros(shape=self.lookback)\n",
    "        self.position_series = np.zeros(shape=(self.lookback,self.n_assets))\n",
    "        self.metric = 0                    \n",
    "        self.index = self.lookback\n",
    "        self.observation = self.get_observation()\n",
    "        return self.observation\n",
    "    \n",
    "    def get_observation(self):\n",
    "        # Can use simple moving average data here \n",
    "        price_lookback = self.featuredata[self.index-self.lookback:self.index,:]\n",
    "        metrics = np.vstack((self.log_return_series[self.index-self.lookback:self.index], \n",
    "                             self.metric_series[self.index-self.lookback:self.index])).transpose()\n",
    "        positions = self.position_series[self.index-self.lookback:self.index]\n",
    "        observation = np.concatenate((price_lookback, metrics, positions), axis=1)\n",
    "        return observation \n",
    "    \n",
    "    # 0.05% and spread to model t-cost for institutional portfolios \n",
    "    def transaction_cost(self,new_action,old_action,):\n",
    "        turnover = np.abs(new_action - old_action) \n",
    "        fees = 0.9995 - self.tcostdata[self.index,:]\n",
    "        tcost = turnover * np.log(fees)\n",
    "        return tcost "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
