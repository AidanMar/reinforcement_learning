{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import typing\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-02 09:49:41,617\tINFO services.py:1092 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.0.0.1',\n",
       " 'raylet_ip_address': '192.0.0.1',\n",
       " 'redis_address': '192.0.0.1:6379',\n",
       " 'object_store_address': '/rds/general/user/asm119/ephemeral/session_2020-12-02_09-49-39_385980_2802831/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/rds/general/user/asm119/ephemeral/session_2020-12-02_09-49-39_385980_2802831/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/rds/general/user/asm119/ephemeral/session_2020-12-02_09-49-39_385980_2802831',\n",
       " 'metrics_export_port': 56457,\n",
       " 'node_id': 'a2f34629866a860a759c85f028327f0e131fdf76'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "# Start up Ray. This must be done before we instantiate any RL agents.\n",
    "ray.init(num_cpus=10, ignore_reinit_error=True, log_to_driver=False,_temp_dir=\"/rds/general/user/asm119/ephemeral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tom_path = \"../Thomas/\"\n",
    "def load_data(\n",
    "    price_source: str, \n",
    "    tickers: typing.List[str],\n",
    "    start: datetime, \n",
    "    end: datetime, \n",
    "    features: typing.List[str],\n",
    "):\n",
    "    \"\"\"Returned price data to use in gym environment\"\"\"\n",
    "    # Load data\n",
    "    # Each dataframe will have columns date and a collection of fields\n",
    "    # TODO: DataLoader from mongoDB\n",
    "    # Raw price from DB, forward impute on the trading days for missing date\n",
    "    # calculate the features (log return, volatility)\n",
    "    if price_source in [\"csvdata\"]:\n",
    "        feature_df = []\n",
    "        for t in tickers:\n",
    "            df1 = pd.read_csv(tom_path + \"csvdata/{}.csv\".format(t))\n",
    "            df1['datetime'] = pd.to_datetime(df1['datetime'])\n",
    "            df1 = df1[(df1['datetime']>=start) & (df1['datetime']<=end)]\n",
    "            df1.set_index(\"datetime\",inplace=True)\n",
    "            selected_features = ['return','tcost'] + features\n",
    "            feature_df.append(df1[selected_features])\n",
    "            ref_df_columns = df1[selected_features].columns\n",
    "\n",
    "    # assume all the price_df are aligned and cleaned in the DataLoader\n",
    "    merged_df = pd.concat(feature_df, axis=1, join=\"outer\")\n",
    "    # Imputer missing values with zeros \n",
    "    price_tensor = merged_df['return'].fillna(0.0).values\n",
    "    tcost = merged_df['tcost'].fillna(0.0).values\n",
    "\n",
    "    return {\n",
    "        \"dates\": merged_df.index,\n",
    "        \"fields\": ref_df_columns,\n",
    "        \"data\": merged_df.fillna(0.0).values,\n",
    "        \"pricedata\": price_tensor,\n",
    "        \"tcost\": tcost,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.36998991e-02,  4.25369008e-05,  1.09934270e-02,\n",
       "        -9.14812793e-01, -2.61064489e-01, -3.01849936e-02,\n",
       "         1.03231135e-04,  1.16465557e-02, -1.10048552e+00,\n",
       "         5.96949184e-01],\n",
       "       [-5.94984959e-03,  4.27953952e-05,  1.09991806e-02,\n",
       "        -9.10788716e-01, -2.70376218e-01, -5.12061786e-03,\n",
       "         1.03745202e-04,  1.16723407e-02, -9.95452223e-01,\n",
       "         4.23777969e-01],\n",
       "       [-3.36369023e-02,  4.42928644e-05,  1.30807177e-02,\n",
       "        -9.16682320e-01, -2.54900342e-01, -3.36202334e-02,\n",
       "         0.00000000e+00,  1.37192261e-02, -9.68839072e-01,\n",
       "        -4.24718444e-02],\n",
       "       [-1.49229482e-02,  4.49216118e-05,  1.31754036e-02,\n",
       "        -7.10326792e-01, -5.75516042e-01, -2.49435926e-02,\n",
       "         0.00000000e+00,  1.45399702e-02, -7.26873145e-01,\n",
       "        -6.77999658e-01],\n",
       "       [ 4.29173814e-02,  4.30496362e-05,  1.66156842e-02,\n",
       "         3.64864054e-01,  7.49281745e-01,  5.01088321e-02,\n",
       "         1.04701078e-04,  1.85963149e-02,  4.85487538e-01,\n",
       "         1.00154483e+00],\n",
       "       [-2.83321867e-03,  4.31685733e-05,  1.66096621e-02,\n",
       "         3.97455884e-01,  7.71150320e-01, -1.03600456e-03,\n",
       "         1.04788850e-04,  1.85902709e-02,  5.00760488e-01,\n",
       "         1.01652457e+00],\n",
       "       [ 1.38321429e-02,  4.25731193e-05,  1.67197778e-02,\n",
       "         3.83285096e-01,  6.79796060e-01,  1.84858246e-02,\n",
       "         1.02848915e-04,  1.90479506e-02,  4.14326683e-01,\n",
       "         6.36670606e-01],\n",
       "       [-1.24574586e-02,  4.31053063e-05,  1.68749185e-02,\n",
       "         4.77305606e-01,  6.20829768e-01, -1.57944420e-02,\n",
       "         1.04525975e-04,  1.90924952e-02,  5.89737350e-01,\n",
       "         7.52217559e-01],\n",
       "       [-1.81948624e-02,  4.38962293e-05,  1.69719556e-02,\n",
       "         4.73712400e-01,  5.68503491e-01, -1.92043281e-02,\n",
       "         0.00000000e+00,  1.93833946e-02,  7.09832439e-01,\n",
       "         7.12169398e-01],\n",
       "       [ 5.24473794e-04,  4.38769690e-05,  1.69286653e-02,\n",
       "         5.03839482e-01,  6.22996147e-01,  3.15641285e-03,\n",
       "         1.06145844e-04,  1.93252157e-02,  6.05525569e-01,\n",
       "         6.52081021e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data('csvdata',['SPY','QQQ',], datetime(2010, 5, 4), datetime(2020, 12, 31), [\"volatility_20\", \"skewness_20\", \"kurtosis_20\"] ) ['data'][:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from empyrical import max_drawdown, alpha_beta, sharpe_ratio, annual_return\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "class Equitydaily(gym.Env):\n",
    "\n",
    "    def __init__(self,env_config):\n",
    "        \n",
    "        self.tickers = env_config['tickers']\n",
    "        self.lookback = env_config['lookback']\n",
    "        self.random_start = env_config['random_start']\n",
    "        self.trading_days = env_config['trading_days'] # Number of days the algorithm runs before resetting\n",
    "        # Load price data, to be replaced by DataLoader class\n",
    "        raw_data = load_data(env_config['pricing_source'],env_config['tickers'],env_config['start'],env_config['end'],env_config['features'])\n",
    "        # Set the trading dates, features and price data \n",
    "        self.dates = raw_data['dates']\n",
    "        self.fields = raw_data['fields']\n",
    "        self.pricedata = raw_data['pricedata']\n",
    "        self.featuredata = raw_data['data']\n",
    "        self.tcostdata = raw_data['tcost']\n",
    "        # Set up historical actions and rewards \n",
    "        self.n_assets = len(self.tickers) + 1\n",
    "        self.n_metrics = 2 \n",
    "        self.n_assets_fields = len(self.fields)\n",
    "        self.n_features = self.n_assets_fields * len(self.tickers) + self.n_assets + self.n_metrics # reward function\n",
    "        #self.n_features = self.n_assets_fields * len(self.tickers)\n",
    "        \n",
    "        # Set up action and observation space\n",
    "        # The last asset is cash \n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(self.tickers)+1,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf,\n",
    "                                            shape=(self.lookback,self.n_features,1), dtype=np.float32)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        # Trade every 10 days \n",
    "        # Normalise action space \n",
    "        if (self.index - self.start_index) % 10 == 0:\n",
    "            normalised_action = action / np.sum(np.abs(action))\n",
    "            self.actions = normalised_action\n",
    "        \n",
    "        done = False\n",
    "        # Rebalance portfolio at close using return of the next date\n",
    "        next_day_log_return = self.pricedata[self.index,:]\n",
    "        # transaction cost \n",
    "        transaction_cost = self.transaction_cost(self.actions,self.position_series[-1])\n",
    "        \n",
    "        # Rebalancing \n",
    "        self.position_series = np.append(self.position_series, [self.actions], axis=0)\n",
    "        # Portfolio return \n",
    "        today_portfolio_return = np.sum(self.actions[:-1] * next_day_log_return) + np.sum(transaction_cost)\n",
    "        self.log_return_series = np.append(self.log_return_series, [today_portfolio_return], axis=0)\n",
    "        \n",
    "        \n",
    "        # Calculate reward \n",
    "        # Need to cast log_return in pd series to use the functions in empyrical \n",
    "        recent_series = pd.Series(self.log_return_series)[-100:]\n",
    "        #print(recent_series)\n",
    "        rolling_volatility = np.std(recent_series)\n",
    "        self.metric = today_portfolio_return / rolling_volatility \n",
    "        reward = self.metric\n",
    "        self.metric_series = np.append(self.metric_series, [self.metric], axis=0)\n",
    "        \n",
    "        # Check if the end of backtest\n",
    "        if self.trading_days is None:\n",
    "            done = self.index >= self.pricedata.shape[0]-2\n",
    "        else:\n",
    "            done = (self.index - self.start_index) >= self.trading_days\n",
    "            \n",
    "        # Prepare observation for next day\n",
    "        self.index += 1\n",
    "        self.observation = self.get_observation()\n",
    "            \n",
    "        return self.observation, reward, done, {}\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        self.log_return_series = np.zeros(shape=self.lookback)\n",
    "        self.metric_series = np.zeros(shape=self.lookback)\n",
    "        self.position_series = np.zeros(shape=(self.lookback,self.n_assets))\n",
    "        self.metric = 0           \n",
    "        if self.random_start:\n",
    "            num_days = len(self.dates)      \n",
    "            self.start_index = np.random.randint(self.lookback, num_days - self.trading_days)\n",
    "            self.index = self.start_index\n",
    "        else:\n",
    "            self.start_index = self.lookback\n",
    "            self.index = self.lookback\n",
    "        self.actions = np.zeros(shape=self.n_assets)\n",
    "        self.observation = self.get_observation()\n",
    "        return self.observation\n",
    "    \n",
    "    def get_observation(self):\n",
    "        # Can use simple moving average data here \n",
    "        last_lookback_day = self.index - self.start_index\n",
    "        price_lookback = self.featuredata[last_lookback_day:last_lookback_day + self.lookback,:]\n",
    "        metrics = np.vstack((self.log_return_series[last_lookback_day:last_lookback_day + self.lookback], \n",
    "                             self.metric_series[last_lookback_day:last_lookback_day + self.lookback])).transpose()\n",
    "        positions = self.position_series[last_lookback_day:last_lookback_day + self.lookback]\n",
    "        scaler = StandardScaler()\n",
    "        price_lookback = scaler.fit_transform(price_lookback)\n",
    "        observation = np.concatenate((price_lookback, metrics, positions), axis=1)\n",
    "        return observation.reshape((observation.shape[0], observation.shape[1], 1))\n",
    "    \n",
    "    # 0.05% and spread to model t-cost for institutional portfolios \n",
    "    def transaction_cost(self, new_action, old_action):\n",
    "        turnover = np.abs(new_action - old_action) \n",
    "        fees = 0.9995 - self.tcostdata[self.index,:]\n",
    "        fees = np.array(list(fees) + [0.9995])\n",
    "        tcost = turnover * np.log(fees)\n",
    "        return tcost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'pricing_source':'csvdata', 'tickers':['BRK','TLT','QQQ','GLD',], \n",
    "          'lookback':100, 'start':'2008-01-02', 'end':'2018-12-31', 'features':[\"volatility_20\", \"skewness_20\", \"kurtosis_20\"], 'random_start': True, 'trading_days':600}\n",
    "EQ_env = Equitydaily(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set the training env to use random starts as made by Pavol, 506 trading days (2 years of trading) and only before the year 2014. Everything after that will be used as a dev set.\n",
    "We use a 60 day look back as used here https://www.oxford-man.ox.ac.uk/wp-content/uploads/2020/06/Deep-Reinforcement-Learning-for-Trading.pdf.\n",
    "This isn't gospel. It's a starting point\n",
    "\n",
    "\"\"\"\n",
    "train_agent_config = {'pricing_source':'csvdata', 'tickers':['BRK','TLT','QQQ','GLD',], \n",
    "          'lookback':60, 'start':'2008-01-02', 'end':'2013-12-31', 'features':[\"volatility_20\", \"skewness_20\", \"kurtosis_20\"], 'random_start': True, 'trading_days':506}\n",
    "train_env = Equitydaily(train_agent_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 1\n",
    "config[\"num_envs_per_worker\"] = 1\n",
    "config[\"rollout_fragment_length\"] = 20\n",
    "config[\"train_batch_size\"] = 5000\n",
    "config[\"batch_mode\"] = \"complete_episodes\"\n",
    "config['num_sgd_iter'] = 20\n",
    "config['sgd_minibatch_size'] = 200\n",
    "config['model']['dim'] = 200\n",
    "config['model']['conv_filters'] = [[32, [5, 1], 5], [32, [5, 1], 5], [4, [5, 1], 5]]\n",
    "config['num_cpus_per_worker'] = 2  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "config['env_config'] = train_agent_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model using only the training data\n",
    "\n",
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 5\n",
    "config[\"num_envs_per_worker\"] = 1\n",
    "config[\"rollout_fragment_length\"] = 20\n",
    "config[\"train_batch_size\"] = 1200\n",
    "config[\"batch_mode\"] = \"complete_episodes\"\n",
    "config['num_sgd_iter'] = 20\n",
    "config['sgd_minibatch_size'] = 200\n",
    "config['model']['dim'] = 200\n",
    "config['model']['conv_filters'] = [[32, [5, 1], 5], [32, [5, 1], 5], [4, [5, 1], 5]]\n",
    "config['num_cpus_per_worker'] = 2  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "config['env_config'] = train_agent_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RayTaskError(ValueError)",
     "evalue": "\u001b[36mray::RolloutWorker.foreach_policy()\u001b[39m (pid=2805496, ip=192.0.0.1)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1812, in _create_c_op\n    c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 5 from 3 for '{{node default_policy/conv3/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 5, 5, 1], use_cudnn_on_gpu=true](default_policy/conv2/Relu, default_policy/conv3/Conv2D/ReadVariableOp)' with input shapes: [?,3,2,32], [5,1,32,4].\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::RolloutWorker.foreach_policy()\u001b[39m (pid=2805496, ip=192.0.0.1)\n  File \"python/ray/_raylet.pyx\", line 443, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 477, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 481, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 454, in __init__\n    self._build_policy_map(policy_dict, policy_config)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1059, in _build_policy_map\n    policy_map[name] = cls(obs_space, act_space, merged_conf)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/policy/tf_policy_template.py\", line 221, in __init__\n    obs_include_prev_action_reward=obs_include_prev_action_reward)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 203, in __init__\n    framework=\"tf\")\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/models/catalog.py\", line 398, in get_model_v2\n    name, **model_kwargs)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/models/tf/visionnet.py\", line 69, in __init__\n    name=\"conv{}\".format(len(filters)))(last_layer)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 776, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 247, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1017, in convolution_v2\n    name=name)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1147, in convolution_internal\n    name=name)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 2591, in _conv2d_expanded_batch\n    name=name)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 979, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3485, in _create_op_internal\n    op_def=op_def)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1975, in __init__\n    control_input_ops, op_def)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1815, in _create_c_op\n    raise ValueError(str(e))\nValueError: Negative dimension size caused by subtracting 5 from 3 for '{{node default_policy/conv3/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 5, 5, 1], use_cudnn_on_gpu=true](default_policy/conv2/Relu, default_policy/conv3/Conv2D/ReadVariableOp)' with input shapes: [?,3,2,32], [5,1,32,4].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(ValueError)\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-3d033f462e9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPOTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEquitydaily\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, env, logger_creator)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         def _init(self, config: TrainerConfigDict,\n",
      "\u001b[0;32m~/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, env, logger_creator)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mlogger_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_logger_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/tune/trainable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, logger_creator)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0msetup_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msetup_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mSETUP_TIME_THRESHOLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mget_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;31m# Evaluation setup.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, config, env_creator)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mpolicy_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_policy_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 num_workers=self.config[\"num_workers\"])\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_plan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_plan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_exec_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_plan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36m_make_workers\u001b[0;34m(self, env_creator, validate_env, policy_class, config, num_workers)\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mtrainer_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             logdir=self.logdir)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mDeveloperAPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_creator, validate_env, policy_class, trainer_config, num_workers, logdir, _setup)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 remote_spaces = ray.get(self.remote_workers(\n\u001b[1;32m     80\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeach_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     lambda p, pid: (pid, p.observation_space, p.action_space)))\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0mspaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mremote_spaces\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1450\u001b[0m                     \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_object_store_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayTaskError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1452\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_instanceof_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1453\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayTaskError(ValueError)\u001b[0m: \u001b[36mray::RolloutWorker.foreach_policy()\u001b[39m (pid=2805496, ip=192.0.0.1)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1812, in _create_c_op\n    c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 5 from 3 for '{{node default_policy/conv3/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 5, 5, 1], use_cudnn_on_gpu=true](default_policy/conv2/Relu, default_policy/conv3/Conv2D/ReadVariableOp)' with input shapes: [?,3,2,32], [5,1,32,4].\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::RolloutWorker.foreach_policy()\u001b[39m (pid=2805496, ip=192.0.0.1)\n  File \"python/ray/_raylet.pyx\", line 443, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 477, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 481, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 454, in __init__\n    self._build_policy_map(policy_dict, policy_config)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1059, in _build_policy_map\n    policy_map[name] = cls(obs_space, act_space, merged_conf)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/policy/tf_policy_template.py\", line 221, in __init__\n    obs_include_prev_action_reward=obs_include_prev_action_reward)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 203, in __init__\n    framework=\"tf\")\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/models/catalog.py\", line 398, in get_model_v2\n    name, **model_kwargs)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/models/tf/visionnet.py\", line 69, in __init__\n    name=\"conv{}\".format(len(filters)))(last_layer)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 776, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 247, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1017, in convolution_v2\n    name=name)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1147, in convolution_internal\n    name=name)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 2591, in _conv2d_expanded_batch\n    name=name)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 979, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3485, in _create_op_internal\n    op_def=op_def)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1975, in __init__\n    control_input_ops, op_def)\n  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1815, in _create_c_op\n    raise ValueError(str(e))\nValueError: Negative dimension size caused by subtracting 5 from 3 for '{{node default_policy/conv3/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 5, 5, 1], use_cudnn_on_gpu=true](default_policy/conv2/Relu, default_policy/conv3/Conv2D/ReadVariableOp)' with input shapes: [?,3,2,32], [5,1,32,4]."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-02 10:23:20,549\tERROR worker.py:1037 -- Possible unhandled error from worker: \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=2805682, ip=192.0.0.1)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 5 from 3 for '{{node default_policy/conv3/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 5, 5, 1], use_cudnn_on_gpu=true](default_policy/conv2/Relu, default_policy/conv3/Conv2D/ReadVariableOp)' with input shapes: [?,3,2,32], [5,1,32,4].\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=2805682, ip=192.0.0.1)\n",
      "  File \"python/ray/_raylet.pyx\", line 477, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 481, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 454, in __init__\n",
      "    self._build_policy_map(policy_dict, policy_config)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1059, in _build_policy_map\n",
      "    policy_map[name] = cls(obs_space, act_space, merged_conf)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/policy/tf_policy_template.py\", line 221, in __init__\n",
      "    obs_include_prev_action_reward=obs_include_prev_action_reward)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 203, in __init__\n",
      "    framework=\"tf\")\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/models/catalog.py\", line 398, in get_model_v2\n",
      "    name, **model_kwargs)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/models/tf/visionnet.py\", line 69, in __init__\n",
      "    name=\"conv{}\".format(len(filters)))(last_layer)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 776, in __call__\n",
      "    outputs = call_fn(cast_inputs, *args, **kwargs)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 247, in call\n",
      "    outputs = self._convolution_op(inputs, self.kernel)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1017, in convolution_v2\n",
      "    name=name)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1147, in convolution_internal\n",
      "    name=name)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 2591, in _conv2d_expanded_batch\n",
      "    name=name)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 979, in conv2d\n",
      "    data_format=data_format, dilations=dilations, name=name)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n",
      "    attrs=attr_protos, op_def=op_def)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3485, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1975, in __init__\n",
      "    control_input_ops, op_def)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1815, in _create_c_op\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Negative dimension size caused by subtracting 5 from 3 for '{{node default_policy/conv3/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 5, 5, 1], use_cudnn_on_gpu=true](default_policy/conv2/Relu, default_policy/conv3/Conv2D/ReadVariableOp)' with input shapes: [?,3,2,32], [5,1,32,4].\n",
      "2020-12-02 10:23:20,551\tERROR worker.py:1037 -- Possible unhandled error from worker: \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=2805683, ip=192.0.0.1)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 5 from 3 for '{{node default_policy/conv3/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 5, 5, 1], use_cudnn_on_gpu=true](default_policy/conv2/Relu, default_policy/conv3/Conv2D/ReadVariableOp)' with input shapes: [?,3,2,32], [5,1,32,4].\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=2805683, ip=192.0.0.1)\n",
      "  File \"python/ray/_raylet.pyx\", line 477, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 481, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 454, in __init__\n",
      "    self._build_policy_map(policy_dict, policy_config)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1059, in _build_policy_map\n",
      "    policy_map[name] = cls(obs_space, act_space, merged_conf)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/policy/tf_policy_template.py\", line 221, in __init__\n",
      "    obs_include_prev_action_reward=obs_include_prev_action_reward)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 203, in __init__\n",
      "    framework=\"tf\")\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/models/catalog.py\", line 398, in get_model_v2\n",
      "    name, **model_kwargs)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/models/tf/visionnet.py\", line 69, in __init__\n",
      "    name=\"conv{}\".format(len(filters)))(last_layer)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 776, in __call__\n",
      "    outputs = call_fn(cast_inputs, *args, **kwargs)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 247, in call\n",
      "    outputs = self._convolution_op(inputs, self.kernel)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1017, in convolution_v2\n",
      "    name=name)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1147, in convolution_internal\n",
      "    name=name)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 2591, in _conv2d_expanded_batch\n",
      "    name=name)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 979, in conv2d\n",
      "    data_format=data_format, dilations=dilations, name=name)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n",
      "    attrs=attr_protos, op_def=op_def)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3485, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1975, in __init__\n",
      "    control_input_ops, op_def)\n",
      "  File \"/rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1815, in _create_c_op\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Negative dimension size caused by subtracting 5 from 3 for '{{node default_policy/conv3/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 5, 5, 1], use_cudnn_on_gpu=true](default_policy/conv2/Relu, default_policy/conv3/Conv2D/ReadVariableOp)' with input shapes: [?,3,2,32], [5,1,32,4].\n"
     ]
    }
   ],
   "source": [
    "agent = PPOTrainer(config, Equitydaily)\n",
    "best_reward = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-88c4b9eca2a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'episode_reward_mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_reward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./sampleagent2/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(10)):\n",
    "    result = agent.train()\n",
    "    if result['episode_reward_mean'] > best_reward + 10:\n",
    "        path = agent.save('./sampleagent2/')\n",
    "        print(path)\n",
    "        best_reward = result['episode_reward_mean']\n",
    "        print(best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 27, 1), 27)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EQ_env.observation.shape, EQ_env.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.05037815259212\n"
     ]
    }
   ],
   "source": [
    "EQ_env.reset()\n",
    "_, rw, _, _ = EQ_env.step([ 0.4612986,  -0.3883527,  -0.45688114, -0.06747285, -0.1717046])\n",
    "print(rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.96203294],\n",
       "        [ 0.38927695],\n",
       "        [ 1.30878227],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.92275479],\n",
       "        [ 0.9387753 ],\n",
       "        [ 1.11769825],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.04201546],\n",
       "        [ 0.53240954],\n",
       "        [ 1.08120239],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.20326979],\n",
       "        [-0.30100075],\n",
       "        [ 0.91832445],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.95157447],\n",
       "        [-0.19321166],\n",
       "        [ 0.62708665],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.50030785],\n",
       "        [-0.3025445 ],\n",
       "        [ 0.6640653 ],\n",
       "        ...,\n",
       "        [-0.29558014],\n",
       "        [-0.04365169],\n",
       "        [-0.11108462]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EQ_env.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = EQ_env.reset()\n",
    "done = False\n",
    "reward_list = []\n",
    "cum_reward = 0\n",
    "actions = list()\n",
    "\n",
    "while not done:\n",
    "    #action = agent.compute_action(state)\n",
    "    action = np.array([1,0,0,0,0])\n",
    "    state, reward, done, future_price = EQ_env.step(action)\n",
    "    cum_reward += reward\n",
    "    actions.append(action)\n",
    "    reward_list.append(reward)\n",
    "\n",
    "pd.Series(reward_list).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = EQ_env.reset()\n",
    "done = False\n",
    "reward_list = []\n",
    "cum_reward = 0\n",
    "actions = list()\n",
    "\n",
    "while not done:\n",
    "    #action = agent.compute_action(state)\n",
    "    action = np.array([1,0,0,0,0])\n",
    "    state, reward, done, future_price = EQ_env.step(action)\n",
    "    cum_reward += reward\n",
    "    actions.append(action)\n",
    "    reward_list.append(reward)\n",
    "\n",
    "pd.Series(reward_list).cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 5\n",
    "config[\"num_envs_per_worker\"] = 1\n",
    "config[\"rollout_fragment_length\"] = 20\n",
    "config[\"train_batch_size\"] = 1200\n",
    "config[\"batch_mode\"] = \"complete_episodes\"\n",
    "config['num_sgd_iter'] = 20\n",
    "config['sgd_minibatch_size'] = 200\n",
    "config['model']['dim'] = 200\n",
    "config['model']['conv_filters'] = [[32, [5, 1], 5], [32, [5, 1], 5], [4, [5, 1], 5]]\n",
    "config['num_cpus_per_worker'] = 2  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "config['env_config'] = {'pricing_source':'csvdata', \"tickers\": [\"BRK_A\", \"GE_\",\"GOLD_\", \"AAPL_\",\"GS_\",\"T_\",],\n",
    "          'lookback':200, 'start':'1995-01-02', 'end':'2018-12-31', 'features':[\"return_volatility_20\", \"return_skewness_20\", \"return_kurtosis_20\"],\n",
    "          'random_start': True, 'trading_days': 600}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_workers': 5,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'create_env_on_driver': False,\n",
       " 'rollout_fragment_length': 20,\n",
       " 'batch_mode': 'complete_episodes',\n",
       " 'num_gpus': 0,\n",
       " 'train_batch_size': 1200,\n",
       " 'model': {'fcnet_hiddens': [256, 256],\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'conv_filters': [[32, [5, 1], 5], [32, [5, 1], 5], [4, [5, 1], 5]],\n",
       "  'conv_activation': 'relu',\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': True,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action_reward': False,\n",
       "  '_time_major': False,\n",
       "  'framestack': True,\n",
       "  'dim': 200,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None},\n",
       " 'optimizer': {},\n",
       " 'gamma': 0.99,\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env_config': {'pricing_source': 'csvdata',\n",
       "  'tickers': ['BRK_A', 'GE_', 'GOLD_', 'AAPL_', 'GS_', 'T_'],\n",
       "  'lookback': 200,\n",
       "  'start': '1995-01-02',\n",
       "  'end': '2018-12-31',\n",
       "  'features': ['return_volatility_20',\n",
       "   'return_skewness_20',\n",
       "   'return_kurtosis_20'],\n",
       "  'random_start': True,\n",
       "  'trading_days': 600},\n",
       " 'env': None,\n",
       " 'normalize_actions': False,\n",
       " 'clip_rewards': None,\n",
       " 'clip_actions': True,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'lr': 5e-05,\n",
       " 'monitor': False,\n",
       " 'log_level': 'WARN',\n",
       " 'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'framework': 'tf',\n",
       " 'eager_tracing': False,\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_num_episodes': 10,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config': {},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'sample_async': False,\n",
       " '_use_trajectory_view_api': True,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'compress_observations': False,\n",
       " 'collect_metrics_timeout': 180,\n",
       " 'metrics_smoothing_episodes': 100,\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'min_iter_time_s': 0,\n",
       " 'timesteps_per_iteration': 0,\n",
       " 'seed': None,\n",
       " 'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_cpus_per_worker': 2,\n",
       " 'num_gpus_per_worker': 0,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'memory': 0,\n",
       " 'object_store_memory': 0,\n",
       " 'memory_per_worker': 0,\n",
       " 'object_store_memory_per_worker': 0,\n",
       " 'input': 'sampler',\n",
       " 'input_evaluation': ['is', 'wis'],\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'multiagent': {'policies': {},\n",
       "  'policy_mapping_fn': None,\n",
       "  'policies_to_train': None,\n",
       "  'observation_fn': None,\n",
       "  'replay_mode': 'independent'},\n",
       " 'logger_config': None,\n",
       " 'replay_sequence_length': 1,\n",
       " 'use_critic': True,\n",
       " 'use_gae': True,\n",
       " 'lambda': 1.0,\n",
       " 'kl_coeff': 0.2,\n",
       " 'sgd_minibatch_size': 200,\n",
       " 'shuffle_sequences': True,\n",
       " 'num_sgd_iter': 20,\n",
       " 'lr_schedule': None,\n",
       " 'vf_share_layers': False,\n",
       " 'vf_loss_coeff': 1.0,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.3,\n",
       " 'vf_clip_param': 10.0,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.01,\n",
       " 'simple_optimizer': False,\n",
       " '_fake_gpus': False}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if agents can be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-01 21:29:20,343\tINFO trainer.py:592 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2020-12-01 21:29:20,344\tINFO trainer.py:1065 -- `_use_trajectory_view_api` only supported for PyTorch so far! Will run w/o.\n",
      "2020-12-01 21:29:20,345\tINFO trainer.py:619 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2020-12-01 21:29:37,701\tINFO trainable.py:255 -- Trainable.setup took 17.361 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2020-12-01 21:29:37,704\tWARNING util.py:40 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "agent = PPOTrainer(config, Equitydaily)\n",
    "best_reward = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /rds/general/user/asm119/home/anaconda3/envs/reinforcement/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:877: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:09<48:49,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleagent/checkpoint_1/checkpoint-1\n",
      "-14.078456598052933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/300 [00:18<47:15,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleagent/checkpoint_2/checkpoint-2\n",
      "-3.732739231450013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 190/300 [28:55<16:28,  8.98s/it]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(300)):\n",
    "    result = agent.train()\n",
    "    if result['episode_reward_mean'] > best_reward + 10:\n",
    "        path = agent.save('sampleagent')\n",
    "        print(path)\n",
    "        best_reward = result['episode_reward_mean']\n",
    "        print(best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-24 18:16:19,141\tINFO trainable.py:482 -- Restored on 192.168.0.101 from checkpoint: sampleagent/checkpoint_1/checkpoint-1\n",
      "2020-11-24 18:16:19,142\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 24.549320936203003, '_episodes_total': 9}\n"
     ]
    }
   ],
   "source": [
    "agent.restore('sampleagent/checkpoint_1/checkpoint-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleagent/checkpoint_2/checkpoint-2\n",
      "-18.499785088445154\n",
      "sampleagent/checkpoint_3/checkpoint-3\n",
      "-16.556459086976048\n",
      "sampleagent/checkpoint_4/checkpoint-4\n",
      "-14.630928403378638\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    result = agent.train()\n",
    "    if result['episode_reward_mean'] > best_reward + 1:\n",
    "        path = agent.save('sampleagent')\n",
    "        print(path)\n",
    "        best_reward = result['episode_reward_mean']\n",
    "        print(best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episode_reward_max': 52.77934555607334,\n",
       " 'episode_reward_min': -86.04378430659364,\n",
       " 'episode_reward_mean': -18.523488700115685,\n",
       " 'episode_len_mean': 601.0,\n",
       " 'episodes_this_iter': 9,\n",
       " 'policy_reward_min': {},\n",
       " 'policy_reward_max': {},\n",
       " 'policy_reward_mean': {},\n",
       " 'custom_metrics': {},\n",
       " 'hist_stats': {'episode_reward': [-45.6825668696604,\n",
       "   -10.03960208396772,\n",
       "   -86.04378430659364,\n",
       "   -17.20824320402023,\n",
       "   9.652539580057784,\n",
       "   -31.748727861143124,\n",
       "   -46.54041751196004,\n",
       "   -73.66879208983079,\n",
       "   -47.84958915896191,\n",
       "   -63.55823822770892,\n",
       "   -14.381210230459878,\n",
       "   -2.019125434167244,\n",
       "   -21.15038879249259,\n",
       "   -50.66122997210185,\n",
       "   -51.34743964490648,\n",
       "   9.509088603245639,\n",
       "   -39.49717156868493,\n",
       "   -39.158988309216575,\n",
       "   -6.857061755878346,\n",
       "   52.77934555607334,\n",
       "   -42.36841265278894,\n",
       "   -33.95732898670692,\n",
       "   35.229035199981965,\n",
       "   -84.7391826807767,\n",
       "   1.2101442723187028,\n",
       "   -13.324725917295487,\n",
       "   -33.97551246279332,\n",
       "   -13.822189658401095,\n",
       "   16.611751221895165,\n",
       "   -52.65329252650407,\n",
       "   8.873974529577376,\n",
       "   -25.62587588102242,\n",
       "   -36.02832254919572,\n",
       "   8.721919388772468,\n",
       "   -46.00308343815432,\n",
       "   38.6993245293719,\n",
       "   12.781451950995663,\n",
       "   -34.82709280331788,\n",
       "   -59.09195613142421,\n",
       "   -4.565612405982268,\n",
       "   0.12071444574522805,\n",
       "   -14.88139261284083,\n",
       "   31.370610428057113,\n",
       "   -16.61518236870877,\n",
       "   -10.829870245642317,\n",
       "   -20.30676271772501,\n",
       "   -44.65692102060569,\n",
       "   -31.853626972199123,\n",
       "   -29.789199258218414,\n",
       "   -26.110634208944038,\n",
       "   1.8132573073631992,\n",
       "   31.683301103043327,\n",
       "   29.544203125980772,\n",
       "   27.317131620403774,\n",
       "   -11.03267872016328,\n",
       "   -35.87237385557684,\n",
       "   -22.96376515733498,\n",
       "   7.507059756839339,\n",
       "   -16.280279132790653,\n",
       "   -11.475589190356144,\n",
       "   -33.84438714982256,\n",
       "   -58.7024644407639,\n",
       "   23.20565144079971],\n",
       "  'episode_lengths': [601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601,\n",
       "   601]},\n",
       " 'sampler_perf': {'mean_env_wait_ms': 0.9942217810868244,\n",
       "  'mean_raw_obs_processing_ms': 0.18674279250673886,\n",
       "  'mean_inference_ms': 0.6311225609268525,\n",
       "  'mean_action_processing_ms': 0.07442045425743668},\n",
       " 'off_policy_estimator': {},\n",
       " 'num_healthy_workers': 1,\n",
       " 'timesteps_total': 32454,\n",
       " 'timers': {'sample_time_ms': 10463.033,\n",
       "  'sample_throughput': 516.963,\n",
       "  'load_time_ms': 286.016,\n",
       "  'load_throughput': 18911.524,\n",
       "  'learn_time_ms': 11276.592,\n",
       "  'learn_throughput': 479.666,\n",
       "  'update_time_ms': 2.517},\n",
       " 'info': {'learner': {'default_policy': {'cur_kl_coeff': 0.00937500037252903,\n",
       "    'cur_lr': 4.999999873689376e-05,\n",
       "    'total_loss': 49.262215,\n",
       "    'policy_loss': -0.018855443,\n",
       "    'vf_loss': 49.281033,\n",
       "    'vf_explained_var': -0.0014109038,\n",
       "    'kl': 0.0036750787,\n",
       "    'entropy': 10.056853,\n",
       "    'entropy_coeff': 0.0,\n",
       "    'model': {}}},\n",
       "  'num_steps_sampled': 32454,\n",
       "  'num_steps_trained': 32454},\n",
       " 'done': False,\n",
       " 'episodes_total': 54,\n",
       " 'training_iteration': 6,\n",
       " 'experiment_id': 'ef7c90146df249558e21c43df610d138',\n",
       " 'date': '2020-11-24_18-18-12',\n",
       " 'timestamp': 1606238292,\n",
       " 'time_this_iter_s': 21.24334979057312,\n",
       " 'time_total_s': 134.85556650161743,\n",
       " 'pid': 20930,\n",
       " 'hostname': 'Pavols-MacBook-Pro.local',\n",
       " 'node_ip': '192.168.0.101',\n",
       " 'config': {'num_workers': 1,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'rollout_fragment_length': 20,\n",
       "  'batch_mode': 'complete_episodes',\n",
       "  'num_gpus': 0,\n",
       "  'train_batch_size': 5000,\n",
       "  'model': {'fcnet_hiddens': [256, 256],\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'conv_filters': [[32, [5, 1], 5], [32, [5, 1], 5], [4, [5, 1], 5]],\n",
       "   'conv_activation': 'relu',\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': True,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action_reward': False,\n",
       "   '_time_major': False,\n",
       "   'framestack': True,\n",
       "   'dim': 200,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None},\n",
       "  'optimizer': {},\n",
       "  'gamma': 0.99,\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env_config': {'pricing_source': 'csvdata',\n",
       "   'tickers': ['BRK_A', 'GE_', 'GOLD_', 'AAPL_', 'GS_', 'T_'],\n",
       "   'lookback': 200,\n",
       "   'start': '1995-01-02',\n",
       "   'end': '2018-12-31',\n",
       "   'features': ['return_volatility_20',\n",
       "    'return_skewness_20',\n",
       "    'return_kurtosis_20'],\n",
       "   'random_start': True,\n",
       "   'trading_days': 600},\n",
       "  'env': 'Equitydaily',\n",
       "  'normalize_actions': False,\n",
       "  'clip_rewards': None,\n",
       "  'clip_actions': True,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'lr': 5e-05,\n",
       "  'monitor': False,\n",
       "  'log_level': 'WARN',\n",
       "  'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'framework': 'tf',\n",
       "  'eager_tracing': False,\n",
       "  'no_eager_on_workers': False,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_num_episodes': 10,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'sample_async': False,\n",
       "  '_use_trajectory_view_api': False,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'compress_observations': False,\n",
       "  'collect_metrics_timeout': 180,\n",
       "  'metrics_smoothing_episodes': 100,\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'min_iter_time_s': 0,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'seed': None,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_cpus_per_worker': 2,\n",
       "  'num_gpus_per_worker': 0,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'memory': 0,\n",
       "  'object_store_memory': 0,\n",
       "  'memory_per_worker': 0,\n",
       "  'object_store_memory_per_worker': 0,\n",
       "  'input': 'sampler',\n",
       "  'input_evaluation': ['is', 'wis'],\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'multiagent': {'policies': {},\n",
       "   'policy_mapping_fn': None,\n",
       "   'policies_to_train': None,\n",
       "   'observation_fn': None,\n",
       "   'replay_mode': 'independent'},\n",
       "  'logger_config': None,\n",
       "  'replay_sequence_length': 1,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 1.0,\n",
       "  'kl_coeff': 0.2,\n",
       "  'sgd_minibatch_size': 200,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 20,\n",
       "  'lr_schedule': None,\n",
       "  'vf_share_layers': False,\n",
       "  'vf_loss_coeff': 1.0,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.3,\n",
       "  'vf_clip_param': 10.0,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.01,\n",
       "  'simple_optimizer': False,\n",
       "  '_fake_gpus': False},\n",
       " 'time_since_restore': 110.30624556541443,\n",
       " 'timesteps_since_restore': 0,\n",
       " 'iterations_since_restore': 5,\n",
       " 'perf': {'cpu_util_percent': 34.0, 'ram_util_percent': 73.68333333333335}}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.sac import SACTrainer, DEFAULT_CONFIG\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 1\n",
    "config[\"num_envs_per_worker\"] = 1\n",
    "\n",
    "config[\"rollout_fragment_length\"] = 10\n",
    "config[\"train_batch_size\"] = 50\n",
    "config[\"timesteps_per_iteration\"] = 10\n",
    "config[\"buffer_size\"] = 10000\n",
    "\n",
    "config[\"Q_model\"][\"fcnet_hiddens\"] = [10, 10]\n",
    "config[\"policy_model\"][\"fcnet_hiddens\"] = [10, 10]\n",
    "config[\"num_cpus_per_worker\"] = 2 \n",
    "config[\"env_config\"] = {\n",
    "    \"pricing_source\": \"csvdata\",\n",
    "    \"tickers\": [\"QQQ\", \"EEM\", \"TLT\", \"SHY\", \"GLD\", \"SLV\"],\n",
    "    \"lookback\": 1,\n",
    "    \"start\": \"2007-01-02\",\n",
    "    \"end\": \"2015-12-31\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train agent \n",
    "agent = SACTrainer(config, Equitydaily)\n",
    "best_reward = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    result = agent.train()\n",
    "    if result['episode_reward_mean'] > best_reward + 0.01:\n",
    "        path = agent.save('sampleagent')\n",
    "        print(path)\n",
    "        best_reward = result['episode_reward_mean']\n",
    "    print(result['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6042\n",
      "2010\n",
      "2020-11-24 18:19:14,974\tWARNING util.py:39 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "agent = PPOTrainer(config, Equitydaily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6042\n",
      "1190\n"
     ]
    }
   ],
   "source": [
    "env = Equitydaily(config['env_config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoint_1087/checkpoint-1087.tune_metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-d66c41531741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoint_1087/checkpoint-1087'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/quant/lib/python3.7/site-packages/ray/tune/trainable.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mThis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mrestores\u001b[0m \u001b[0madditional\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0msaved\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \"\"\"\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".tune_metadata\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"experiment_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoint_1087/checkpoint-1087.tune_metadata'"
     ]
    }
   ],
   "source": [
    "agent.restore('checkpoint_1087/checkpoint-1087')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "done = False\n",
    "reward_list = []\n",
    "cum_reward = 0\n",
    "actions = list()\n",
    "\n",
    "while not done:\n",
    "    #action = agent.compute_action(state)\n",
    "    action = np.array([0,0,0,0,0,0,1])\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    cum_reward += reward\n",
    "    actions.append(action)\n",
    "    reward_list.append(reward)\n",
    "\n",
    "pd.Series(env.log_return_series).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(reward_list).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run environment for RNN environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Equitydaily({'pricing_source':'Alpaca_Equity_daily', 'tickers':['SPY','QQQ'], 'lookback':50, 'start':'2018-01-02', 'end':'2020-12-31'})\n",
    "\n",
    "state = env.reset()\n",
    "done = False\n",
    "cum_reward = 0 \n",
    "actions = list()\n",
    "\n",
    "rnn_state = agent.get_policy().get_initial_state()\n",
    "\n",
    "while not done:\n",
    "    action, rnn_state, _ = agent.compute_action(state,rnn_state)\n",
    "    #action = np.array([1,-1])\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    cum_reward += reward\n",
    "    actions.append(actions)\n",
    "\n",
    "pd.Series(env.log_return_series).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_drawdown(pd.Series(env.log_return_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_return(pd.Series(env.log_return_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Equitydaily_v1(gym.Env):\n",
    "\n",
    "    def __init__(self,env_config):\n",
    "        \n",
    "        self.tickers = env_config['tickers']\n",
    "        self.lookback = env_config['lookback']\n",
    "        # Load price data, to be replaced by DataLoader class\n",
    "        raw_data = load_data(env_config['pricing_source'],env_config['tickers'],env_config['start'],env_config['end'])\n",
    "        # Set the trading dates, features and price data \n",
    "        self.dates = raw_data['dates']\n",
    "        self.fields = raw_data['fields']\n",
    "        self.pricedata = raw_data['pricedata']\n",
    "        self.featuredata = raw_data['data']\n",
    "        self.tcostdata = raw_data['tcost']\n",
    "        # Set up historical actions and rewards \n",
    "        self.n_assets = len(self.tickers) + 1\n",
    "        self.n_metrics = 2 \n",
    "        self.n_assets_fields = len(self.fields)\n",
    "        self.n_features = self.n_assets_fields * len(self.tickers) + self.n_assets + self.n_metrics # reward function\n",
    "        \n",
    "        # Set up action and observation space\n",
    "        # The last asset is cash \n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(self.tickers)+1,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf,\n",
    "                                            shape=(self.lookback,self.n_features), dtype=np.float32)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        ## Normalise action space \n",
    "        normalised_action = action / np.sum(np.abs(action))\n",
    "        \n",
    "        done = False\n",
    "        # Rebalance portfolio at close using return of the next date\n",
    "        next_day_log_return = self.pricedata[self.index,:]\n",
    "        # transaction cost \n",
    "        transaction_cost = self.transaction_cost(normalised_action,self.position_series[-1])\n",
    "        \n",
    "        # Rebalancing \n",
    "        self.position_series = np.append(self.position_series, [normalised_action], axis=0)\n",
    "        # Portfolio return \n",
    "        today_portfolio_return = np.sum(normalised_action[:-1] * next_day_log_return) + np.sum(transaction_cost)\n",
    "        self.log_return_series = np.append(self.log_return_series, [today_portfolio_return], axis=0)\n",
    "        \n",
    "        \n",
    "        # Calculate reward \n",
    "        # Need to cast log_return in pd series to use the functions in empyrical \n",
    "        live_days = self.index - self.lookback\n",
    "        burnin = 250\n",
    "        recent_series = pd.Series(self.log_return_series)[-100:]\n",
    "        whole_series = pd.Series(self.log_return_series)\n",
    "        if live_days > burnin: \n",
    "            self.metric = annual_return(whole_series) + 0.5* max_drawdown(whole_series)\n",
    "        else:\n",
    "            self.metric = annual_return(whole_series) + 0.5* max_drawdown(whole_series) *live_days / burnin\n",
    "        reward = self.metric - self.metric_series[-1]\n",
    "        #reward = self.metric\n",
    "        self.metric_series = np.append(self.metric_series, [self.metric], axis=0)\n",
    "        \n",
    "        # Check if the end of backtest\n",
    "        if self.index >= self.pricedata.shape[0]-2:\n",
    "            done = True\n",
    "            \n",
    "        # Prepare observation for next day\n",
    "        self.index += 1\n",
    "        self.observation = self.get_observation()\n",
    "            \n",
    "        return self.observation, reward, done, {'current_price':next_day_log_return}\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        self.log_return_series = np.zeros(shape=self.lookback)\n",
    "        self.metric_series = np.zeros(shape=self.lookback)\n",
    "        self.position_series = np.zeros(shape=(self.lookback,self.n_assets))\n",
    "        self.metric = 0                    \n",
    "        self.index = self.lookback\n",
    "        self.observation = self.get_observation()\n",
    "        return self.observation\n",
    "    \n",
    "    def get_observation(self):\n",
    "        # Can use simple moving average data here \n",
    "        price_lookback = self.featuredata[self.index-self.lookback:self.index,:]\n",
    "        metrics = np.vstack((self.log_return_series[self.index-self.lookback:self.index], \n",
    "                             self.metric_series[self.index-self.lookback:self.index])).transpose()\n",
    "        positions = self.position_series[self.index-self.lookback:self.index]\n",
    "        observation = np.concatenate((price_lookback, metrics, positions), axis=1)\n",
    "        return observation \n",
    "    \n",
    "    # 0.05% and spread to model t-cost for institutional portfolios \n",
    "    def transaction_cost(self,new_action,old_action,):\n",
    "        turnover = np.abs(new_action - old_action) \n",
    "        fees = 0.9995 - self.tcostdata[self.index,:]\n",
    "        tcost = turnover * np.log(fees)\n",
    "        return tcost "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reinforcement]",
   "language": "python",
   "name": "conda-env-reinforcement-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
